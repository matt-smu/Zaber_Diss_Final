
In this section we describe our proof of concept implementation of the pipeline shown in Figure \ref{fig:automation:metric_pipeline} and demonstrate how it can be used to address some current issues in security measurement research. We provide an example environment for metric development and evaluation. We create a library of select security metrics from the literature and build up reusable processing components for end-to-end automation of the pipeline. We then demonstrate the utility of the framework with two motivating examples. In the first case we develop a simple validation methodology for security metrics. Then we describe a distributed stream processing architecture for deploying security metrics in production, and discuss practical considerations for scaling, securing, and managing dependencies in the metric pipeline.. The entire workflow can be thought of in terms of the well-known \textit{extract, transform, load} (ETL) process, which opens up a variety of design, implementation, and deployment options. Our goal in this section therefore is to describe contributions specific to security metrics analysis, where adherence to the literature is prioritized above computational optimization and efficiency. In Section \ref{sec:automation:dev_env} we described how to use ansible as a driver to control process flows which easily creates a clean environment suitable for development and testing of pipeline components like interaction rules, transform logic, metrics, and reporting formats. In Section \ref{sec:automation:results:graph_manip_figs} we discuss how implementing this pipeline as a (Python) library enables us to batch experiments for controlled validation and analysis. Finally, we review the details of how we have implemented the metrics catalog and some findings we have come across regarding their presentation in the literature.

