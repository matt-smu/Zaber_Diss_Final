@phdthesis{Abraham_2016,
	title        = {Cyber-security analytics: Stochastic models for security quantification},
	author       = {Abraham, Subil},
	year         = 2016,
	school       = {Southern Methodist University}
}
@article{Abraham_Nair_2014,
	title        = {Cyber security analytics: a stochastic model for security quantification using absorbing markov chains},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2014,
	journal      = {Journal of Communications},
	volume       = 9,
	number       = 12,
	pages        = {899–907}
}
@inproceedings{Abraham_Nair_2015a,
	title        = {A novel architecture for predictive cybersecurity using non-homogenous markov models},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	booktitle    = {2015 IEEE Trustcom/BigDataSE/ISPA},
	publisher    = {IEEE},
	volume       = 1,
	pages        = {774–781}
}
@article{Abraham_Nair_2015b,
	title        = {A predictive framework for cyber security analytics using attack graphs},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1502.01240}
}
@inproceedings{Abraham_Nair_2015c,
	title        = {Exploitability analysis using predictive cybersecurity framework},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	booktitle    = {2015 IEEE 2nd International Conference on Cybernetics (CYBCONF)},
	publisher    = {IEEE},
	pages        = {317–323}
}
@article{Abraham_Nair_2015d,
	title        = {Predictive cyber-security analytics framework: a non-homogenous markov model for security quantification},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1501.01901}
}
@article{Abraham_Nair_2018,
	title        = {Comparative analysis and patch optimization using the cyber security analytics framework},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2018,
	journal      = {The Journal of Defense Modeling and Simulation},
	volume       = 15,
	number       = 2,
	pages        = {161–180}
}
@article{Dijkstra_1959,
	title        = {A note on two problems in connexion with graphs},
	author       = {Dijkstra, Edsger W.},
	year         = 1959,
	journal      = {Numerische mathematik},
	volume       = 1,
	number       = 1,
	pages        = {269–271}
}
@article{Idika_Bhargava_2012,
	title        = {Extending attack graph-based security metrics and aggregating their application},
	author       = {Idika, Nwokedi and Bhargava, Bharat},
	year         = 2012,
	journal      = {IEEE Transactions on dependable and secure computing},
	volume       = 9,
	number       = 1,
	pages        = {75–85}
}
@book{Kirkham_2012,
	title        = {Issues with Private IP Addressing in the Internet},
	author       = {Kirkham, Anthony},
	year         = 2012
}
@inproceedings{Li_Vaughn_2006,
	title        = {Cluster security research involving the modeling of network exploitations using exploitation graphs},
	author       = {Li, Wei and Vaughn, Rayford B.},
	year         = 2006,
	booktitle    = {Sixth IEEE International Symposium on Cluster Computing and the Grid (CCGRID’06)},
	publisher    = {IEEE},
	volume       = 2,
	pages        = {26–26}
}
@article{Ortalo_1999,
	title        = {Experimenting with quantitative evaluation tools for monitoring operational security},
	author       = {Ortalo, Rodolphe and Deswarte, Yves and Kaâniche, Mohamed},
	year         = 1999,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 25,
	number       = 5,
	pages        = {633–650}
}
@book{Ou_Appel_2005,
	title        = {A logic-programming approach to network security analysis},
	author       = {Ou, Xinming and Appel, Andrew W.},
	year         = 2005,
	publisher    = {Princeton University Princeton}
}
@misc{Mell07thecommon,
	title        = {The Common Vulnerability Scoring System (CVSS) and Its Applicability to Federal Agency Systems},
	author       = {Peter Mell and Karen Scarfone and Sasha Romanosky and Peter Mell and Karen Scarfone and Sasha Romanosky and Carlos M. Gutierrez and William Jeffrey Director},
	year         = 2007
}
@article{Ou_Govindavajhala_Appel,
	title        = {MulVAL: A Logic-based Network Security Analyzer},
	author       = {Ou, Xinming and Govindavajhala, Sudhakar and Appel, Andrew W},
	pages        = 16,
	abstractnote = {To determine the security impact software vulnerabilities have on a particular network, one must consider interactions among multiple network elements. For a vulnerability analysis tool to be useful in practice, two features are crucial. First, the model used in the analysis must be able to automatically integrate formal vulnerability speciﬁcations from the bug-reporting community. Second, the analysis must be able to scale to networks with thousands of machines.}
}
@inproceedings{Rao_1997,
	title        = {XSB: A system for efficiently computing well-founded semantics},
	author       = {Rao, Prasad and Sagonas, Konstantinos and Swift, Terrance and Warren, David S. and Freire, Juliana},
	year         = 1997,
	booktitle    = {Logic Programming And Nonmonotonic Reasoning},
	publisher    = {Springer Berlin Heidelberg},
	pages        = {430–440},
	isbn         = {978-3-540-69249-2},
	place        = {Berlin, Heidelberg},
	abstractnote = {The well-founded model provides a natural and robust semantics for logic programs with negative literals in rule bodies. We implemented the well-founded semantics in the SLG-WAM of XSB [19]. Performance results indicate that the overhead of delay and simplification to Prolog — or tabled — evaluations is minimal. To compute the well-founded semantics, the SLG-WAM adds to an efficient tabling engine for definite programs three operations — negative loop detection, delay and simplification — which serve to detect, to break and to resolve cycles through negation that might arise in evaluating normal programs. XSB is a full Prolog system that closely approximates the ISO standard; additionally, it supports a tight integration of tabled predicates with nontabled predicates.},
	editor       = {Dix, Jürgen and Furbach, Ulrich and Nerode, AnilEditors}
}
@inproceedings{Phillips_Swiler_1998,
	title        = {A graph-based system for network-vulnerability analysis},
	author       = {Phillips, Cynthia and Swiler, Laura Painton},
	year         = 1998,
	booktitle    = {Proceedings of the 1998 workshop on New security paradigms  - NSPW ’98},
	publisher    = {ACM Press},
	pages        = {71–79},
	doi          = {10.1145/310889.310919},
	isbn         = {978-1-58113-168-0},
	url          = {http://portal.acm.org/citation.cfm?doid=310889.310919},
	place        = {Charlottesville, Virginia, United States},
	abstractnote = {This paper presents a graph-based approach to network vulnerability analysis. The method is flexible, allowing analysis of attacks from both outside and inside the network. It can analyze risks to a specific network asset, or examine the universe of possible consequences following a successful attack. The graph-based tool can identify the set of attack paths that have a high probability of success (or a low “effort” cost) for the attacker. The system could be used to test the effectiveness of making configuration changes, implementing an intrusion detection system, etc.}
}
@inproceedings{Ou_Boyer_McQueen_2006,
	title        = {A scalable approach to attack graph generation},
	author       = {Ou, Xinming and Boyer, Wayne F. and McQueen, Miles A.},
	year         = 2006,
	booktitle    = {Proceedings of the 13th ACM conference on Computer and communications security},
	publisher    = {ACM},
	pages        = {336–345},
	url          = {http://dl.acm.org/citation.cfm?id=1180446}
}
@inproceedings{Hong_Kim_Takaoka_2013,
	title        = {Scalable Attack Representation Model Using Logic Reduction Techniques},
	author       = {Hong, J. B. and Kim, D. S. and Takaoka, T.},
	year         = 2013,
	month        = {07},
	booktitle    = {2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications},
	pages        = {404–411},
	doi          = {10.1109/TrustCom.2013.51},
	abstractnote = {Automated construction methods of attack graphs (AGs) and their improved attack representation models (ARMs) have been proposed, but the AG has a state space explosion when analysing the security of very large sized networked systems. Instead, attack trees (ATs) and their improved ARMs can be used (e.g., Defense Trees, Protection Trees, Attack Response Trees, and Attack Countermeasure Trees), because they are a non-state-space model. However, there are no known methods to construct ATs in a scalable manner automatically while maintaining all possible attack scenarios. We can use an AG generation tools, and transform the AG into the AT using min-cuts. However, this method requires a transformation (i.e., an overhead), and computing min-cuts is a NP-hard problem. Another way is to construct ATs directly with given network information. A naive approach is to compute all possible attack paths and populate the AT branches using logic gates (e.g., AND and OR gates), but this method generates an exponential number of nodes, causing a scalability problem. We propose two logic reduction techniques to automate the ATs construction and to reduce the size of the AT. The computational complexity is calculated. The simulation result shows the construction time for the naive method and two logic reduction techniques. The trade-off between the construction time and the memory usage of simplified ATs are also shown.}
}
@inproceedings{Chowdhary_Pisharody_Huang_2016,
	title        = {SDN based Scalable MTD solution in Cloud Network},
	author       = {Chowdhary, Ankur and Pisharody, Sandeep and Huang, Dijiang},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 ACM Workshop on Moving Target Defense  - MTD’16},
	publisher    = {ACM Press},
	pages        = {27–36},
	doi          = {10.1145/2995272.2995274},
	isbn         = {978-1-4503-4570-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2995272.2995274},
	place        = {Vienna, Austria},
	abstractnote = {Software-Deﬁned Networking (SDN) has emerged as a framework for centralized command and control in cloud data centric environments. SDN separates data and control plane, which provides network administrator better visibility and policy enforcement capability compared to traditional networks. The SDN controller can assess reachability information of all the hosts in a network. There are many critical assets in a network which can be compromised by a malicious attacker through a multistage attack. Thus we make use of centralized controller to assess the security state of the entire network and pro-actively perform attack analysis and countermeasure selection. This approach is also known as Moving Target Defense (MTD). We use the SDN controller to assess the attack scenarios through scalable Attack Graphs (AG) and select necessary countermeasures to perform network reconﬁguration to counter network attacks. Moreover, our framework has a comprehensive conﬂict detection and resolution module that ensures that no two ﬂow rules in a distributed SDN-based cloud environment have conﬂicts at any layer; thereby assuring consistent conﬂict-free policy implementation and preventing information leakage.}
}
@article{Bacic_Froh_Henderson_2006,
	title        = {MulVAL Extensions for Dynamic Asset Protection},
	author       = {Bacic, Eugen and Froh, Michael and Henderson, Glen},
	year         = 2006,
	month        = {04},
	pages        = 68,
	abstractnote = {This paper documents research into extensions to the Multihost, Multistage Vulnerability Analysis (MulVAL) framework to support DRDC efforts to develop a feasible abstraction in the area of defensive posture technology. The results presented in this paper demonstrate that the MulVAL model is extensible and can be enhanced to include additional data representation and analysis features to tailor the model to meet the need of the DND defence community. The extensions evaluated in this effort have been shown to be both technically valid given the capabilities of logic-based programming and appropriate given the current model data representations. The primary extensions researched as part of this work are: improved representation of network path constructs and assignment of value to data assets in the model. This paper documents a substantial degree of progress in the development of each of the proposed MulVAL extensions.}
}
@article{Kordy_2013,
	title        = {DAG-Based Attack and Defense Modeling: Don’t Miss the Forest for the Attack Trees},
	author       = {Kordy, Barbara and Piètre-Cambacédès, Ludovic and Schweitzer, Patrick},
	year         = 2013,
	month        = {03},
	journal      = {arXiv:1303.7397 [cs]},
	url          = {http://arxiv.org/abs/1303.7397},
	note         = {arXiv: 1303.7397},
	abstractnote = {This paper presents the current state of the art on attack and defense modeling approaches that are based on directed acyclic graphs (DAGs). DAGs allow for a hierarchical decomposition of complex scenarios into simple, easily understandable and quantiﬁable actions. Methods based on threat trees and Bayesian networks are two well-known approaches to security modeling. However there exist more than 30 DAG-based methodologies, each having diﬀerent features and goals. The objective of this survey is to present a complete overview of graphical attack and defense modeling techniques based on DAGs. This consists of summarizing the existing methodologies, comparing their features and proposing a taxonomy of the described formalisms. This article also supports the selection of an adequate modeling technique depending on user requirements.}
}
@book{Lippmann_Ingols_2005,
	title        = {An annotated review of past papers on attack graphs},
	author       = {Lippmann, Richard Paul and Ingols, Kyle William},
	year         = 2005,
	institution  = {MASSACHUSETTS INST OF TECH LEXINGTON LINCOLN LAB}
}
@inproceedings{Sheyner_Haines_Jha_Lippmann_Wing_2002,
	title        = {Automated generation and analysis of attack graphs},
	author       = {Sheyner, Oleg and Haines, Joshua and Jha, Somesh and Lippmann, Richard and Wing, Jeannette M.},
	year         = 2002,
	booktitle    = {Proceedings 2002 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {273–284}
}
@inproceedings{Dacier_1994,
	title        = {Privilege Graph: An Extension to the Typed Access Matrix Model},
	author       = {Dacier, Marc and Deswarte, Yves},
	year         = 1994,
	booktitle    = {Proceedings of the Third European Symposium on Research in Computer Security},
	publisher    = {Springer-Verlag},
	address      = {London, UK, UK},
	series       = {ESORICS '94},
	pages        = {319--334},
	isbn         = {3-540-58618-0},
	url          = {http://dl.acm.org/citation.cfm?id=646645.699167},
	numpages     = 16,
	acmid        = 699167
}
@article{Sembiring_Ramadhan_Gondokaryono_Arman_2015,
	title        = {Network Security Risk Analysis using Improved MulVAL Bayesian Attack Graphs},
	author       = {Sembiring, Jaka and Ramadhan, Mufti and Gondokaryono, Yudi and Arman, Arry},
	year         = 2015,
	month        = 12,
	journal      = {International Journal on Electrical Engineering and Informatics},
	volume       = 7,
	pages        = {735–753},
	doi          = {10.15676/ijeei.2015.7.4.15},
	abstractnote = {This paper presents some improvements on the Multihost Multistage Vulnerability Analysis (MulVAL) framework. MulVAL is a framework to generate an attack graph for analysis of a computer network security risk. In MulVAL, it is assumed that the probability of success in exploiting the machine configuration and vulnerability variable is 100, and the vulnerability variables are independent of each other. In reality each machine has its own security configuration issue, and vulnerabilities are not independent of each other. Moreover the research in MulVAL attack graph solely focuses on the probability of vulnerability, whereas the probability of vulnerability in security configuration is not covered. In this paper we introduce three methods to improve the MulVAL framework. In the first method we employ Common Vulnerability Scoring System (CVSS) for calculating the probability of vulnerability variables, and Common Configuration Scoring System (CCSS) for calculating the probability of vulnerability of system security configuration. In the second method we introduce the interdependence of vulnerability variables in Bayesian senses. Finally, in the third method we analyze the impact of the change in system security configuration to the probability of vulnerability in the context of Bayesian probability. We analyze and discuss the proposed methods through a simulation for a simple network configuration. The simulation results of the proposed methods demonstrate that the introduction of CVSS, CCSS, employing dependency of vulnerability variables and system security configuration represent a more realistic model for vulnerability in MulVAL framework. © 2015, School of Electrical Engineering and Informatics. All rights reserved.}
}
@book{Swanson_Bartol_Sabato_Hash_Graffo_2003,
	title        = {Security metrics guide for information technology systems},
	author       = {Swanson, M and Bartol, N and Sabato, J and Hash, J and Graffo, L},
	year         = 2003,
	number       = {NIST SP 800-55},
	pages        = {NIST SP 800--55},
	doi          = {10.6028/NIST.SP.800-55},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-55.pdf},
	place        = {Gaithersburg, MD},
	institution  = {National Institute of Standards and Technology}
}
@article{Dacier_Deswarte_Kaaniche,
	title        = {Quantitative Assessment of Operational Security: Models and Tools},
	author       = {Dacier, Marc and Deswarte, Yves and Kaâniche, Mohamed},
	pages        = 23,
	abstractnote = {This paper proposes a novel approach to help computing system administrators in monitoring the security of their systems. This approach is based on modeling the system as a privilege graph exhibiting operational security vulnerabilities and on transforming this privilege graph into a Markov chain corresponding to all possible successful attack scenarios. A set of tools has been developed to generate automatically the privilege graph of a Unix system, to transform it into the corresponding Markov chain and to compute characteristic measures of the operational system security.}
}
@article{Liu_Singhal_Wijesekera,
	title        = {A Logic Based Network Forensics Model for Evidence Analysis},
	author       = {Liu, Changwei and Singhal, Anoop and Wijesekera, Duminda},
	pages        = 19,
	abstractnote = {Modern-day attackers tend to use sophisticated multi-stage/multi-host attack techniques and anti-forensics tools to cover their attack traces. Due to the limitations of current intrusion detection and forensic analysis tools, reconstructing attack scenarios from evidence left behind by the attackers of an enterprise system is challenging. In particular, reconstructing attack scenarios by using intrusion detection system (IDS) alerts and system logs that have too many false positives is a big challenge. In this paper, we present a model and an accompanying software tool that systematically addresses how to resolve the above problems to reconstruct attack scenarios that could stand up in court. These problems include a large amount of data including non-relevant data, missing evidence and incomplete evidence destroyed by using anti-forensic techniques. Our system is based on a Prolog system using known vulnerability databases and an anti-forensic database that we plan to extend to a standardized database like the existing NIST National Vulnerability Database (NVD). In this model, we use diﬀerent methods, including mapping the evidence to system vulnerabilities, inductive reasoning and abductive reasoning, to reconstruct attack scenarios. The goal of this work is to reduce the security investigators’ time and eﬀort in reaching deﬁnite conclusion about how an attack occurred. Our results indicate that such a reasoning system can be useful for network forensics analysis.}
}
@inbook{McQueen_Boyer_Flynn_Beitel_2006,
	title        = {Time-to-Compromise Model for Cyber Risk Reduction Estimation},
	author       = {McQueen, Miles A. and Boyer, Wayne F. and Flynn, Mark A. and Beitel, George A.},
	year         = 2006,
	booktitle    = {Quality of Protection},
	publisher    = {Springer US},
	volume       = 23,
	pages        = {49–64},
	doi          = {10.1007/978-0-387-36584-8_5},
	isbn         = {978-0-387-29016-4},
	url          = {http://link.springer.com/10.1007/978-0-387-36584-8_5},
	place        = {Boston, MA},
	abstractnote = {We propose a new model for estimating the time to compromise a system component that is visible to an attacker. The model provides an estimate of the expected value of the time-to-compromise as a function of known and visible vulnerabilities, and attacker skill level. The time-to-compromise random process model is a composite of three subprocesses associated with attacker actions aimed at the exploitation of vulnerabilities. In a case study, the model was used to aid in a risk reduction estimate between a baseline Supervisory Control and Data Acquisition (SCADA) system and the baseline system enhanced through a specific set of control system security remedial actions. For our case study, the total number of system vulnerabilities was reduced by 86 but the dominant attack path was through a component where the number of vulnerabilities was reduced by only 42 and the time-to-compromise of that component was increased by only 13 to 30 depending on attacker skill level.},
	editor       = {Gollmann, Dieter and Massacci, Fabio and Yautsiukhin, ArtsiomEditors}
}
@book{Hall:2013:ACM:2601666,
	title        = {Ansible Configuration Management},
	author       = {Hall, Daniel},
	year         = 2013,
	publisher    = {Packt Publishing},
	isbn         = 9781783280810
}
@article{Henderson_Bacic_Froh_2005,
	title        = {Dynamic Asset Protection and Risk Management Abstraction Study},
	author       = {Henderson, G and Bacic, E and Froh, M},
	year         = 2005,
	pages        = 50
}
@book{Donovan_Prabhu_2017,
	title        = {Building the Network of the Future: Getting Smarter, Faster, and More Flexible with a Software Centric Approach},
	author       = {Donovan, John and Prabhu, Krish},
	year         = 2017,
	publisher    = {CRC Press}
}
@book{Khosravi_Anderson_2003,
	title        = {Requirements for separation of IP control and forwarding},
	author       = {Khosravi, Horzmud and Anderson, Todd},
	year         = 2003,
	publisher    = {RFC 3654, November}
}
@article{Awduche_Agogbua_1999,
	title        = {Requirements for traffic engineering over MPLS},
	author       = {Awduche, Daniel O. and Agogbua, Johnson},
	year         = 1999
}
@misc{Muthukrishnan_Malis,
	title        = {A Core MPLS IP VPN Architecture},
	author       = {Muthukrishnan, Karthik and Malis, Andrew},
	url          = {https://tools.ietf.org/html/rfc2917}
}
@article{Rosen_Rekhter_2006,
	title        = {BGP/MPLS IP virtual private networks (VPNs)},
	author       = {Rosen, Eric C. and Rekhter, Yakov},
	year         = 2006
}
@article{Chandra_Harel_1985,
	title        = {Horn clause queries and generalizations},
	author       = {Chandra, Ashok K. and Harel, David},
	year         = 1985,
	journal      = {The Journal of Logic Programming},
	volume       = 2,
	number       = 1,
	pages        = {1–15}
}
@article{Chakrabarti_Govindarasu_2002,
	title        = {Internet infrastructure security: A taxonomy},
	author       = {Chakrabarti, A and Govindarasu, Manimaran},
	year         = 2002,
	month        = 12,
	journal      = {Network, IEEE},
	volume       = 16,
	pages        = {13–21},
	doi          = {10.1109/MNET.2002.1081761},
	abstractnote = {The pervasive and ubiquitous nature of the Internet coupled with growing concerns about cyber terrorism demand immediate solutions for securing the Internet infrastructure. So far, the research in Internet security primarily focused on. securing the information rather than securing the infrastructure itself. Given the prevailing threat situation, there is a compelling need to develop architectures, algorithms, and protocols to realize a dependable Internet infrastructure. In order to achieve this goal, the first and foremost step is to develop a comprehensive understanding of the security threats and existing solutions. This article attempts to fulfill this important step by providing a taxonomy of security attacks, which are classified into four main categories: DNS hacking, routing table poisoning, packet mistreatment, and denial-of-service attacks. The article discusses the existing solutions for each of these categories, and also outlines a methodology for developing secure protocols.}
}
@article{Zimmermann_1980,
	title        = {OSI reference model-the ISO model of architecture for open systems interconnection},
	author       = {Zimmermann, Hubert},
	year         = 1980,
	journal      = {IEEE Transactions on communications},
	volume       = 28,
	number       = 4,
	pages        = {425–432}
}
@misc{Plummer,
	title        = {An Ethernet Address Resolution Protocol: Or Converting Network Protocol Addresses to 48.bit Ethernet Address for Transmission on Ethernet Hardware},
	author       = {Plummer, D.},
	url          = {https://tools.ietf.org/html/rfc826}
}
@article{Stan_Bitton_Ezrets_Dadon_Inokuchi_Ohta_Yamada_Yagyu_Elovici_Shabtai_2019,
	title        = {Extending Attack Graphs to Represent Cyber-Attacks in Communication Protocols and Modern IT Networks},
	author       = {Stan, Orly and Bitton, Ron and Ezrets, Michal and Dadon, Moran and Inokuchi, Masaki and Ohta, Yoshinobu and Yamada, Yoshiyuki and Yagyu, Tomohiko and Elovici, Yuval and Shabtai, Asaf},
	year         = 2019,
	month        = 6,
	journal      = {arXiv:1906.09786 [cs]},
	url          = {http://arxiv.org/abs/1906.09786},
	note         = {arXiv: 1906.09786},
	abstractnote = {An attack graph is a method used to enumerate the possible paths that an attacker can execute in the organization network. MulVAL is a known open-source framework used to automatically generate attack graphs. MulVAL’s default modeling has two main shortcomings. First, it lacks the representation of network protocol vulnerabilities, and thus it cannot be used to model common network attacks such as ARP poisoning, DNS spoofing, and SYN flooding. Second, it does not support advanced types of communication such as wireless and bus communication, and thus it cannot be used to model cyber-attacks on networks that include IoT devices or industrial components. In this paper, we present an extended network security model for MulVAL that: (1) considers the physical network topology, (2) supports short-range communication protocols (e.g., Bluetooth), (3) models vulnerabilities in the design of network protocols, and (4) models specific industrial communication architectures. Using the proposed extensions, we were able to model multiple attack techniques including: spoofing, man-in-the-middle, and denial of service, as well as attacks on advanced types of communication. We demonstrate the proposed model on a testbed implementing a simplified network architecture comprised of both IT and industrial components.}
}
@inproceedings{Acosta_Padilla_Homer_2016,
	title        = {Augmenting attack graphs to represent data link and network layer vulnerabilities},
	author       = {Acosta, J. C. and Padilla, E. and Homer, J.},
	year         = 2016,
	month        = 11,
	booktitle    = {MILCOM 2016 - 2016 IEEE Military Communications Conference},
	pages        = {1010–1015},
	doi          = {10.1109/MILCOM.2016.7795462},
	abstractnote = {Attack graphs enable system stakeholders to understand the stepping stones or exploitation procedures that an adversary could potentially execute to impact the confidentiality, integrity, and availability of a network system. These graphs are used to assess risk and to determine components that, when hardened, contribute most to risk reduction. While these graphs are powerful and widely used in enterprise network systems they focus on application vulnerabilities; they currently do not incorporate weaknesses in the network backbone (e.g., routing) that could lead to traffic hijacking, spoofing, eavesdropping, and several others. In this paper, we describe our work in augmenting the MulVAL attack graph software to incorporate network layer misconfigurations. Through a case study, we show how our modular data pipeline, leveraging previous work in network layer attack impact prediction, can aid system stakeholders in identifying risk and deciding on risk reduction strategies.}
}
@article{Dacier_Deswarte_Kaaniche_1996,
	title        = {Quantitative assessment of operational security: Models and tools},
	author       = {Dacier, Marc and Deswarte, Yves and Kaâniche, Mohamed},
	year         = 1996,
	journal      = {Information Systems Security, ed. by SK Katsikas and D. Gritzalis, London, Chapman \& Hall},
	pages        = {179–86}
}
@inproceedings{Noel_Jajodia_2014,
	title        = {Metrics suite for network attack graph analytics},
	author       = {Noel, Steven and Jajodia, Sushil},
	year         = 2014,
	booktitle    = {Proceedings of the 9th Annual Cyber and Information Security Research Conference on - CISR ’14},
	publisher    = {ACM Press},
	pages        = {5–8},
	doi          = {10.1145/2602087.2602117},
	isbn         = {978-1-4503-2812-8},
	url          = {http://dl.acm.org/citation.cfm?doid=2602087.2602117},
	place        = {Oak Ridge, Tennessee},
	abstractnote = {We describe a suite of metrics for measuring network-wide cyber security risk based on a model of multi-step attack vulnerability (attack graphs). Our metrics are grouped into families, with family-level metrics combined into an overall metric for network vulnerability risk. The Victimization family measures risk in terms of key attributes of risk across all known network vulnerabilities. The Size family is an indication of the relative size of the attack graph. The Containment family measures risk in terms of minimizing vulnerability exposure across protection boundaries. The Topology family measures risk through graph theoretic properties (connectivity, cycles, and depth) of the attack graph. We display these metrics (at the individual, family, and overall levels) in interactive visualizations, showing multiple metrics trends over time.}
}
@article{Noel_Jajodia,
	title        = {Measuring Security Risk of Networks Using Attack Graphs},
	author       = {Noel, Steven and Jajodia, Sushil},
	volume       = 1,
	number       = 1,
	pages        = 13,
	abstractnote = {Today’s computer systems face sophisticated attackers who combine multiple vulnerabilities to penetrate networks with devastating impact. The overall security of a network cannot be determined by simply counting the number of vulnerabilities. To accurately assess the security of networked systems, one must understand how vulnerabilities can be combined to stage an attack. We model such composition of vulnerabilities through attack graphs. By simulating incremental network penetration, and propagating attack likelihoods, we measure the overall security of a networked system. From this, we score risk mitigation options in terms of maximizing security and minimizing cost. We populate our attack graph models from live network scans and databases that have knowledge about properties such as vulnerability likelihood, impact, severity, and ease of exploitation. Our ﬂexible model can be used to quantify overall security of networked systems, and to study cost/beneﬁt tradeoﬀs for analyzing return on security investment.}
}
@inproceedings{Wang_Islam_Long_Singhal_Jajodia_2008,
	title        = {An attack graph-based probabilistic security metric},
	author       = {Wang, Lingyu and Islam, Tania and Long, Tao and Singhal, Anoop and Jajodia, Sushil},
	year         = 2008,
	booktitle    = {IFIP Annual Conference on Data and Applications Security and Privacy},
	publisher    = {Springer},
	pages        = {283–296},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-70567-3_22}
}
@book{Wang_Jajodia_Singhal_2017,
	title        = {Network Security Metrics},
	author       = {Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop},
	year         = 2017,
	publisher    = {Springer International Publishing},
	doi          = {10.1007/978-3-319-66505-4},
	isbn         = {978-3-319-66504-7},
	url          = {http://link.springer.com/10.1007/978-3-319-66505-4},
	place        = {Cham}
}
@inproceedings{McDermott_2000,
	title        = {Attack net penetration testing},
	author       = {McDermott, J. P.},
	year         = 2000,
	booktitle    = {Proceedings of the 2000 workshop on New security paradigms  - NSPW ’00},
	publisher    = {ACM Press},
	pages        = {15–21},
	doi          = {10.1145/366173.366183},
	isbn         = {978-1-58113-260-1},
	url          = {http://portal.acm.org/citation.cfm?doid=366173.366183},
	place        = {Ballycotton, County Cork, Ireland},
	abstractnote = {The modeling of penetration testing as a Petri net is surprisingly useful. It retains key advantages of the flaw hypothesis and attack tree approaches while providing some new benefits.}
}
@article{Costa_Russo_Armando,
	title        = {Automating the Generation of Cyber Range Virtual Scenarios with VSDL},
	author       = {Costa, Gabriele and Russo, Enrico and Armando, Alessandro},
	pages        = 19,
	abstractnote = {A cyber range is an environment used for training security experts and testing attack and defence tools and procedures. Usually, a cyber range simulates one or more critical infrastructures that attacking (red) and defending (blue) teams must compromise and protect, respectively. The infrastructure can be physically assembled, but much more convenient is to rely on the Infrastructure as a Service (IaaS) paradigm. Although some modern technologies support the IaaS, the design and deployment of scenarios of interest is mostly a manual operation. As a consequence, it is a common practice to have a cyber range hosting few (sometimes only one), consolidated scenarios. However, reusing the same scenario may signiﬁcantly reduce the effectiveness of the training and testing sessions.}
}
@inproceedings{Weiss_1991,
	title        = {A system security engineering process},
	author       = {Weiss, Jonathan D.},
	year         = 1991,
	booktitle    = {Proceedings of the 14th National Computer Security Conference},
	volume       = 249,
	pages        = {572–581}
}
@article{Fleming_Wallace_1986,
	title        = {How not to lie with statistics: the correct way to summarize benchmark results},
	author       = {Fleming, Philip J. and Wallace, John J.},
	year         = 1986,
	month        = mar,
	journal      = {Communications of the ACM},
	volume       = 29,
	number       = 3,
	pages        = {218–221},
	doi          = {10.1145/5666.5673},
	issn         = {00010782}
}
@article{Oppenheimer_Brown_Traupman_Broadwell_Patterson,
	title        = {Practical Issues in Dependability Benchmarking},
	author       = {Oppenheimer, David and Brown, Aaron B and Traupman, Jonathan and Broadwell, Pete and Patterson, David A},
	pages        = 6,
	abstractnote = {Much of the work to date on dependability benchmarks has focused on costly, comprehensive measurements of whole-system dependability. But benchmarks should also be useful for developers and researchers to quickly evaluate incremental improvements to their systems. To address both audiences, we propose dividing the space of dependability benchmarks into two categories: competitive benchmarks that take the holistic approach, and less expensive developer benchmarks aimed at day-to-day development tasks. In this paper we differentiate the goals of these two types of benchmarks, discuss how each type might be appropriately realized, and propose simplifying assumptions for making them cost-effective.}
}
@inproceedings{Paxson_2004,
	title        = {Strategies for sound internet measurement},
	author       = {Paxson, Vern},
	year         = 2004,
	booktitle    = {Proceedings of the 4th ACM SIGCOMM conference on Internet measurement  - IMC ’04},
	publisher    = {ACM Press},
	pages        = 263,
	doi          = {10.1145/1028788.1028824},
	isbn         = {978-1-58113-821-4},
	url          = {http://portal.acm.org/citation.cfm?doid=1028788.1028824},
	note         = {tex.ids: paxsonStrategiesSoundInternet2004a},
	place        = {Taormina, Sicily, Italy},
	abstractnote = {Conducting an Internet measurement study in a sound fashion can be much more difﬁcult than it might ﬁrst appear. We present a number of strategies drawn from experiences for avoiding or overcoming some of the pitfalls. In particular, we discuss dealing with errors and inaccuracies; the importance of associating meta-data with measurements; the technique of calibrating measurements by examining outliers and testing for consistencies; difﬁculties that arise with large-scale measurements; the utility of developing a discipline for reliably reproducing analysis results; and issues with making datasets publicly available. We conclude with thoughts on the sorts of tools and community practices that can assist researchers with conducting sound measurement studies.}
}
@article{Smith_1988,
	title        = {Characterizing computer performance with a single number},
	author       = {Smith, James E.},
	year         = 1988,
	journal      = {Communications of the ACM},
	volume       = 31,
	number       = 10,
	pages        = {1202–1206}
}
@misc{SSI,
	title        = {Single Metric for HPC (NERSC)},
	url          = {https://www.nersc.gov/research-and-development/benchmarking-and-workload-characterization/ssi/}
}
@article{Abubakar_Chiroma_Muaz_Ila_2015,
	title        = {A Review of the Advances in Cyber Security Benchmark Datasets for Evaluating Data-Driven Based Intrusion Detection Systems},
	author       = {Abubakar, Adamu I. and Chiroma, Haruna and Muaz, Sanah Abdullahi and Ila, Libabatu Baballe},
	year         = 2015,
	journal      = {Procedia Computer Science},
	volume       = 62,
	pages        = {221–227},
	doi          = {10.1016/j.procs.2015.08.443},
	issn         = 18770509,
	abstractnote = {Cybercrime has led to the loss of billions of dollars, the malfunctioning of computer systems, the destruction of critical information, the compromising of network integrity and confidentiality, etc. In view of these crimes committed on a daily basis, the security of the computer systems has become imperative to minimize and possibly avoid the impact of cybercrimes. In this paper, we review recent advances in the use of cyber security benchmark datasets for the evaluation of machine learning and data mining-based intrusion detection systems. It was found that the state-of-the-art cyber security benchmark datasets KDD and UNM are no longer reliable, because their datasets cannot meet the expectations of current advances in computer technology. As a result, a new ADFA Linux (ADFA-LD) cyber security benchmark dataset for the evaluation of machine learning and data mining-based intrusion detection systems was proposed in 2013 to meet the current significant advances in computer technology. ADFA-LD requires improvement in terms of full descriptions of its attributes. This review can be used by the research community as a basis for abandoning the previous state-of-the-art cyber security benchmark datasets and starting to use the newly introduced benchmark dataset for effective and robust evaluation of machine learning and data mining-based intrusion detection system.}
}
@article{Amin_Schwartz_Hussain_2013,
	title        = {In quest of benchmarking security risks to cyber-physical systems},
	author       = {Amin, S. and Schwartz, G. A. and Hussain, A.},
	year         = 2013,
	month        = jan,
	journal      = {IEEE Network},
	volume       = 27,
	number       = 1,
	pages        = {19–24},
	doi          = {10.1109/MNET.2013.6423187},
	issn         = {0890-8044},
	abstractnote = {We present a generic yet practical framework for assessing security risks to cyberphysical systems (CPSs). Our framework can be used to benchmark security risks when information is less than perfect, and interdependencies of physical and computational components may result in correlated failures. Such environments are prone to externalities, and can cause huge societal losses. We focus on the risks that arise from interdependent reliability failures (faults) and security failures (attacks). We advocate that a sound assessment of these risks requires explicit modeling of the effects of both technology-based defenses and institutions necessary for supporting them. Thus, we consider technology-based security defenses grounded in information security tools and fault-tolerant control in conjunction with institutional structures. Our game-theoretic approach to estimating security risks facilitates more effective defenses, especially against correlated failures.}
}
@inproceedings{Anisetti_Ardagna_Damiani_Gaudenzi_2017,
	title        = {A Security Benchmark for OpenStack},
	author       = {Anisetti, Marco and Ardagna, Claudio A. and Damiani, Ernesto and Gaudenzi, Filippo},
	year         = 2017,
	month        = jun,
	booktitle    = {2017 IEEE 10th International Conference on Cloud Computing (CLOUD)},
	publisher    = {IEEE},
	pages        = {294–301},
	doi          = {10.1109/CLOUD.2017.45},
	isbn         = {978-1-5386-1993-3},
	url          = {http://ieeexplore.ieee.org/document/8030601/},
	place        = {Honolulu, CA, USA},
	abstractnote = {The cloud computing paradigm entails a radical change in IT provisioning, which must be understood and correctly applied especially when security requirements are considered. Security requirements do not cover anymore just the application itself, but involve the whole cloud supply chain from the hosting infrastructure to the ﬁnal applications. This scenario requires, on one side, new security mechanisms protecting the cloud against misbehaviors/malicious attacks and, on the other side, a continuous and adaptive assurance process evaluating the observed cloud security behavior against the expected one. In this paper, we focus on the evaluation of the security assurance of OpenStack, a major open source cloud infrastructure. We ﬁrst deﬁne a security benchmark for OpenStack, inspired by Center for Internet Security (CIS) benchmark for cloud infrastructures. We then present a platform, called Moon Cloud, for cloud security assurance evaluation, showing an application of our benchmark and platform to the in-production OpenStack deployment of the University of Milan.}
}
@inproceedings{Dumitras_Shou_2011,
	title        = {Toward a standard benchmark for computer security research: the worldwide intelligence network environment (WINE)},
	author       = {Dumitras, Tudor and Shou, Darren},
	year         = 2011,
	booktitle    = {Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security - BADGERS ’11},
	publisher    = {ACM Press},
	pages        = {89–96},
	doi          = {10.1145/1978672.1978683},
	isbn         = {978-1-4503-0768-0},
	url          = {http://portal.acm.org/citation.cfm?doid=1978672.1978683},
	place        = {Salzburg, Austria},
	abstractnote = {Unlike benchmarks that focus on performance or reliability evaluations, a benchmark for computer security must necessarily include sensitive code and data. Because these artifacts could damage systems or reveal personally identiﬁable information about the users affected by cyber attacks, publicly disseminating such a benchmark raises several scientiﬁc, ethical and legal challenges. We propose the Worldwide Intelligence Network Environment (WINE), a security-benchmarking approach based on rigorous experimental methods. WINE includes representative ﬁeld data, collected worldwide from 240,000 sensors, for new empirical studies, and it will enable the validation of research on all the phases in the lifecycle of security threats. We tackle the key challenges for security benchmarking by designing a platform for repeatable experimentation on the WINE data sets and by collecting the metadata required for understanding the results. In this paper, we review the unique characteristics of the WINE data, we discuss why rigorous benchmarking will provide fresh insights on the security arms race and we propose a research agenda for this area.}
}
@inproceedings{Hlyne_Zavarsky_Butakov_2015,
	title        = {SCAP benchmark for Cisco router security configuration compliance},
	author       = {Hlyne, Chit Nyi Nyi and Zavarsky, Pavol and Butakov, Sergey},
	year         = 2015,
	month        = dec,
	booktitle    = {2015 10th International Conference for Internet Technology and Secured Transactions (ICITST)},
	publisher    = {IEEE},
	pages        = {270–276},
	doi          = {10.1109/ICITST.2015.7412104},
	isbn         = {978-1-908320-52-0},
	url          = {http://ieeexplore.ieee.org/document/7412104/},
	place        = {London, United Kingdom},
	abstractnote = {Information security management is timeconsuming and error-prone. Apart from day-to-day operations, organizations need to comply with industrial regulations or government directives. Thus, organizations are looking for security tools to automate security management tasks and daily operations. Security Content Automation Protocol (SCAP) is a suite of specifications that help to automate security management tasks such as vulnerability measurement and policy compliance evaluation. SCAP benchmark provides detailed guidance on setting the security configuration of network devices, operating systems, and applications. Organizations can use SCAP benchmark to perform automated configuration compliance assessment on network devices, operating systems, and applications. This paper discusses SCAP benchmark components and the development of a SCAP benchmark for automating Cisco router security configuration compliance.}
}
@article{Ring_Wunderlich,
	title        = {Flow-based benchmark data sets for intrusion detection},
	author       = {Ring, Markus and Wunderlich, Sarah and Grüdl, Dominik and Landes, Dieter and Hotho, Andreas},
	pages        = 10,
	note         = {tex.ids: ringFlowbasedBenchmarkDataa},
	abstractnote = {Anomaly based intrusion detection systems suffer from a lack of appropriate evaluation data sets. Often, existing data sets may not be published due to privacy concerns or do not reflect actual and current attack scenarios. In order to overcome these problems, we identify characteristics of good data sets and develop an appropriate concept for the generation of labelled flow-based data sets that satisfy these criteria. The concept is implemented based on OpenStack, thus demonstrating the suitability of virtual environments. Virtual environments offer advantages compared to static data sets by easily creating up-to-date data sets with recent trends in user behaviour and new attack scenarios.}
}
@article{Sharafaldin_Gharib_Lashkari_Ghorbani_2018,
	title        = {Towards a Reliable Intrusion Detection Benchmark Dataset},
	author       = {Sharafaldin, Iman and Gharib, Amirhossein and Lashkari, Arash Habibi and Ghorbani, Ali A.},
	year         = 2018,
	month        = jan,
	journal      = {Software Networking},
	volume       = 2018,
	number       = 1,
	pages        = {177–200},
	doi          = {10.13052/jsn2445-9739.2017.009},
	issn         = {2445-9739},
	abstractnote = {Towards a Reliable Intrusion Detection Benchmark Dataset}
}
@inproceedings{cipher_benchmark,
	title        = {Survey and Benchmark of Lightweight Block Ciphers for Wireless Sensor Networks},
	year         = 2013,
	booktitle    = {Proceedings of the 10th International Conference on Security and Cryptography},
	publisher    = {SCITEPRESS - Science and and Technology Publications},
	pages        = {543–548},
	doi          = {10.5220/0004530905430548},
	isbn         = {978-989-8565-73-0},
	url          = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0004530905430548},
	place        = {Reykjavík, Iceland}
}
@report{zaber_pkb,
	title        = {Measuring Cloud Network Performance with PerfKit Benchmarker},
	author       = {Derek Phanekham and Matthew Zaber and Suku Nair}
}
@article{Wald_1980,
	title        = {A method of estimating plane vulnerability based on damage of survivors, CRC 432, July 1980},
	author       = {Wald, A.},
	year         = 1980,
	journal      = {Center for Naval Analyses}
}
@article{Rashid_Chivers_Danezis_Lupu_Martin,
	title        = {The Cyber Security Body of Knowledge},
	author       = {Rashid, Awais and Chivers, Howard and Danezis, George and Lupu, Emil and Martin, Andrew},
	pages        = 854,
	note         = {tex.ids: rashidCyberSecurityBodya, rashidCyberSecurityBodyb}
}
@inbook{Bos_2019,
	title        = {The cyber security body of knowledge},
	author       = {Bos, Herbert},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Operating Systems \& Virtualisation}
}
@inbook{Burnap_2019,
	title        = {The cyber security body of knowledge},
	author       = {Burnap, Pete},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Risk Management \& Governance}
}
@inbook{Capkun_2019,
	title        = {The cyber security body of knowledge},
	author       = {Čapkun, Srdjan},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Physical Layer \& Telecommunications}
}
@inbook{Cardenas_2019,
	title        = {The cyber security body of knowledge},
	author       = {Cardenas, Alvaro},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Cyber-Physical Systems Security}
}
@inbook{Carolina_2019,
	title        = {The cyber security body of knowledge},
	author       = {Carolina, Robert},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Law \& Regulation}
}
@inbook{Fahl_2019,
	title        = {The cyber security body of knowledge},
	author       = {Fahl, Sascha},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Web \& Mobile Security}
}
@inbook{Gollmann_2019,
	title        = {The cyber security body of knowledge},
	author       = {Gollmann, Dieter},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Authentication, Authorisation \& Accountability}
}
@inbook{Jha_2019,
	title        = {The cyber security body of knowledge},
	author       = {Jha, Sanjah},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Network Security}
}
@inbook{Lee_2019,
	title        = {The cyber security body of knowledge},
	author       = {Lee, Wenke},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Malware \& Attack Technology}
}
@inbook{Piessens_2019,
	title        = {The cyber security body of knowledge},
	author       = {Piessens, Frank},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Software Security}
}
@inbook{Roussev_2019,
	title        = {The cyber security body of knowledge},
	author       = {Roussev, Vassil},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Forensics}
}
@inbook{Sasse_2019,
	title        = {The cyber security body of knowledge},
	author       = {Sasse, M. Angela},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Human Factors}
}
@inbook{Smart_2019,
	title        = {The cyber security body of knowledge},
	author       = {Smart, Nigel},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Cryptography}
}
@inbook{Stringhini_2019,
	title        = {The cyber security body of knowledge},
	author       = {Stringhini, Gianluca},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Adversarial Behaviours}
}
@inbook{Suri_2019,
	title        = {The cyber security body of knowledge},
	author       = {Suri, Neeraj},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Distributed Systems Security}
}
@inbook{Troncoso_2019,
	title        = {The cyber security body of knowledge},
	author       = {Troncoso, Carmela},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Privacy \& Online Rights}
}
@inbook{Verbauwhede_2019,
	title        = {The cyber security body of knowledge},
	author       = {Verbauwhede, Ingrid},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Hardware Security}
}
@inbook{Williams_2019,
	title        = {The cyber security body of knowledge},
	author       = {Williams, Laurie},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Secure Software Lifecycle}
}
@article{Chew_Swanson_Stine_Bartol_Brown_Robinson_2008,
	title        = {Performance Measurement Guide for Information Security},
	author       = {Chew, Elizabeth and Swanson, Marianne M. and Stine, Kevin M. and Bartol, N. and Brown, Anthony and Robinson, W.},
	year         = 2008,
	month        = {07},
	url          = {https://www.nist.gov/publications/performance-measurement-guide-information-security},
	abstractnote = {This document provides guidance on how an organization, through the use of metrics, identifies the adequacy of in-place security controls, policies, and procedu}
}
@article{iso_27004,
	title        = {ISO/IEC 27004:2016},
	author       = {14:00-17:00},
	journal      = {ISO},
	url          = {http://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/06/41/64120.html},
	abstractnote = {Information technology — Security techniques — Information security management — Monitoring, measurement, analysis and evaluation}
}
@article{cis_cic,
	title        = {CIS Controls V7 Measures \& Metrics},
	journal      = {CIS},
	url          = {https://www.cisecurity.org/white-papers/cis-controls-v7-measures-metrics/},
	abstractnote = {CIS Controls are updated \& reviewed in collaboration with international cybersecurity experts and IT professionals in various industries.}
}
@inbook{Debar_2019,
	title        = {The cyber security body of knowledge},
	author       = {Debar, Hervé},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Security Operations \& Inicident Management}
}
@misc{soss_v9,
	title        = {STATE OF SOFTWARE SECURITY},
	url          = {https://www.veracode.com/sites/default/files/pdf/resources/ipapers/state-of-software-security-volume-9/}
}
@article{Alhazmi_Malaiya_2008,
	title        = {Application of vulnerability discovery models to major operating systems},
	author       = {Alhazmi, Omar H. and Malaiya, Yashwant K.},
	year         = 2008,
	journal      = {IEEE Transactions on Reliability},
	volume       = 57,
	number       = 1,
	pages        = {14–22},
	note         = {tex.ids: alhazmiApplicationVulnerabilityDiscovery2008a, alhazmiApplicationVulnerabilityDiscovery2008b}
}
@inproceedings{Anderson_2001,
	title        = {Why information security is hard-an economic perspective},
	author       = {Anderson, Ross},
	year         = 2001,
	booktitle    = {Seventeenth Annual Computer Security Applications Conference},
	publisher    = {IEEE},
	pages        = {358–365},
	issn         = {null},
	note         = {tex.ids: andersonWhyInformationSecurity2001a, andersonWhyInformationSecurity2001b}
}
@inproceedings{Anderson_Moore_2007,
	title        = {The economics of information security: A survey and open questions},
	author       = {Anderson, Ross and Moore, Tyler},
	year         = 2007,
	booktitle    = {Fourth bi-annual Conference on the Economics of the Software and Internet Industries},
	pages        = {19–20}
}
@article{Bellovin_2006,
	title        = {On the Brittleness of Software and the Infeasibility of Security Metrics},
	author       = {Bellovin, S.M.},
	year         = 2006,
	month        = {07},
	journal      = {IEEE Security \& Privacy Magazine},
	volume       = 4,
	number       = 4,
	pages        = {96–96},
	doi          = {10.1109/MSP.2006.101},
	issn         = {1540-7993},
	note         = {tex.ids: bellovinBrittlenessSoftwareInfeasibility2006a}
}
@article{Bohme_Moore,
	title        = {Security Metrics and Security Investment},
	author       = {Bohme, Rainer and Moore, Tyler},
	year         = 2013,
	pages        = 36
}
@article{Gordon_Loeb,
	title        = {The economics of information security investment},
	author       = {Gordon, Lawrence A and Loeb, Martin P},
	journal      = {ACM Transactions on Information and System Security},
	volume       = 5,
	number       = 4,
	pages        = 20
}
@article{Anderson_Mooreb,
	title        = {Information Security Economics -- and Beyond},
	author       = {Anderson, Ross and Moore, Tyler},
	pages        = 24,
	abstractnote = {The economics of information security has recently become a thriving and fast-moving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, incentives are becoming as important to dependability as technical design. The new ﬁeld provides valuable insights not just into ‘security’ topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of eﬀort by programmers and testers), and policy (particularly digital rights management). This research program has been starting to spill over into more general security questions (such as law-enforcement strategy), and into the interface between security and sociology. Most recently it has started to interact with psychology, both through the psychology-and-economics tradition and in response to phishing. The promise of this research program is a novel framework for analyzing information security problems – one that is both principled and eﬀective.}
}
@article{Anderson_Moore,
	title        = {The Economics of Information Security: A Survey and Open Questions},
	author       = {Anderson, Ross and Moore, Tyler},
	pages        = 27,
	abstractnote = {The economics of information security has recently become a thriving and fastmoving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, we ﬁnd incentives becoming as important to dependability as technical design is. The new ﬁeld provides valuable insights not just into ‘security’ topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of eﬀort by programmers and testers), policy (particularly digital rights management) and more general security questions (such as law-enforcement strategy).}
}
@book{Bell_LaPadula_1973,
	title        = {Secure computer systems: Mathematical foundations (volume 1)},
	author       = {Bell, D. and LaPadula, L.},
	year         = 1973,
	institution  = {Technical Report ESD-TR-73-278, Mitre Corporation}
}
@article{Dhillon_2011,
	title        = {Developer-Driven Threat Modeling: Lessons Learned in the Trenches},
	author       = {Dhillon, Danny},
	year         = 2011,
	month        = {07},
	journal      = {IEEE Security \& Privacy},
	volume       = 9,
	number       = 4,
	pages        = {41–47},
	doi          = {10.1109/MSP.2011.47},
	issn         = {1540-7993}
}
@article{Duggan_Michalski,
	title        = {Threat Analysis Framework},
	author       = {Duggan, David P and Michalski, John T},
	pages        = 31,
	abstractnote = {The need to protect national critical infrastructure has led to the development of a threat analysis framework. The threat analysis framework can be used to identify the elements required to quantify threats against critical infrastructure assets and provide a means of distributing actionable threat information to critical infrastructure entities for the protection of infrastructure assets. This document identifies and describes five key elements needed to perform a comprehensive analysis of threat: the identification of an adversary, the development of generic threat profiles, the identification of generic attack paths, the discovery of adversary intent, and the identification of mitigation strategies.}
}
@article{Ellison,
	title        = {Ceremony Design and Analysis},
	author       = {Ellison, Carl},
	pages        = 17,
	abstractnote = {The concept of ceremony is introduced as an extension of the concept of network protocol, with human nodes alongside computer nodes and with communication links that include UI, human-to-human communication and transfers of physical objects that carry data. What is out-of-band to a protocol is in-band to a ceremony, and therefore subject to design and analysis using variants of the same mature techniques used for the design and analysis of protocols. Ceremonies include all protocols, as well as all applications with a user interface, all workflow and all provisioning scenarios. A secure ceremony is secure against both normal attacks and social engineering. However, some secure protocols imply ceremonies that cannot be made secure.}
}
@article{Hutchins_Cloppert_Amin,
	title        = {Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains},
	author       = {Hutchins, Eric M and Cloppert, Michael J and Amin, Rohan M},
	pages        = 14,
	abstractnote = {Conventional network defense tools such as intrusion detection systems and anti-virus focus on the vulnerability component of risk, and traditional incident response methodology presupposes a successful intrusion. An evolution in the goals and sophistication of computer network intrusions has rendered these approaches insuﬃcient for certain actors. A new class of threats, appropriately dubbed the “Advanced Persistent Threat” (APT), represents well-resourced and trained adversaries that conduct multi-year intrusion campaigns targeting highly sensitive economic, proprietary, or national security information. These adversaries accomplish their goals using advanced tools and techniques designed to defeat most conventional computer network defense mechanisms. Network defense techniques which leverage knowledge about these adversaries can create an intelligence feedback loop, enabling defenders to establish a state of information superiority which decreases the adversary’s likelihood of success with each subsequent intrusion attempt. Using a kill chain model to describe phases of intrusions, mapping adversary kill chain indicators to defender courses of action, identifying patterns that link individual intrusions into broader campaigns, and understanding the iterative nature of intelligence gathering form the basis of intelligence-driven computer network defense (CND). Institutionalization of this approach reduces the likelihood of adversary success, informs network defense investment and resource prioritization, and yields relevant metrics of performance and eﬀectiveness. The evolution of advanced persistent threats necessitates an intelligence-based model because in this model the defenders mitigate not just vulnerability, but the threat component of risk, too.}
}
@book{Morana_2015,
	title        = {Risk centric threat modeling: process for attack simulation and threat analysis},
	author       = {Morana, Marco M. and Uceda Vélez, Tony},
	year         = 2015,
	publisher    = {Wiley},
	isbn         = {978-1-118-98835-0},
	place        = {Hoboken, New Jersey},
	abstractnote = {“This book describes how to apply application threat modeling as an advanced preventive form of security”--}
}
@article{Musman_Turner_2018,
	title        = {A game theoretic approach to cyber security risk management},
	author       = {Musman, Scott and Turner, Andrew},
	year         = 2018,
	month        = {04},
	journal      = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	volume       = 15,
	number       = 2,
	pages        = {127–146},
	doi          = {10.1177/1548512917699724},
	issn         = {1548-5129, 1557-380X},
	abstractnote = {This paper describes the Cyber Security Game (CSG). Cyber Security Game is a method that has been implemented in software that quantitatively identifies cyber security risks and uses this metric to determine the optimal employment of security methods for any given investment level. Cyber Security Game maximizes a system’s ability to operate in today’s contested cyber environment by minimizing its mission risk. The risk score is calculated by using a mission impact model to compute the consequences of cyber incidents and combining that with the likelihood that attacks will succeed. The likelihood of attacks succeeding is computed by applying a threat model to a system topology model and defender model. Cyber Security Game takes into account the widespread interconnectedness of cyber systems, where defenders must defend all multi-step attack paths and an attacker only needs one to succeed. It employs a game theoretic solution using a game formulation that identifies defense strategies to minimize the maximum cyber risk (MiniMax). This paper discusses the methods and models that compose Cyber Security Game . A limited example of a Point of Sale system is used to provide specific demonstrations of Cyber Security Game models and analyses.}
}
@article{Rosenquist,
	title        = {Prioritizing Information Security Risks with Threat Agent Risk Assessment},
	author       = {Rosenquist, Matt},
	pages        = 8
}
@article{Saitta_Larcom_Eddington,
	title        = {Trike v.1 Methodology Document [Draft]},
	author       = {Saitta, Paul and Larcom, Brenda and Eddington, Michael},
	pages        = 17
}
@article{Schneier_1999,
	title        = {Attack trees},
	author       = {Schneier, Bruce},
	year         = 1999,
	journal      = {Dr. Dobb’s journal},
	volume       = 24,
	number       = 12,
	pages        = {21–29},
	note         = {tex.ids: schneierAttackTrees1999a}
}
@article{Schoenfield,
	title        = {Threat Modeling Demystified},
	author       = {Schoenfield, Brook S E},
	pages        = 98
}
@article{Shevchenko,
	title        = {Threat Modeling: A Summary of Available Methods},
	author       = {Shevchenko, Nataliya and Chick, Timothy A and O’Riordan, Paige and Scanlon, Thomas Patrick and Woody, Carol},
	pages        = 26
}
@article{Shostack,
	title        = {Experiences Threat Modeling at Microsoft},
	author       = {Shostack, Adam},
	pages        = 11,
	abstractnote = {Describes a decade of experience threat modeling products and services at Microsoft. Describes the current threat modeling methodology used in the Security Development Lifecycle. The methodology is a practical approach, usable by non-experts, centered on data ﬂow diagrams and a threat enumeration technique of ‘STRIDE per element.’ The paper covers some lessons learned which are likely applicable to other security analysis techniques. The paper closes with some possible questions for academic research.}
}
@inbook{Srivatanakul_Clark_Polack_2004,
	title        = {Effective Security Requirements Analysis: HAZOP and Use Cases},
	author       = {Srivatanakul, Thitima and Clark, John A. and Polack, Fiona},
	year         = 2004,
	booktitle    = {Information Security},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 3225,
	pages        = {416–427},
	doi          = {10.1007/978-3-540-30144-8_35},
	isbn         = {978-3-540-23208-7},
	url          = {http://link.springer.com/10.1007/978-3-540-30144-8_35},
	place        = {Berlin, Heidelberg},
	abstractnote = {Use cases are widely used for functional requirements elicitation. However, security non-functional requirements are often neglected in this requirements analysis process. As systems become increasingly complex current means of analysis will probably prove ineﬀective. In the safety domain a variety of eﬀective analysis techniques have emerged over many years. Since the safety and security domains share many similarities, various authors have suggested that safety techniques might usefully ﬁnd application in security. This paper takes one such technique, HAZOP, and applies it to one widely used functional requirement elicitation component, UML use cases, in order to provide systematic analysis of potential security issues at the start of system development.},
	editor       = {Zhang, Kan and Zheng, YuliangEditors}
}
@article{Sullivan,
	title        = {Chapter 9: Dataflow Diagrams},
	author       = {Sullivan, Louis Henri},
	pages        = 50
}
@book{Woodard_Veitch_Thomas_Duggan_2007,
	title        = {Categorizing threat: building and using a generic threat matrix.},
	author       = {Woodard, Laura and Veitch, Cynthia K. and Thomas, Sherry Reede and Duggan, David Patrick},
	year         = 2007,
	month        = {09},
	number       = {SAND2007-5791, 921121},
	pages        = {SAND2007--5791, 921121},
	doi          = {10.2172/921121},
	url          = {http://www.osti.gov/servlets/purl/921121-o2fi48/}
}
@article{Wynn_Whitmore_Upton_Spriggs_McKinnon_McInnes_Graubart_Clausen,
	title        = {Methodology Description Version 1.0},
	author       = {Wynn, Jackson and Whitmore, Joseph and Upton, Geoff and Spriggs, Lindsay and McKinnon, Dan and McInnes, Richard and Graubart, Richard and Clausen, Lauren},
	pages        = 60
}
@article{Zhu_Rass_2018,
	title        = {Game Theory Meets Network Security: A Tutorial at ACM CCS},
	author       = {Zhu, Quanyan and Rass, Stefan},
	year         = 2018,
	month        = {01},
	journal      = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {2163–2165},
	doi          = {10.1145/3243734.3264421},
	note         = {arXiv: 1808.08066},
	abstractnote = {The increasingly pervasive connectivity of today’s information systems brings up new challenges to security. Traditional security has accomplished a long way toward protecting well-defined goals such as confidentiality, integrity, availability, and authenticity. However, with the growing sophistication of the attacks and the complexity of the system, the protection using traditional methods could be costprohibitive. A new perspective and a new theoretical foundation are needed to understand security from a strategic and decision-making perspective. Game theory provides a natural framework to capture the adversarial and defensive interactions between an attacker and a defender. It provides a quantitative assessment of security, prediction of security outcomes, and a mechanism design tool that can enable security-by-design and reverse the attacker’s advantage. This tutorial provides an overview of diverse methodologies from game theory that includes games of incomplete information, dynamic games, mechanism design theory to offer a modern theoretic underpinning of a science of cybersecurity. The tutorial will also discuss open problems and research challenges that the CCS community can address and contribute with an objective to build a multidisciplinary bridge between cybersecurity, economics, game and decision theory.}
}
@article{Corporation,
	title        = {Structured Threat Information eXpression (STIX™)},
	author       = {Corporation, The MITRE},
	pages        = 18
}
@inproceedings{Beck_2013,
	title        = {Manifesto for Agile Software Development},
	author       = {Beck, Kent M. and Beedle, Mike and Bennekum, Arie van and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andy and Jeffries, Ron and et al.},
	year         = 2013
}
@inproceedings{Johnson_2013,
	title        = {Why don’t software developers use static analysis tools to find bugs?},
	author       = {Johnson, Brittany and Song, Yoonki and Murphy-Hill, Emerson and Bowdidge, Robert},
	year         = 2013,
	month        = {05},
	booktitle    = {2013 35th International Conference on Software Engineering (ICSE)},
	publisher    = {IEEE},
	pages        = {672–681},
	doi          = {10.1109/ICSE.2013.6606613},
	isbn         = {978-1-4673-3076-3},
	url          = {http://ieeexplore.ieee.org/document/6606613/},
	place        = {San Francisco, CA, USA}
}
@inproceedings{Michael_Williams_2007,
	title        = {Toward the Use of Automated Static Analysis Alerts for Early Identification of Vulnerability- and Attack-prone Components},
	author       = {Michael and Williams, Laurie},
	year         = 2007,
	month        = {07},
	booktitle    = {Second International Conference on Internet Monitoring and Protection (ICIMP 2007)},
	publisher    = {IEEE},
	pages        = {18–18},
	doi          = {10.1109/ICIMP.2007.46},
	url          = {https://ieeexplore.ieee.org/document/4271764/},
	place        = {San Jose, CA},
	abstractnote = {Extensive research has shown that software metrics can be used to identify fault- and failure-prone components. These metrics can also give early indications of overall software quality. We seek to parallel the identification and prediction of fault- and failure-prone components in the reliability context with vulnerability- and attack-prone components in the security context. Our research will correlate the quantity and severity of alerts generated by source code static analyzers to vulnerabilities discovered by manual analyses and testing. A strong correlation may indicate that automated static analyzers (ASA), a potentially early technique for vulnerability identification in the development phase, can identify high risk areas in the software system. Based on the alerts, we may be able to predict the presence of more complex and abstract vulnerabilities involved with the design and operation of the software system. An early knowledge of vulnerability can allow software engineers to make informed risk management decisions and prioritize redesign, inspection, and testing efforts. This paper presents our research objective and methodology.}
}
@article{Basili_Briand_Melo_1996,
	title        = {A validation of object-oriented design metrics as quality indicators},
	author       = {Basili, V.R. and Briand, L.C. and Melo, W.L.},
	year         = 1996,
	month        = 10,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 22,
	number       = 10,
	pages        = {751–761},
	doi          = {10.1109/32.544352},
	issn         = {00985589},
	abstractnote = {This paper presents the results of a study conducted at the University of Maryland in which we experimentally investigated the suite of Object-Oriented (OO) design metrics introduced by [Chidamber&Kemerer, 1994]. In order to do this, we assessed these metrics as predictors of fault-prone classes. This study is complementary to [Li&Henry, 1993] where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on experimental results, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber&Kemerer’s OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. We also showed that they are, on our data set, better predictors than “traditional” code metrics, which can only be collected at a later phase of the software development processes.}
}
@inproceedings{Rahman_Williams_2016,
	title        = {Security practices in DevOps},
	author       = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
	year         = 2016,
	booktitle    = {Proceedings of the Symposium and Bootcamp on the Science of Security - HotSos ’16},
	publisher    = {ACM Press},
	pages        = {109–111},
	doi          = {10.1145/2898375.2898383},
	isbn         = {978-1-4503-4277-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2898375.2898383},
	place        = {Pittsburgh, Pennsylvania}
}
@article{Chandramouli_Samarati_Ray_Ray_2018,
	title        = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	author       = {Chandramouli, Ramaswamy and Samarati, Pierangela and Ray, Indrakshi and Ray, Indrajit},
	year         = 2018,
	journal      = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	pages        = {55–77},
	doi          = {https://doi.org/10.1007/978-3-030-04834-1_3},
	abstractnote = {Virtualization is the dominant technology employed in enterprise data centers and those used for offering cloud computing services. This technology has resulted in what is called a virtualized infrastructure.}
}
@inproceedings{Cheng_Deng_Li_DeLoach_Singhal_Ou_2014,
	title        = {Metrics of Security},
	author       = {Cheng, Yi and Deng, Julia and Li, Jason H. and DeLoach, Scott A. and Singhal, Anoop and Ou, Xinming},
	year         = 2014,
	booktitle    = {Cyber Defense and Situational Awareness},
	doi          = {10.1007/978-3-319-11391-3_13},
	abstractnote = {Discussion of challenges and ways of improving Cyber Situational Awareness dominated our previous chapters. However, we have not yet touched on how to quantify any improvement we might achieve. Indeed, to get an accurate assessment of network security and provide sufficient Cyber Situational Awareness (CSA), simple but meaningful metrics—the focus of the Metrics of Security chapter—are necessary. The adage, “what can’t be measured can’t be effectively managed,” applies here. Without good metrics and the corresponding evaluation methods, security analysts and network operators cannot accurately evaluate and measure the security status of their networks and the success of their operations. In particular, this chapter explores two distinct issues: (i) how to define and use metrics as quantitative characteristics to represent the security state of a network, and (ii) how to define and use metrics to measure CSA from a defender’s point of view.}
}
@inproceedings{Cho_Hurley_Xu_2016,
	title        = {Metrics and measurement of trustworthy systems},
	author       = {Cho, Jin-Hee and Hurley, Patrick M. and Xu, Shouhuai},
	year         = 2016,
	month        = nov,
	booktitle    = {MILCOM 2016 - 2016 IEEE Military Communications Conference},
	publisher    = {IEEE},
	pages        = {1237–1242},
	doi          = {10.1109/MILCOM.2016.7795500},
	isbn         = {978-1-5090-3781-0},
	url          = {http://ieeexplore.ieee.org/document/7795500/},
	place        = {Baltimore, MD, USA},
	abstractnote = {Accurate measurement of the quality of systems is crucial to building trustworthy systems. Such a measurement indicates whether a system is working properly and meeting its requirements. Although security and dependability metrics are regarded as key metrics for measuring the quality of systems, they are not sufﬁcient for measuring the quality of systems that are placed in a multi-domain environment including hardware, software, network, human factors, and physical environments. In order to embrace multidimensional aspects of the quality of a system, we introduce a trustworthiness metric framework that supports three key submetrics of trust, resilience, and agility, and propose an ontology-based framework with three corresponding sub-ontologies. We also discuss how the key metrics are related to the severity of threats and the quality of assessment tools. This work is part of the cyber defense effort conducted by the Trustworthy Systems Working Group (TSWG) under the Cyber Strategic Challenge Group (CSCG) of The Technical Cooperation Program (TTCP), which is an international cooperation organization for enhancing defense science and technology.}
}
@inproceedings{DaSilva_Ferreira_deGeus_2012,
	title        = {A methodology for management of cloud computing using security criteria},
	author       = {Da Silva, Carlos Alberto and Ferreira, Anderson Soares and de Geus, Paulo Licio},
	year         = 2012,
	booktitle    = {2012 IEEE Latin America Conference on Cloud Computing and Communications (LatinCloud)},
	publisher    = {IEEE},
	pages        = {49–54}
}
@inbook{deFranco_Rosa_Jino_2017,
	title        = {A Survey of Security Assessment Ontologies},
	author       = {de Franco Rosa, Ferrucio and Jino, Mario},
	year         = 2017,
	booktitle    = {Recent Advances in Information Systems and Technologies},
	publisher    = {Springer International Publishing},
	volume       = 569,
	pages        = {166–173},
	doi          = {10.1007/978-3-319-56535-4_17},
	isbn         = {978-3-319-56534-7},
	url          = {http://link.springer.com/10.1007/978-3-319-56535-4_17},
	place        = {Cham},
	abstractnote = {A literature survey on ontologies concerning the Security Assessment domain has been carried out to uncover initiatives that aim at formalizing concepts from the “Security Assessment” field of research. A preliminary analysis and a discussion on the selected works are presented. Our main contribution is an updated literature review, describing key characteristics, results, research issues, and application domains of the papers. We have also detected gaps in the Security Assessment literature that could be the subject of further studies in the field. This work is meant to be useful for security researchers who wish to adopt a formal approach in their methods.},
	editor       = {Rocha, Álvaro and Correia, Ana Maria and Adeli, Hojjat and Reis, Luís Paulo and Costanzo, SandraEditors}
}
@article{Grubesic_Matisziw_Murray_Snediker_2008a,
	title        = {Comparative approaches for assessing network vulnerability},
	author       = {Grubesic, Tony H. and Matisziw, Timothy C. and Murray, Alan T. and Snediker, Diane},
	year         = 2008,
	journal      = {International Regional Science Review},
	volume       = 31,
	number       = 1,
	pages        = {88–112}
}
@article{Grubesic_Matisziw_Murray_Snediker_2008b,
	title        = {Comparative Approaches for Assessing Network Vulnerability},
	author       = {Grubesic, Tony and Matisziw, Timothy and Murray, Alan and Snediker, Diane},
	year         = 2008,
	month        = jan,
	journal      = {International Regional Science Review - INT REG SCI REV},
	volume       = 31,
	doi          = {10.1177/0160017607308679},
	abstractnote = {A common theme in analysis and evaluation of network-based critical infrastructure is the assessment of system vulnerability. Graph theoretic, simulation, and optimization-based tech-niques have played a significant role in examining potential network vulnerabilities given the insights they can provide for mitigating facility loss and prioritizing fortification efforts. Cen-tral to these approaches is the concept of facility (arc–node) importance or criticality to sys-tem survivability. Assessments of network vulnerability can dramatically differ based on how facility importance is characterized. In this review, various approaches for assessing facility importance and network vulnerability are examined. The key differences in these approaches are the ways in which a facility’s role in maintaining network operability is evaluated given arc–node disruption. Comparative results suggest significant differences exist among mea-sures of facility importance and network performance. Furthermore, the subsequent incon-gruities in these measures and their implications need to be clearly understood to support interdiction risk and vulnerability assessment for critical infrastructures.}
}
@inbook{Kotenko_Doynikova_2014a,
	title        = {Security Assessment of Computer Networks Based on Attack Graphs and Security Events},
	author       = {Kotenko, Igor and Doynikova, Elena},
	year         = 2014,
	booktitle    = {Information and Communication Technology},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 8407,
	pages        = {462–471},
	doi          = {10.1007/978-3-642-55032-4_47},
	isbn         = {978-3-642-55031-7},
	url          = {http://link.springer.com/10.1007/978-3-642-55032-4_47},
	place        = {Berlin, Heidelberg},
	abstractnote = {Security assessment is an important task for operation of modern computer networks. The paper suggests the security assessment technique based on attack graphs which can be implemented in contemporary SIEM systems. It is based on the security metrics taxonomy and different techniques for calculation of security metrics according to the data about current events. Proposed metrics form the basis for security awareness and reflect current security situation, including development of attacks, attacks sources and targets, attackers’ characteristics. The technique suggested is demonstrated on a case study.},
	editor       = {Linawati and Mahendra, Made Sudiana and Neuhold, Erich J. and Tjoa, A Min and You, IlsunEditors}
}
@inbook{Kotenko_Doynikova_2014b,
	title        = {Security Assessment of Computer Networks Based on Attack Graphs and Security Events},
	author       = {Kotenko, Igor and Doynikova, Elena},
	year         = 2014,
	booktitle    = {Information and Communication Technology},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 8407,
	pages        = {462–471},
	doi          = {10.1007/978-3-642-55032-4_47},
	isbn         = {978-3-642-55031-7},
	url          = {http://link.springer.com/10.1007/978-3-642-55032-4_47},
	place        = {Berlin, Heidelberg},
	abstractnote = {Security assessment is an important task for operation of modern computer networks. The paper suggests the security assessment technique based on attack graphs which can be implemented in contemporary SIEM systems. It is based on the security metrics taxonomy and different techniques for calculation of security metrics according to the data about current events. Proposed metrics form the basis for security awareness and reflect current security situation, including development of attacks, attacks sources and targets, attackers’ characteristics. The technique suggested is demonstrated on a case study.},
	editor       = {Linawati and Mahendra, Made Sudiana and Neuhold, Erich J. and Tjoa, A Min and You, IlsunEditors}
}
@inproceedings{Kotenko_Polubelova_Saenko_Doynikova_2013,
	title        = {The Ontology of Metrics for Security Evaluation and Decision Support in SIEM Systems},
	author       = {Kotenko, Igor and Polubelova, Olga and Saenko, Igor and Doynikova, Elena},
	year         = 2013,
	month        = sep,
	pages        = {638–645},
	doi          = {10.1109/ARES.2013.84},
	abstractnote = {Analysis of computer network security is a serious challenge. Many security metrics has been proposed for this purpose, but their effective use for rapid and reliable security evaluation and generation of countermeasures in SIEM systems remains an important problem. The use of ontologies for security information representation in SIEM systems contributes largely to the success of this task. However, most of works on ontological security data representation does not take into account the ontologies of security metrics. This paper proposes a new approach on using security metrics which is based on their ontological representation and serves for comprehensive security evaluation and subsequent countermeasure generation. The novelty of the proposed approach is that ontology of security metrics is viewed as a core component of a countermeasure decision support system. The proposed solutions are tested on a specific example.}
}
@article{Latora_Marchiori_2005,
	title        = {Vulnerability and Protection of Critical Infrastructures},
	author       = {Latora, Vito and Marchiori, Massimo},
	year         = 2005,
	month        = jan,
	journal      = {Physical Review E},
	volume       = 71,
	number       = 1,
	pages        = {015103},
	doi          = {10.1103/PhysRevE.71.015103},
	issn         = {1539-3755, 1550-2376},
	note         = {arXiv: cond-mat/0407491},
	abstractnote = {Critical infrastructure networks are a key ingredient of modern society. We discuss a general method to spot the critical components of a critical infrastructure network, i.e. the nodes and the links fundamental to the perfect functioning of the network. Such nodes, and not the most connected ones, are the targets to protect from terrorist attacks. The method, used as an improvement analysis, can also help to better shape a planned expansion of the network.}
}
@book{Mahalingam_Abdollah_Sahib_2014,
	title        = {Learner Centric in M-Learning: Integration of Security, Dependability and Trust.},
	author       = {Mahalingam, Sheila and Abdollah, Faizal Mohd and Sahib, Shahrin},
	year         = 2014,
	publisher    = {ERIC}
}
@article{Mir_2013,
	title        = {Modeling of Security Measurement Metrics in an Information System},
	author       = {Mir, Irshad Ahmad},
	year         = 2013
}
@article{Azuwa_Ahmad_Sahib_2012,
	title        = {Technical security metrics model in compliance with ISO/IEC 27001 standard},
	author       = {MP Azuwa, Azuwa and Ahmad, Rabiah and Sahib, Sharin},
	year         = 2012,
	journal      = {International Journal of Cyber-Security and Digital Forensics},
	volume       = 1,
	pages        = {280–288}
}
@article{Oltramari_Henshel_Cains_Hoffman,
	title        = {Towards a Human Factors Ontology for Cyber Security},
	author       = {Oltramari, Alessandro and Henshel, Diane and Cains, Mariana and Hoffman, Blaine},
	pages        = 8,
	abstractnote = {Traditional cybersecurity risk assessment is reactive and based on business risk assessment approach. The 2014 NIST Cybersecurity Framework provides businesses with an organizational tool to catalog cybersecurity efforts and areas that need additional support. As part of an on-going effort to develop a holistic, predictive cyber security risk assessment model, the characterization of human factors, which includes human behavior, is needed to understand how the actions of users, defenders (IT personnel), and attackers affect cybersecurity risk. Trust has been found to be a crucial element affecting an individual’s role within a cyber system. The use of trust as a human factor in holistic cybersecurity risk assessment relies on an understanding how differing mental models, risk postures, and social biases impact the level trust given to an individual and the biases affecting the ability to give said trust. The Human Factors Ontology illustrates the individual characteristics, situational characteristics, and relationships that influence the trust given to an individual. Furthering the incorporation of ontologies into the science of cybersecurity will help decision-makers build the foundation needed for predictive and quantitative risk assessments.}
}
@article{Payne_2007,
	title        = {A Guide to Security Metrics},
	author       = {Payne, Shirley},
	year         = 2007,
	pages        = 11
}
@article{Pendleton_Garcia-Lebron_Cho_Xu_2016,
	title        = {A Survey on Systems Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Cho, Jin-Hee and Xu, Shouhuai},
	year         = 2016,
	month        = 12,
	journal      = {ACM Computing Surveys},
	volume       = 49,
	number       = 4,
	pages        = {1–35},
	doi          = {10.1145/3005714},
	issn         = {03600300}
}
@article{Pendleton_Garcia-Lebron_Xu_2016,
	title        = {A Survey on Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Xu, Shouhuai},
	year         = 2016,
	month        = jan,
	journal      = {arXiv:1601.05792 [cs]},
	url          = {http://arxiv.org/abs/1601.05792},
	note         = {arXiv: 1601.05792},
	abstractnote = {The importance of security metrics can hardly be overstated. Despite the attention that has been paid by the academia, government and industry in the past decades, this important problem stubbornly remains open. In this survey, we present a survey of knowledge on security metrics. The survey is centered on a novel taxonomy, which classifies security metrics into four categories: metrics for measuring the system vulnerabilities, metrics for measuring the defenses, metrics for measuring the threats, and metrics for measuring the situations. The insight underlying the taxonomy is that situations (or outcomes of cyber attack-defense interactions) are caused by certain threats (or attacks) against systems that have certain vulnerabilities (including human factors) and employ certain defenses. In addition to systematically reviewing the security metrics that have been proposed in the literature, we discuss the gaps between the state of the art and the ultimate goals.}
}
@article{Ramos_Lazar_Filho_Rodrigues_2017,
	title        = {Model-Based Quantitative Network Security Metrics: A Survey},
	author       = {Ramos, Alex and Lazar, Marcella and Filho, Raimir Holanda and Rodrigues, Joel J. P. C.},
	year         = 2017,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 19,
	number       = 4,
	pages        = {2704–2734},
	doi          = {10.1109/COMST.2017.2745505},
	issn         = {2373-745X},
	abstractnote = {Network security metrics (NSMs) based on models allow to quantitatively evaluate the overall resilience of networked systems against attacks. For that reason, such metrics are of great importance to the security-related decision-making process of organizations. Considering that over the past two decades several model-based quantitative NSMs have been proposed, this paper presents a deep survey of the state-of-the-art of these proposals. First, to distinguish the security metrics described in this survey from other types of security metrics, an overview of security metrics, in general, and their classifications is presented. Then, a detailed review of the main existing model-based quantitative NSMs is provided, along with their advantages and disadvantages. Finally, this survey is concluded with an in-depth discussion on relevant characteristics of the surveyed proposals and open research issues of the topic.}
}
@article{Tariq_2012,
	title        = {Towards information security metrics framework for cloud computing},
	author       = {Tariq, Muhammad Imran},
	year         = 2012,
	journal      = {International Journal of Cloud Computing and Services Science},
	volume       = 1,
	number       = 4,
	pages        = 209
}
@inproceedings{Verendel_2009,
	title        = {Quantified security is a weak hypothesis: a critical survey of results and assumptions},
	author       = {Verendel, Vilhelm},
	year         = 2009,
	booktitle    = {Proceedings of the 2009 workshop on New security paradigms workshop - NSPW ’09},
	publisher    = {ACM Press},
	pages        = 37,
	doi          = {10.1145/1719030.1719036},
	isbn         = {978-1-60558-845-2},
	url          = {http://portal.acm.org/citation.cfm?doid=1719030.1719036},
	place        = {Oxford, United Kingdom},
	abstractnote = {This paper critically surveys previous work on quantitative representation and analysis of security. Such quantiﬁed security has been presented as a general approach to precisely assess and control security. We classify a signiﬁcant part of the work between 1981 and 2008 with respect to security perspective, target of quantiﬁcation, underlying assumptions and type of validation. The result shows how the validity of most methods is still strikingly unclear. Despite applying a number of techniques from ﬁelds such as computer science, economics and reliability theory to the problem it is unclear what valid results exist with respect to operational security. Quantiﬁed security is thus a weak hypothesis because a lack of validation and comparison between such methods against empirical data. Furthermore, many assumptions in formal treatments are not empirically well-supported in operational security and have been adopted from other ﬁelds. A number of risks are present with depending on quantitative methods with limited or no validation.}
}
@article{attacktrees.pdf,
	url          = {http://tnlandforms.us/cs594-cns96/attacktrees.pdf}
}
@article{SEv2-c21.pdf,
	url          = {https://www.cl.cam.ac.uk/~rja14/Papers/SEv2-c21.pdf}
}
@book{Mell_Scarfone_Romanosky_2007,
	title        = {The common vulnerability scoring system (CVSS) and its applicability to federal agency systems},
	author       = {Mell, Peter and Scarfone, Karen and Romanosky, Sasha},
	year         = 2007,
	number       = {NIST IR 7435},
	pages        = {NIST IR 7435},
	doi          = {10.6028/NIST.IR.7435},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nistir7435.pdf},
	place        = {Gaithersburg, MD},
	abstractnote = {The Common Vulnerability Scoring System (CVSS) provides an open framework for communicating the characteristics and impacts of IT vulnerabilities. The National Vulnerability Database (NVD) provides specific CVSS scores for publicly known vulnerabilities. Federal agencies can use the Federal Information Processing Standards (FIPS) 199 security categories with the NVD CVSS scores to obtain impact scores that are tailored to each agency’s environment. CVSS consists of three groups: Base, Temporal and Environmental. Each group produces a numeric score ranging from 0.0 to 10.0, and a vector, a compressed textual representation that reflects the values used to derive the score. The Base group represents the intrinsic qualities of a vulnerability. The Temporal group reflects the characteristics of a vulnerability that change over time. The Environmental group represents the characteristics of a vulnerability that are unique to any user’s environment. CVSS enables IT managers, vulnerability bulletin providers, security vendors, application vendors and researchers to all benefit by adopting this common language of scoring IT vulnerabilities.},
	institution  = {National Institute of Standards and Technology}
}
@article{Almasizadeh_Azgomi_2013,
	title        = {A stochastic model of attack process for the evaluation of security metrics},
	author       = {Almasizadeh, Jaafar and Azgomi, Mohammad Abdollahi},
	year         = 2013,
	month        = jul,
	journal      = {Computer Networks},
	series       = {Towards a Science of Cyber Security},
	volume       = 57,
	number       = 10,
	pages        = {2159–2180},
	doi          = {10.1016/j.comnet.2013.03.011},
	issn         = {1389-1286},
	abstractnote = {To trust a computer system that is supposed to be secure, it is necessary to predict the degree to which the system’s security level can be achieved when operating in a specific environment under cyber attacks. In this paper, we propose a state-based stochastic model for obtaining quantitative security metrics representing the level of a system’s security. The main focus of the study is on how to model the progression of an attack process over time. The basic assumption of our model is that the time parameter plays the essential role in capturing the nature of an attack process. In practice, the attack process will terminate successfully, possibly after a number of unsuccessful attempts. What is important is, indeed, the estimation of how long it takes to be conducted. The proposed stochastic model is parameterized based on a suitable definition of time distributions describing attacker’s actions and system’s reactions over time. For this purpose, probability distribution functions are defined and assigned to transitions of the model for characterizing the temporal aspects of the attacker and system behavior. With the definition of the distributions, the stochastic model will be recognized to be a semi-Markov chain. This mathematical model will be analytically solved to calculate the desirable quantitative security metrics, such as mean time to security failure and steady-state security. The proposed method shows a systematic development of the stochastic modeling techniques and concepts, used frequently in the area of dependability evaluation, for attack process modeling. Like any other modeling method, the proposed model is also constructed based on some underlying assumptions, which are specific to the context of security analysis.},
	collection   = {Towards a Science of Cyber Security}
}
@article{Jha_Sheyner_Wing,
	title        = {Minimization and Reliability Analyses of Attack Graphs},
	author       = {Jha, Somesh and Sheyner, Oleg and Wing, Jeannette M},
	pages        = 31
}
@inproceedings{Kanoun_Cuppens_Boulahia_Cuppens_Dubus_Martin_2009,
	title        = {Success Likelihood of Ongoing Attacks for Intrusion Detection and Response Systems},
	author       = {Kanoun, Wael and Cuppens-Boulahia, Nora and Cuppens, Frédéric and Dubus, Samuel and Martin, Antony},
	year         = 2009,
	month        = aug,
	booktitle    = {2009 International Conference on Computational Science and Engineering},
	volume       = 3,
	pages        = {83–91},
	doi          = {10.1109/CSE.2009.233},
	issn         = {null},
	abstractnote = {Intrusion Detection and Response Systems have become a core component in modern security architectures. Current researches are combining intrusion detection and response systems with risk analysis or cost-sensitive approaches to enhance the detection and the response procedure, by assessing the risk of detected attacks and candidate countermeasures. The Risk has two primary dimensions: (i) the likelihood of success of the attack(s), and (ii) the impact of the attack(s) and the countermeasure(s).In this paper, we present a model to assess the success likelihood of attack objectives. This model can be used by intrusion detection and response systems to identify candidate ongoing scenarios, calculate dynamically the likelihood of success for each of them considering the progress of the attack and the state of the target system, and finally prioritize candidate intrusion objectives and associated countermeasures.}
}
@article{Li_Parker_Xu_2011,
	title        = {A Stochastic Model for Quantitative Security Analyses of Networked Systems},
	author       = {Li, Xiaohu and Parker, Paul and Xu, Shouhuai},
	year         = 2011,
	month        = mar,
	journal      = {IEEE Transactions on Dependable and Secure Computing; Washington},
	volume       = 8,
	number       = 1,
	pages        = {28–43},
	doi          = {http://dx.doi.org/10.1109/TDSC.2008.75},
	issn         = 15455971,
	abstractnote = {Traditional security analyses are often geared toward cryptographic primitives or protocols. Although such analyses are necessary, they cannot address a defender’s need for insight into which aspects of a networked system having a significant impact on its security, and how to tune its configurations or parameters so as to improve security. This question is known to be notoriously difficult to answer, and the state of the art is that we know little about it. Toward ultimately addressing this question, this paper presents a stochastic model for quantifying security of networked systems. The resulting model captures two aspects of a networked system: 1. the strength of deployed security mechanisms such as intrusion detection systems and 2. the underlying vulnerability graph, which reflects how attacks may proceed. The resulting model brings the following insights: 1. How should a defender tune system configurations (e.g., network topology) so as to improve security? 2).How should a defender “tune” system parameters (e.g., by upgrading which security mechanisms) so as to improve security? 3. Under what conditions is the steady-state number of compromised entities of interest below a given threshold with a high probability? Simulation studies are conducted to confirm the analytic results, and to show the tightness of the bounds of certain important metric that cannot be resolved analytically.}
}
@book{Morris_2001,
	title        = {Measurement and instrumentation principles},
	author       = {Morris, Alan S.},
	year         = 2001,
	publisher    = {Butterworth-Heinemann},
	isbn         = {978-0-7506-5081-6},
	place        = {Oxford [England] ; Boston}
}
@article{Debievre_2009,
	title        = {The 2007 International Vocabulary of Metrology (VIM), JCGM 200:2008 [ISO/IEC Guide 99]: Meeting the need for intercontinentally understood concepts and their associated intercontinentally agreed terms},
	author       = {De Bièvre, Paul},
	year         = 2009,
	month        = mar,
	journal      = {Clinical Biochemistry},
	series       = {Highlight Section: Quality \& Accreditation in Laboratory Medicine},
	volume       = 42,
	number       = 4,
	pages        = {246–248},
	doi          = {10.1016/j.clinbiochem.2008.09.007},
	issn         = {0009-9120},
	abstractnote = {Unambiguous and consistent concepts and terms such as measurand, metrological traceability, measurement uncertainty, comparability of measurement results, target measurement uncertainty, etc., must govern the description of measurements in order to enable a valid comparison of measurement results. That is not yet the case as numerous workshops over the last decade have shown worldwide and as chemical literature continuously displays. For international trade in food and feed to be fair, for border-crossing implementation of environmental regulations to be the same for all parties concerned, for interchangeability of results of clinical measurements to become a reality, for any border-crossing interpretation of measurement results in chemistry to become possible, well understood and mutually accepted, common and well defined concepts and terms are essential. Similarly, their translations from one language – English – to 30–40 other languages, must be realized and fixed unequivocally. Countries using English as common language have not yet fully realized that they are at a considerable advantage over countries where such translated terms describing concepts may not yet be available, let alone understood and accepted. A number of ambiguities in the definitions and terms are described which illustrate the importance of the revision (1997–2007) of the International Vocabulary of Metrology (VIM), henceforth conveniently called “VIM3”, especially since chemical measurement is covered in this VIM for the first time in history:‘measurand’‘metrological comparability of measurement results’‘metrology’‘metrological compatibility of measurement results’‘measurement result’‘metrological traceability’ (incl ‘to the SI’)‘measurement uncertainty’‘target measurement uncertainty’‘calibration hierarchy’‘quantity’and many others. It is concluded that the revised VIM is of primordial importance for good understanding within and between the measurement communities worldwide.},
	collection   = {Highlight Section: Quality & Accreditation in Laboratory Medicine}
}
@article{Schneider,
	title        = {Blueprint for a Science of Cybersecurity},
	author       = {Schneider, Fred B},
	pages        = 17
}
@inbook{Kott_2014,
	title        = {Towards fundamental science of cyber security},
	author       = {Kott, Alexander},
	year         = 2014,
	booktitle    = {Network science and cybersecurity},
	publisher    = {Springer},
	pages        = {1–13}
}
@inproceedings{Spring_Moore_Pym_2017,
	title        = {Practicing a Science of Security: A Philosophy of Science Perspective},
	author       = {Spring, Jonathan M. and Moore, Tyler and Pym, David},
	year         = 2017,
	booktitle    = {Proceedings of the 2017 New Security Paradigms Workshop on ZZZ - NSPW 2017},
	publisher    = {ACM Press},
	pages        = {1–18},
	doi          = {10.1145/3171533.3171540},
	isbn         = {978-1-4503-6384-6},
	url          = {http://dl.acm.org/citation.cfm?doid=3171533.3171540},
	place        = {Santa Cruz, CA, USA},
	abstractnote = {Our goal is to refocus the question about cybersecurity research from ‘is this process scienti c’ to ‘why is this scienti c process producing unsatisfactory results’. We focus on ve common complaints that claim cybersecurity is not or cannot be scienti c. Many of these complaints presume views associated with the philosophical school known as Logical Empiricism that more recent scholarship has largely modi ed or rejected. Modern philosophy of science, supported by mathematical modeling methods, provides constructive resources to mitigate all purported challenges to a science of security. Therefore, we argue the community currently practices a science of cybersecurity. A philosophy of science perspective suggests the following form of practice: structured observation to seek intelligible explanations of phenomena, evaluating explanations in many ways, with specialized elds (including engineering and forensics) constraining explanations within their own expertise, intertranslating where necessary. A natural question to pursue in future work is how collecting, evaluating, and analyzing evidence for such explanations is di erent in security than other sciences.}
}
@article{Evans_2008,
	title        = {NSF/IARPA/NSA Workshop on the Science of Security},
	author       = {Evans, D.},
	year         = 2008,
	journal      = {Also see http://sos. cs. virginia. edu/., University of Virginia}
}
@article{Yamin_Katt_Gkioulos_2020,
	title        = {Cyber ranges and security testbeds: Scenarios, functions, tools and architecture},
	author       = {Yamin, Muhammad Mudassar and Katt, Basel and Gkioulos, Vasileios},
	year         = 2020,
	month        = jan,
	journal      = {Computers \& Security},
	volume       = 88,
	pages        = 101636,
	doi          = {10.1016/j.cose.2019.101636},
	issn         = {0167-4048},
	abstractnote = {The first line of defense against cyber threats and cyber crimes is to be aware and get ready, e.g., through cyber security training. Training can have two forms, the first is directed towards security professionals and aims at improving understanding of the latest threats and increasing skill levels in defending and mitigating against them. The second form of training, which used to attract less attention, aims at increasing cyber security awareness among non-security professionals and the general public. Conducting such training programs requires dedicated testbeds and infrastructures that help realizing and executing the training scenarios and provide a playground for the trainees. A cyber range is an environment that aims at providing such testbeds. The purpose of this paper is to study the concept of a cyber range, and provide a systematic literature review that covers unclassified cyber ranges and security testbeds. In this study we develop a taxonomy for cyber range systems and evaluate the current literature focusing on architecture and scenarios, but including also capabilities, roles, tools and evaluation criteria. The results of this study can be used as a baseline for future initiatives towards the development and evaluation of cyber ranges in accordance with existing best practices and lessons learned from contemporary research and developments.}
}
@article{Sonmez_2019,
	title        = {A Conceptual Model for a Metric Based Framework for the Monitoring of Information Security Tasks’ Efficiency},
	author       = {Sönmez, Ferda Özdemir},
	year         = 2019,
	journal      = {Procedia Computer Science},
	volume       = 160,
	pages        = {181–188},
	doi          = {10.1016/j.procs.2019.09.459},
	issn         = 18770509,
	abstractnote = {Abstract Information Security Governance Systems are not adequate to measure the effectiveness and efficiency of security tIansfkosrmfoartitohne SenecteurrpitryiseGso. vAelrtnhaonucgehSsyosmteemosf athre nsyostteamdesqoufafteertwo amyseafsourrme tehaesuerfefmecetnivt,entheesys satnildl nefefeidciethnecydeoffinsieticounriotyf mtasekasufroermtheentenotbejrepcrtiisveess. Aanltdhomugehtriscosm. Tehoifs thsteusdyystpermops oosfefserawcaoynscfeoprtumaelafsruarmemewenotr,kthmeyodsetillwnheiecdh thaesdhefuimniatinonanodf tmooeal/spurroecmesesntreolabtjedctimvestriacns.d Tmhiestrsicyss.teTmhiaslssotuadlylowprsopthoesecsolaleccotinocnepotfuaelvifdreanmceewdoartka mfoor dseecwurhitiych-rehlastedhutmasakns and twoaoyl/sprtocmesostirvealatetetdhemseetcriucrsi.tyTshtiasffsytostepmrovaildsoe allmoworse tphreodcuolclteivcteioennvoifroenvmideenntc.eTdhaistasyfosrtesmecmuraityyb-reelaptepdlietadsktos aannyd swizaeysoftoenmteortpivriaste itnhdeespeecnudreitnyt sotfaiftfstboupsrinoevsidsedoammaoinreoprrfoudnucctitoivnes eansvliornognmasentht.eTahimis issytsoteimmpmroavyebteheapepfflieecdtivtoenaensys asinzde eofffiecnietenrcpyriosfe siencduerpiteyn-drenlatteodf ittasskbsu.siness domain or functions as long as the aim is to improve the effectiveness and efficiency of security-related tasks.}
}
@inproceedings{Haque_Keffeler_Atkison_2017,
	title        = {An Evolutionary Approach of Attack Graphs and Attack Trees: A Survey of Attack Modeling},
	author       = {Haque, S. and Keffeler, M. and Atkison, T.},
	year         = 2017,
	booktitle    = {Proceedings of the International Conference on Security and Management (SAM); Athens},
	publisher    = {The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp)},
	pages        = {224–229},
	url          = {https://search.proquest.com/docview/2139471619/abstract/7169E9EF244F4076PQ/1},
	place        = {Athens, United States, Athens},
	abstractnote = {The advancement of modern day computing has led to an increase of threats and intrusions. As a result, advanced security measures and threat analysis models are necessary to detect these threats and identify protective measures needed to secure a system. The most popular forms of attack modeling today are attack graphs and attack trees. This literature summarizes the different approaches through an extensive survey of the relevant papers and identifies the current challenges, requirements and limitations of efficient attack modeling.}
}
@inproceedings{Kundu_Ghosh_Chokshi_Ghosh_2012,
	title        = {Analysis of attack graph-based metrics for quantification of network security},
	author       = {Kundu, A. and Ghosh, N. and Chokshi, I. and Ghosh, S. K.},
	year         = 2012,
	month        = dec,
	booktitle    = {2012 Annual IEEE India Conference (INDICON)},
	pages        = {530–535},
	doi          = {10.1109/INDCON.2012.6420675},
	abstractnote = {Computer network has grown both in size and complexity with the advent of Internet. It facilitates easy access to vast store of reference materials, collaborative computing, and information sharing. However, this requires a secure interconnected world of computing where confidentiality, integrity, and availability of information and resources are restored. Traditionally, security mechanism is enforced by access control and authentication. However, these security best practices do not take operating system, or network service-based or application vulnerabilities (programming flaws) into account. With the evolution of sophisticated hacking tools, attackers exploit these vulnerabilities and can gain legitimate access to network resources, bypassing the access control and authentication policies. One tool that presents a succinct representation of different attack scenarios specific to a network is attack graph. Attack graph models service or application-based attacks and depicts all possible multihost multi-step attack scenarios that an attacker can launch to penetrate into an enterprise network. The severity associated with each attack scenario can be evaluated following some attack graph-based security metrics. A good number of security metrics are prevalent in the literature, however, there exists no reported work which determines their efficacy and applicability. In this paper, a survey on attack graph-based metrics has been done and comparative analysis of the existing metrics has been presented to facilitate understanding of a given network’s level of security strength. A case study has been perceived for the purpose of analysis.}
}
@inbook{Bohme_Nowey_2008,
	title        = {Economic Security Metrics},
	author       = {Böhme, Rainer and Nowey, Thomas},
	year         = 2008,
	booktitle    = {Dependability Metrics},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 4909,
	pages        = {176–187},
	doi          = {10.1007/978-3-540-68947-8_15},
	isbn         = {978-3-540-68946-1},
	url          = {http://link.springer.com/10.1007/978-3-540-68947-8_15},
	place        = {Berlin, Heidelberg},
	abstractnote = {This chapter surveys economic approaches for security metrics, among which we could identify two main areas of research. One has its roots in investment and decision theory and is mainly pursued in the ﬁeld of information technology-oriented business administration. It has yielded a number of quantitative metrics that can be applied as guidelines in investment decisions as well as for the evaluation of existing security measures. The second area of research has ancestors in micro-economics. It deals with market concepts to gather security-relevant information and extract quantitative indicators on information security properties.},
	editor       = {Eusgeld, Irene and Freiling, Felix C. and Reussner, RalfEditors}
}
@inproceedings{Hecker_2008,
	title        = {On System Security Metrics and the Definition Approaches},
	author       = {Hecker, Artur},
	year         = 2008,
	month        = aug,
	booktitle    = {2008 Second International Conference on Emerging Security Information, Systems and Technologies},
	pages        = {412–419},
	doi          = {10.1109/SECURWARE.2008.37},
	issn         = {2162-2116},
	abstractnote = {In this survey paper, we assess existing approaches to security metric definition. We classify proposed definitions and discuss their advantages and problems. We argue that without a more restrictive definition, the apparently common term degenerates to a mere buzzword, which can be dangerous in terms of suggested comparability. We conclude with some guidelines on IS metric definition and sketch an alternative concept for the operational IS security evaluation.}
}
@article{Savola_2013,
	title        = {Quality of security metrics and measurements},
	author       = {Savola, Reijo M.},
	year         = 2013,
	month        = {09},
	journal      = {Computers \& Security},
	volume       = 37,
	pages        = {78–90},
	doi          = {10.1016/j.cose.2013.05.002},
	issn         = {0167-4048},
	abstractnote = {Quantification of information security can be used to obtain evidence to support decision-making about the security performance of software systems. Knowledge about the relational importance of the main quality criteria of security metrics can help build security metrology models based on practical needs. This paper presents the results of a quantitative security metrics expert survey of 141 respondents, and an associated interview study, regarding the prioritization of 19 quality criteria of security metrics identified in the literature. The interviews were used to validate the survey results and to obtain further information on the findings. The results identified three foundational quality criteria of security metrics: correctness, measurability, and meaningfulness. These criteria form the basis for credibility and sufficiency for security metrics and associated measurements. Moreover, usability was seen as an important criterion. The paper analyzes the foundational and related quality criteria and proposes a model of them.}
}
@article{Rudolph_Schwarz_2012,
	title        = {Security indicators–a state of the art survey public report},
	author       = {Rudolph, Manuel and Schwarz, Reinhard},
	year         = 2012,
	journal      = {FhG IESE VII (043)}
}
@inproceedings{survey_2013,
	year         = 2013,
	booktitle    = {Proceedings of the 10th International Conference on Security and Cryptography},
	publisher    = {SCITEPRESS - Science and and Technology Publications},
	pages        = {543–548},
	doi          = {10.5220/0004530905430548},
	isbn         = {978-989-8565-73-0},
	url          = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0004530905430548},
	place        = {Reykjavík, Iceland}
}
@article{Wagner_Eckhoff_2018,
	title        = {Technical Privacy Metrics: A Systematic Survey},
	author       = {Wagner, Isabel and Eckhoff, David},
	year         = 2018,
	month        = {06},
	journal      = {ACM Computing Surveys},
	volume       = 51,
	number       = 3,
	pages        = {1–38},
	doi          = {10.1145/3168389},
	issn         = {03600300}
}
@article{Tavallaee_Stakhanova_Ghorbani_2010,
	title        = {Toward Credible Evaluation of Anomaly-Based Intrusion-Detection Methods},
	author       = {Tavallaee, Mahbod and Stakhanova, Natalia and Ghorbani, Ali Akbar},
	year         = 2010,
	month        = {09},
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume       = 40,
	number       = 5,
	pages        = {516–524},
	doi          = {10.1109/TSMCC.2010.2048428},
	issn         = {1094-6977, 1558-2442},
	abstractnote = {Since the ﬁrst introduction of anomaly-based intrusion detection to the research community in 1987, the ﬁeld has grown tremendously. A variety of methods and techniques introducing new capabilities in detecting novel attacks were developed. Most of these techniques report a high detection rate of 98\% at the low false alarm rate of 1\%. In spite of the anomaly-based approach’s appeal, the industry generally favors signature-based detection for mainstream implementation of intrusion-detection systems. While a variety of anomaly-detection techniques have been proposed, adequate comparison of these methods’ strengths and limitations that can lead to potential commercial application is difﬁcult. Since the validity of experimental research in academic computer science, in general, is questionable, it is plausible to assume that research in anomaly detection shares the above problem. The concerns about the validity of these methods may partially explain why anomaly-based intrusion-detection methods are not adopted by industry. To investigate this issue, we review the current state of the experimental practice in the area of anomaly-based intrusion detection and survey 276 studies in this area published during the period of 2000–2008. We summarize our observations and identify the common pitfalls among surveyed works.}
}
@inproceedings{Savola_2007,
	title        = {Towards a Security Metrics Taxonomy for the Information and Communication Technology Industry},
	author       = {Savola, Reijo},
	year         = 2007,
	month        = {08},
	booktitle    = {International Conference on Software Engineering Advances (ICSEA 2007)},
	pages        = {60–60},
	doi          = {10.1109/ICSEA.2007.79},
	issn         = {null},
	abstractnote = {To obtain evidence of the security of different products or organizations, systematic approaches to measuring security are needed. We introduce a high abstraction level taxonomy to support the development of feasible security metrics, along with a survey of the emerging security metrics from the academic, governmental and industrial perspectives. With our taxonomy, we strive to bridge the gap between information security management and ICT products, and services security engineering. We believe that if common metrics approaches between different security disciplines can be found, this will advance our holistic understanding and capabilities, both in security management and engineering. Our taxonomy is based on comparing earlier taxonomy approaches and analyzing types of security metrics. Based on the survey, a discussion of future research directions is given in order to prompt advances in the field.}
}
@inproceedings{Chawla_Lazarevic_Hall_Bowyer_2003,
	title        = {SMOTEBoost: Improving prediction of the minority class in boosting},
	author       = {Chawla, Nitesh V. and Lazarevic, Aleksandar and Hall, Lawrence O. and Bowyer, Kevin W.},
	year         = 2003,
	booktitle    = {European Conference on Principles of Data Mining and Knowledge Discovery},
	publisher    = {Springer},
	pages        = {107–119},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-39804-2_12}
}
@inbook{Isaksson_Dunham_Hahsler_2012,
	title        = {SOStream: Self Organizing Density-Based Clustering over Data Stream},
	author       = {Isaksson, Charlie and Dunham, Margaret H. and Hahsler, Michael},
	year         = 2012,
	booktitle    = {Machine Learning and Data Mining in Pattern Recognition},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 7376,
	pages        = {264–278},
	isbn         = {978-3-642-31536-7},
	url          = {http://link.springer.com/10.1007/978-3-642-31537-4_21},
	place        = {Berlin, Heidelberg},
	editor       = {Perner, PetraEditor}
}
@inproceedings{Kang_Hauswald_Gao_Rovinski_Mudge_Mars_Tang_2017,
	title        = {Neurosurgeon: Collaborative intelligence between the cloud and mobile edge},
	author       = {Kang, Yiping and Hauswald, Johann and Gao, Cao and Rovinski, Austin and Mudge, Trevor and Mars, Jason and Tang, Lingjia},
	year         = 2017,
	booktitle    = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher    = {ACM},
	pages        = {615–629}
}
@article{King_Zeng_2001,
	title        = {Logistic regression in rare events data},
	author       = {King, Gary and Zeng, Langche},
	year         = 2001,
	journal      = {Political analysis},
	volume       = 9,
	number       = 2,
	pages        = {137–163}
}
@article{Kingma_Ba_2014,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik and Ba, Jimmy},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.6980},
	url          = {https://arxiv.org/abs/1412.6980}
}
@article{LeCun_Bengio_Hinton_2015,
	title        = {Deep learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	month        = {05},
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436–444},
	doi          = {10.1038/nature14539},
	issn         = {0028-0836},
	abstractnote = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}
@inproceedings{Maclaurin_Duvenaud_Adams_2015,
	title        = {Gradient-based Hyperparameter Optimization through Reversible Learning.},
	author       = {Maclaurin, Dougal and Duvenaud, David K. and Adams, Ryan P.},
	year         = 2015,
	booktitle    = {ICML},
	pages        = {2113–2122},
	url          = {http://www.jmlr.org/proceedings/papers/v37/maclaurin15.pdf}
}
@article{Snoek_Larochelle_Adams_2012,
	title        = {Practical Bayesian Optimization of Machine Learning Algorithms},
	author       = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	year         = 2012,
	month        = {06},
	journal      = {arXiv:1206.2944 [cs, stat]},
	url          = {http://arxiv.org/abs/1206.2944},
	note         = {arXiv: 1206.2944},
	abstractnote = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a “black art” that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.}
}
@article{Snoek_Rippel_Swersky_Kiros_Satish_Sundaram_Patwary_Prabhat_Adams_2015,
	title        = {Scalable Bayesian Optimization Using Deep Neural Networks},
	author       = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
	year         = 2015,
	month        = {02},
	journal      = {arXiv:1502.05700 [stat]},
	url          = {http://arxiv.org/abs/1502.05700},
	note         = {arXiv: 1502.05700},
	abstractnote = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}
@article{Boutaba_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
@article{Buczak_Guven_2016,
	title        = {A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection},
	author       = {Buczak, Anna L. and Guven, Erhan},
	year         = 2016,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 18,
	number       = 2,
	pages        = {1153–1176},
	doi          = {10.1109/COMST.2015.2494502},
	issn         = {2373-745X},
	abstractnote = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@book{ml_telecom_med,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	place        = {Washington, D.C.},
	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
}
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker’s goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM ’18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network’s normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices’ context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks’ Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the ﬁeld of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE—a fast, scalable, and effective model, whose single-thread version is 10–400× faster than efﬁcient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE ﬁrst initializes network embeddings efﬁciently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and signiﬁcant efﬁciency superiority when compared to the aforementioned baselines. In addition, ProNE’s embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
@article{journa_1,
	volume       = 2,
	number       = 2,
	pages        = 6,
	abstractnote = {An intrusion detection system is software that monitors a single or a network of computers for malicious activities that are aimed at stealing or censoring information or corrupting network protocols. Most technique used in today’s intrusion detection system are not able to deal with the dynamic and complex nature of cyber-attacks on computer networks. Even though efficient adaptive methods like various techniques of machine learning can result in higher detection rates, lower false alarm rates and reasonable computation and communication cost. With the use of data mining can result in frequent pattern mining, classification, clustering and mini data stream. This survey paper describes a focused literature survey of machine learning and data mining methods for cyber analytics in support of intrusion detection. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in machine learning and data mining approaches, some well-known cyber data sets used in machine learning and data mining are described for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@article{Denker,
	title        = {Large Automatic Learning, Rule Extraction, and Generalization},
	author       = {Denker, John},
	pages        = 46
}
@book{Sutton_Barto_2018,
	title        = {Reinforcement learning: an introduction},
	author       = {Sutton, Richard S. and Barto, Andrew G.},
	year         = 2018,
	publisher    = {The MIT Press},
	series       = {Adaptive computation and machine learning series},
	isbn         = {978-0-262-03924-6},
	place        = {Cambridge, Massachusetts},
	edition      = {Second edition},
	abstractnote = {“Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field’s key ideas and algorithms.”--},
	collection   = {Adaptive computation and machine learning series}
}
@article{Zhang_Patras_Haddadi_2019,
	title        = {Deep Learning in Mobile and Wireless Networking: A Survey},
	author       = {Zhang, Chaoyun and Patras, Paul and Haddadi, Hamed},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1803.04311 [cs]},
	url          = {http://arxiv.org/abs/1803.04311},
	note         = {arXiv: 1803.04311},
	abstractnote = {The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile trafﬁc volumes, real-time extraction of ﬁne-grained analytics, and agile management of network resources, so as to maximize user experience. Fulﬁlling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space.}
}
@article{Xin_Kong_Liu_Chen_Li_Zhu_Gao_Hou_Wang_2018,
	title        = {Machine Learning and Deep Learning Methods for Cybersecurity},
	author       = {Xin, Yang and Kong, Lingshuang and Liu, Zhi and Chen, Yuling and Li, Yanmiao and Zhu, Hongliang and Gao, Mingcheng and Hou, Haixia and Wang, Chunhua},
	year         = 2018,
	journal      = {IEEE Access},
	volume       = 6,
	pages        = {35365–35381},
	doi          = {10.1109/ACCESS.2018.2836950},
	issn         = {2169-3536},
	note         = {tex.ids: xinMachineLearningDeep2018a},
	abstractnote = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.}
}
@inproceedings{Mohamed_Salleh_Omar_2012,
	title        = {A comparative study of Reduced Error Pruning method in decision tree algorithms},
	author       = {Mohamed, W. Nor Haizan W. and Salleh, Mohd Najib Mohd and Omar, Abdul Halim},
	year         = 2012,
	month        = nov,
	booktitle    = {2012 IEEE International Conference on Control System, Computing and Engineering},
	pages        = {392–397},
	doi          = {10.1109/ICCSCE.2012.6487177},
	issn         = {null},
	abstractnote = {Decision tree is one of the most popular and efficient technique in data mining. This technique has been established and well-explored by many researchers. However, some decision tree algorithms may produce a large structure of tree size and it is difficult to understand. Furthermore, misclassification of data often occurs in learning process. Therefore, a decision tree algorithm that can produce a simple tree structure with high accuracy in term of classification rate is a need to work with huge volume of data. Pruning methods have been introduced to reduce the complexity of tree structure without decrease the accuracy of classification. One of pruning methods is the Reduced Error Pruning (REP). To better understand pruning methods, an experiment was conducted using Weka application to compare the performance in term of complexity of tree structure and accuracy of classification for J 48, REPTree, PART, JRip, and Ridor algorithms using seven standard datasets from UCI machine learning repository. In data modeling, J48 and REPTree generate tree structure as an output while PART, Ridor and JRip generate rules. In additional J48, REPTree and PART using REP method for pruning while Ridor and JRip using improvement of REP method, namely IREP and RIPPER methods. The experiment result shown performance of J48 and REPTree are competitive in producing better result. Between J48 and REPTree, average differences performance of accuracy of classification is 7.1006\% and 6.285\% for complexity of tree structure. For classification rules algorithms, Ridor is the best algorithms compare to PART and JRip due to highest percentage of accuracy of classification in five dataset from seven datasets. An algorithm that produces high accuracy with simple tree structure or simple rules can be awarded as the best algorithm in decision tree.}
}
@book{Chang_2019,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
}
@inbook{Noel_2018,
	title        = {Text Mining for Modeling Cyberattacks},
	author       = {Noel, Steven},
	year         = 2018,
	month        = jan,
	booktitle    = {Handbook of Statistics},
	doi          = {10.1016/bs.host.2018.06.001},
	abstractnote = {This chapter examines how natural language processing can be applied for building rich models for cybersecurity analytics. For this, it applies text mining to the natural-language content of Common Attack Pattern Enumeration and Classification (CAPECTM), a standardized corpus of cyberattack patterns. We adopt a vector-space model in which CAPEC attack patterns are treated as documents with term vectors. This provides a space in which to define distance measures, such as for retrieving attack patterns through term queries or finding clusters of related attack patterns. Analysis of clustering patterns, i.e., cluster hierarchies (clusters within clusters) is aided through tree visualization techniques. These analytic and visual techniques provide a range of capabilities for leveraging the content and relationships in CAPEC, e.g., for building more complex security models such as network attack graphs.}
}
@inproceedings{perozzi2014deepwalk,
	title        = {Deepwalk: Online learning of social representations},
	author       = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
	year         = 2014,
	booktitle    = {Proceedings of KDD},
	pages        = {701--710}
}
@inproceedings{tang2015line,
	title        = {Line: Large-scale information network embedding},
	author       = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
	year         = 2015,
	booktitle    = {Proceedings of WWW},
	pages        = {1067--1077}
}
@inproceedings{grover2016node2vec,
	title        = {node2vec: Scalable feature learning for networks},
	author       = {Grover, Aditya and Leskovec, Jure},
	year         = 2016,
	booktitle    = {Proceedings of KDD},
	pages        = {855--864}
}
@article{kipf2016semi,
	title        = {Semi-Supervised Classification with Graph Convolutional Networks},
	author       = {Kipf, Thomas N and Welling, Max},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1609.02907}
}
@inproceedings{cao2015grarep,
	title        = {Grarep: Learning graph representations with global structural information},
	author       = {Cao, Shaosheng and Lu, Wei and Xu, Qiongkai},
	year         = 2015,
	booktitle    = {Proceedings of CIKM},
	pages        = {891--900}
}
@inproceedings{yang2015network,
	title        = {Network representation learning with rich text information},
	author       = {Yang, Cheng and Liu, Zhiyuan and Zhao, Deli and Sun, Maosong and Chang, Edward},
	year         = 2015,
	booktitle    = {Proceedings of IJCAI}
}
@article{tu2017network,
	title        = {Network representation learning: an overview},
	author       = {TU, Cunchao and YANG, Cheng and LIU, Zhiyuan and SUN, Maosong},
	year         = 2017,
	journal      = {SCIENTIA SINICA Informationis},
	volume       = 47,
	number       = 8,
	pages        = {980--996}
}
@inproceedings{ou2016asymmetric,
	title        = {Asymmetric transitivity preserving graph embedding},
	author       = {Ou, Mingdong and Cui, Peng and Pei, Jian and Zhang, Ziwei and Zhu, Wenwu},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd ACM SIGKDD},
	pages        = {1105--1114},
	organization = {ACM}
}
@inproceedings{belkin2002laplacian,
	title        = {Laplacian eigenmaps and spectral techniques for embedding and clustering},
	author       = {Belkin, Mikhail and Niyogi, Partha},
	year         = 2002,
	booktitle    = {Advances in neural information processing systems},
	pages        = {585--591}
}
@inproceedings{ahmed2013distributed,
	title        = {Distributed large-scale natural graph factorization},
	author       = {Ahmed, Amr and Shervashidze, Nino and Narayanamurthy, Shravan and Josifovski, Vanja and Smola, Alexander J},
	year         = 2013,
	booktitle    = {Proceedings of the 22nd international conference on World Wide Web},
	pages        = {37--48},
	organization = {ACM}
}
@inproceedings{wang2016structural,
	title        = {Structural deep network embedding},
	author       = {Wang, Daixin and Cui, Peng and Zhu, Wenwu},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages        = {1225--1234},
	organization = {ACM}
}
@article{Boutaba_Salahuddin_Limam_Ayoubi_Shahriar_Estrada-Solano_Caicedo_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
@article{Bruna_Zaremba_Szlam_LeCun_2014,
	title        = {Spectral Networks and Locally Connected Networks on Graphs},
	author       = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	year         = 2014,
	month        = may,
	journal      = {arXiv:1312.6203 [cs]},
	url          = {http://arxiv.org/abs/1312.6203},
	note         = {arXiv: 1312.6203},
	abstractnote = {Convolutional Neural Networks are extremely efﬁcient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals deﬁned on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efﬁcient deep architectures.}
}
@article{Chen,
	title        = {Directed Graph Embedding},
	author       = {Chen, Mo},
	pages        = 6,
	abstractnote = {In this paper, we propose the Directed Graph Embedding (DGE) method that embeds vertices on a directed graph into a vector space by considering the link structure of graphs. The basic idea is to preserve the locality property of vertices on a directed graph in the embedded space. We use the transition probability together with the stationary distribution of Markov random walks to measure such locality property. It turns out that by exploring the directed links of the graph using random walks, we can get an optimal embedding on the vector space that preserves the local affinity which is inherent in the directed graph. Experiments on both synthetic data and real-world Web page data are considered. The application of our method to Web page classification problems gets a significant improvement comparing with state-of-art methods.}
}
@book{ai_cybersec,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	place        = {Washington, D.C.},
	editor       = {Johnson, Anne and Grumbling, Emily}
}
@article{Dai_Li_Tian_Huang_Wang_Zhu_Song_2018,
	title        = {Adversarial Attack on Graph Structured Data},
	author       = {Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.02371 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.02371},
	note         = {arXiv: 1806.02371},
	abstractnote = {Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We ﬁrst propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classiﬁer. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction conﬁdence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classiﬁcation tasks. We also show such attacks can be used to diagnose the learned classiﬁers.}
}
@inproceedings{Dua_Du_2011,
	title        = {Data Mining and Machine Learning in Cybersecurity},
	author       = {Dua, Sumeet and Du, Xian},
	year         = 2011,
	doi          = {10.1201/b10867},
	abstractnote = {With the rapid advancement of information discovery techniques, machine learning and data mining continue to play a significant role in cybersecurity. Although several conferences, workshops, and journals focus on the fragmented research topics in this area, there has been no single interdisciplinary resource on past and current works and possible paths for future research in this area. This book fills this need. From basic concepts in machine learning and data mining to advanced problems in the machine learning domain, Data Mining and Machine Learning in Cybersecurity provides a unified reference for specific machine learning solutions to cybersecurity problems. It supplies a foundation in cybersecurity fundamentals and surveys contemporary challengesdetailing cutting-edge machine learning and data mining techniques. It also: Unveils cutting-edge techniques for detectingnew attacks Contains in-depth discussions of machine learning solutions to detection problems Categorizes methods for detecting, scanning, and profiling intrusions and anomalies Surveys contemporary cybersecurity problems and unveils state-of-the-art machine learning and data mining solutions Details privacy-preserving data mining methods This interdisciplinary resource includes technique review tables that allow for speedy access to common cybersecurity problems and associated data mining methods. Numerous illustrative figures help readers visualize the workflow of complex techniques and more than forty case studies provide a clear understanding of the design and application of data mining and machine learning techniques in cybersecurity.}
}
@article{Goyal_Ferrara_2018,
	title        = {Graph Embedding Techniques, Applications, and Performance: A Survey},
	author       = {Goyal, Palash and Ferrara, Emilio},
	year         = 2018,
	month        = jul,
	journal      = {Knowledge-Based Systems},
	volume       = 151,
	pages        = {78–94},
	doi          = {10.1016/j.knosys.2018.03.022},
	issn         = {09507051},
	note         = {arXiv: 1705.02801},
	abstractnote = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and diﬀerent patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We ﬁrst introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We ﬁnally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a uniﬁed interface to foster and facilitate research on the topic.}
}
@article{Hamilton_Ying_Leskovec,
	title        = {Representation Learning on Graphs: Methods and Applications},
	author       = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
	pages        = 23,
	abstractnote = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is ﬁnding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-deﬁned heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph convolutional networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a uniﬁed framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.}
}
@inproceedings{Kutuzov_Dorgham_Oliynyk_Biemann_Panchenko_2019,
	title        = {Making Fast Graph\-based Algorithms with Graph Metric Embeddings},
	author       = {Kutuzov, Andrey and Dorgham, Mohammad and Oliynyk, Oleksiy and Biemann, Chris and Panchenko, Alexander},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	pages        = {3349–3355},
	doi          = {10.18653/v1/P19-1325},
	url          = {https://www.aclweb.org/anthology/P19-1325},
	place        = {Florence, Italy},
	abstractnote = {The computation of distance measures between nodes in graphs is inefﬁcient and does not scale to large graphs. We explore dense vector representations as an effective way to approximate the same information: we introduce a simple yet efﬁcient and effective approach for learning graph embeddings. Instead of directly operating on the graph structure, our method takes structural measures of pairwise node similarities into account and learns dense node representations reﬂecting user-deﬁned graph distance measures, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings on semantic similarity and word sense disambiguation tasks and show evaluations on the WordNet graph and two knowledge base graphs.}
}
@article{Li_Tarlow_Brockschmidt_Zemel_2017,
	title        = {Gated Graph Sequence Neural Networks},
	author       = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
	year         = 2017,
	month        = sep,
	journal      = {arXiv:1511.05493 [cs, stat]},
	url          = {http://arxiv.org/abs/1511.05493},
	note         = {arXiv: 1511.05493},
	abstractnote = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a ﬂexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program veriﬁcation, in which subgraphs need to be described as abstract data structures.}
}
@article{Oroojlooyjadid_2019,
	title        = {A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning algorithm to Solve Inventory Optimization Problems},
	author       = {Oroojlooyjadid, Afshin and Nazari, MohammadReza and Snyder, Lawrence and Takáč, Martin},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1708.05924 [cs]},
	url          = {http://arxiv.org/abs/1708.05924},
	note         = {arXiv: 1708.05924},
	abstractnote = {The beer game is a widely used in-class game that is played in supply chain management classes to demonstrate the bullwhip effect. The game is a decentralized, multi-agent, cooperative problem that can be modeled as a serial supply chain network in which agents cooperatively attempt to minimize the total cost of the network even though each agent can only observe its own local information. Each agent chooses order quantities to replenish its stock. Under some conditions, a base-stock replenishment policy is known to be optimal. However, in a decentralized supply chain in which some agents (stages) may act irrationally (as they do in the beer game), there is no known optimal policy for an agent wishing to act optimally. We propose a machine learning algorithm, based on deep Q-networks, to optimize the replenishment decisions at a given stage. When playing alongside agents who follow a base-stock policy, our algorithm obtains near-optimal order quantities. It performs much better than a base-stock policy when the other agents use a more realistic model of human ordering behavior. Unlike most other algorithms in the literature, our algorithm does not have any limits on the beer game parameter values. Like any deep learning algorithm, training the algorithm can be computationally intensive, but this can be performed ahead of time; the algorithm executes in real time when the game is played. Moreover, we propose a transfer learning approach so that the training performed for one agent and one set of cost coefficients can be adapted quickly for other agents and costs. Our algorithm can be extended to other decentralized multi-agent cooperative games with partially observed information, which is a common type of situation in real-world supply chain problems.}
}
@inproceedings{Tang_Mhamdi_McLernon_Zaidi_Ghogho_2016,
	title        = {Deep learning approach for Network Intrusion Detection in Software Defined Networking},
	author       = {Tang, Tuan A and Mhamdi, Lotfi and McLernon, Des and Zaidi, Syed Ali Raza and Ghogho, Mounir},
	year         = 2016,
	month        = oct,
	booktitle    = {2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)},
	publisher    = {IEEE},
	pages        = {258–263},
	doi          = {10.1109/WINCOM.2016.7777224},
	isbn         = {978-1-5090-3837-4},
	url          = {http://ieeexplore.ieee.org/document/7777224/},
	place        = {Fez, Morocco},
	abstractnote = {Software Deﬁned Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for ﬂow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSLKDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the fortyone features of NSL-KDD Dataset. Through experiments, we conﬁrm that the deep learning approach shows strong potential to be used for ﬂow-based anomaly detection in SDN environments.}
}
@article{Bacciu_Errica_Micheli_Podda_2019,
	title        = {A Gentle Introduction to Deep Learning for Graphs},
	author       = {Bacciu, Davide and Errica, Federico and Micheli, Alessio and Podda, Marco},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1912.12693 [cs, stat]},
	url          = {http://arxiv.org/abs/1912.12693},
	note         = {arXiv: 1912.12693},
	abstractnote = {The adaptive processing of graph data is a long-standing research topic which has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is designed as a tutorial introduction to the field of deep learning for graphs. It favours a consistent and progressive introduction of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view to the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. It introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. The methodological exposition is complemented by a discussion of interesting research challenges and applications in the field.}
}
@article{Qu_Bengio_Tang,
	title        = {GMNN: Graph Markov Neural Networks},
	author       = {Qu, Meng and Bengio, Yoshua and Tang, Jian},
	pages        = 10,
	abstractnote = {This paper studies semi-supervised object classiﬁcation in relational data, which is a fundamental problem in relational data modeling. The problem has been extensively studied in the literature of both statistical relational learning (e.g. relational Markov networks) and graph neural networks (e.g. graph convolutional networks). Statistical relational learning methods can effectively model the dependency of object labels through conditional random ﬁelds for collective classiﬁcation, whereas graph neural networks learn effective object representations for classiﬁcation through end-to-end training. In this paper, we propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds. A GMNN models the joint distribution of object labels with a conditional random ﬁeld, which can be effectively trained with the variational EM algorithm. In the E-step, one graph neural network learns effective object representations for approximating the posterior distributions of object labels. In the M-step, another graph neural network is used to model the local label dependency. Experiments on object classiﬁcation, link classiﬁcation, and unsupervised node representation learning show that GMNN achieves state-of-the-art results.}
}



 @inproceedings{Vaughn_Henning_Siraj_2003, place={Big Island, HI, USA}, title={Information assurance measures and metrics - state of practice and proposed taxonomy}, ISBN={978-0-7695-1874-9}, url={http://ieeexplore.ieee.org/document/1174904/}, DOI={10.1109/HICSS.2003.1174904}, abstractNote={The term “ assurance” has been used for decades in trusted system development as an expression of confidence that one has in the strength of mechanisms or countermeasures. One of the unsolved problems of security engineering is the adoption of measures or metrics that can reliably depict the assurance associated with a specific hardware and software system. This paper reports on a recent attempt to focus requirements in this area by examining those currently in use. It then suggests a categorization of Information Assurance (IA) metrics that may be tailored to an organization’s needs1. We believe that the provision of security mechanisms in systems is a subset of the systems engineering discipline having a large software-engineering correlation. There is general agreement that no single system metric or any “one-prefect” set of IA metrics applies across all systems or audiences. The set most useful for an organization largely depends on their IA goals, their technical, organizational and operational needs, and the financial, personnel, and technical resources that are available.}, note={tex.ids: vaughn2003a
tex.citation-number: 14}, booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, publisher={IEEE}, author={Vaughn, R.B. and Henning, R. and Siraj, A.}, year={2003}, pages={10 pp.} }

 @article{Morrison_Moye_Pandita_Williams_2018, title={Mapping the field of software life cycle security metrics}, volume={102}, ISSN={09505849}, DOI={10.1016/j.infsof.2018.05.011}, abstractNote={Objective: The goal of this research is to support practitioner and researcher use of security measurement in the software life cycle by cataloging security metrics presented in the literature, their validation, and the subjects they measure.
Method: We conducted a systematic mapping study, beginning with 4818 papers and narrowing down to 71 papers reporting on 324 unique security metrics. For each metric, we identiﬁed the subject being measured, how the metric has been validated, and how the metric is used. We categorized the metrics, and give examples of metrics for each category.
Results: In our data, 85\% of security metrics have been proposed and evaluated solely by their authors, leaving room for replication and conﬁrmation through ﬁeld studies. Approximately 60\% of the metrics have been empirically evaluated, by their authors or by others. The available metrics are weighted heavily toward the implementation and operations phases, with relatively few metrics for requirements, design, and testing phases of software development. Some artifacts and processes remain unmeasured. Measured by phase, Testing received the least attention, with 1.5\% of the metrics.
Conclusions: At present, the primary application of security metrics to the software development life cycle in the literature is to study the relationship between properties of source code and reported vulnerabilities. The most-cited and most used metric, vulnerability count, has multiple deﬁnitions and operationalizations. We suggest that researchers must check vulnerability count deﬁnitions when making comparisons between papers. In addition to reﬁning vulnerability measurement, we see research opportunities for greater attention to metrics for the requirement, design, and testing phases of development. We conjecture from our data that the ﬁeld of software life cycle security metrics has yet to converge on an accepted set of metrics.}, journal={Information and Software Technology}, author={Morrison, Patrick and Moye, David and Pandita, Rahul and Williams, Laurie}, year={2018}, month={Oct}, pages={146–159} }
