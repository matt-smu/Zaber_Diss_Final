@inproceedings{Abedin_Nessa_Al-Shaer_Khan_2006,
	title        = {Vulnerability analysis for evaluating quality of protection of security policies},
	author       = {Abedin, M. and Nessa, S. and Al-Shaer, E. and Khan, L.},
	year         = 2006,
	booktitle    = {Proceedings of the 2Nd ACM workshop on quality of protection, ser. QoP '06},
	publisher    = {ACM},
	pages        = {49–52},
	note         = {Citation Key: abedin2006a tex.citation-number: 124},
	place        = {New York, NY, USA}
}
@phdthesis{Abraham_2016,
	title        = {Cyber-security analytics: Stochastic models for security quantification},
	author       = {Abraham, Subil},
	year         = 2016,
	month        = jun,
	booktitle    = {2016 IEEE 40th annual computer software and applications conference (COMPSAC},
	volume       = 2,
	pages        = {467–472},
	note         = {Citation Key: abraham2016a tex.citation-number: 78},
	school       = {Southern Methodist University}
}
@article{Abraham_Nair_2014,
	title        = {Cyber security analytics: a stochastic model for security quantification using absorbing markov chains},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2014,
	journal      = {Journal of Communications},
	volume       = 9,
	number       = 12,
	pages        = {899–907}
}
@inproceedings{Abraham_Nair_2015a,
	title        = {A novel architecture for predictive cybersecurity using non-homogenous markov models},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	booktitle    = {2015 IEEE Trustcom/BigDataSE/ISPA},
	publisher    = {IEEE},
	volume       = 1,
	pages        = {774–781}
}
@article{Abraham_Nair_2015b,
	title        = {A predictive framework for cyber security analytics using attack graphs},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1502.01240}
}
@inproceedings{Abraham_Nair_2015c,
	title        = {Exploitability analysis using predictive cybersecurity framework},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	booktitle    = {2015 IEEE 2nd International Conference on Cybernetics (CYBCONF)},
	publisher    = {IEEE},
	pages        = {317–323}
}
@article{Abraham_Nair_2015d,
	title        = {Predictive cyber-security analytics framework: a non-homogenous markov model for security quantification},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1501.01901}
}
@article{Abraham_Nair_2018,
	title        = {Comparative analysis and patch optimization using the cyber security analytics framework},
	author       = {Abraham, Subil and Nair, Suku},
	year         = 2018,
	journal      = {The Journal of Defense Modeling and Simulation},
	volume       = 15,
	number       = 2,
	pages        = {161–180}
}
@article{Abubakar_Chiroma_Muaz_Ila_2015,
	title        = {A Review of the Advances in Cyber Security Benchmark Datasets for Evaluating Data-Driven Based Intrusion Detection Systems},
	author       = {Abubakar, Adamu I. and Chiroma, Haruna and Muaz, Sanah Abdullahi and Ila, Libabatu Baballe},
	year         = 2015,
	journal      = {Procedia Computer Science},
	volume       = 62,
	pages        = {221–227},
	doi          = {10.1016/j.procs.2015.08.443},
	issn         = 18770509,
	abstractnote = {Cybercrime has led to the loss of billions of dollars, the malfunctioning of computer systems, the destruction of critical information, the compromising of network integrity and confidentiality, etc. In view of these crimes committed on a daily basis, the security of the computer systems has become imperative to minimize and possibly avoid the impact of cybercrimes. In this paper, we review recent advances in the use of cyber security benchmark datasets for the evaluation of machine learning and data mining-based intrusion detection systems. It was found that the state-of-the-art cyber security benchmark datasets KDD and UNM are no longer reliable, because their datasets cannot meet the expectations of current advances in computer technology. As a result, a new ADFA Linux (ADFA-LD) cyber security benchmark dataset for the evaluation of machine learning and data mining-based intrusion detection systems was proposed in 2013 to meet the current significant advances in computer technology. ADFA-LD requires improvement in terms of full descriptions of its attributes. This review can be used by the research community as a basis for abandoning the previous state-of-the-art cyber security benchmark datasets and starting to use the newly introduced benchmark dataset for effective and robust evaluation of machine learning and data mining-based intrusion detection system.}
}
@inproceedings{Acosta_Padilla_Homer_2016,
	title        = {Augmenting attack graphs to represent data link and network layer vulnerabilities},
	author       = {Acosta, J. C. and Padilla, E. and Homer, J.},
	year         = 2016,
	month        = 11,
	booktitle    = {MILCOM 2016 - 2016 IEEE Military Communications Conference},
	pages        = {1010–1015},
	doi          = {10.1109/MILCOM.2016.7795462},
	abstractnote = {Attack graphs enable system stakeholders to understand the stepping stones or exploitation procedures that an adversary could potentially execute to impact the confidentiality, integrity, and availability of a network system. These graphs are used to assess risk and to determine components that, when hardened, contribute most to risk reduction. While these graphs are powerful and widely used in enterprise network systems they focus on application vulnerabilities; they currently do not incorporate weaknesses in the network backbone (e.g., routing) that could lead to traffic hijacking, spoofing, eavesdropping, and several others. In this paper, we describe our work in augmenting the MulVAL attack graph software to incorporate network layer misconfigurations. Through a case study, we show how our modular data pipeline, leveraging previous work in network layer attack impact prediction, can aid system stakeholders in identifying risk and deciding on risk reduction strategies.}
}
@inbook{Ahmed_Al-Shaer_Khan_2008,
	title        = {A novel quantitative approach for measuring network security},
	author       = {Ahmed, M. and Al-Shaer, E. and Khan, L.},
	year         = 2008,
	month        = apr,
	booktitle    = {IEEE INFOCOM'2008.Google scholar},
	publisher    = {IEEE},
	pages        = {1957–1965},
	note         = {Citation Key: ahmed2008a}
}
@article{Ahmed_Al-Shaer_Taibah_Khan_2011,
	title        = {Objective risk evaluation for automated security management},
	author       = {Ahmed, M.S. and Al-Shaer, E. and Taibah, M. and Khan, L.},
	year         = 2011,
	month        = sep,
	journal      = {Journal of Network and Systems Management},
	volume       = 19,
	number       = 3,
	pages        = {343--366,},
	note         = {Citation Key: ahmed2011a tex.citation-number: 126}
}
@inproceedings{ahmed2013distributed,
	title        = {Distributed large-scale natural graph factorization},
	author       = {Ahmed, Amr and Shervashidze, Nino and Narayanamurthy, Shravan and Josifovski, Vanja and Smola, Alexander J},
	year         = 2013,
	booktitle    = {Proceedings of the 22nd international conference on World Wide Web},
	pages        = {37--48},
	organization = {ACM}
}
@book{ai_cybersec,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	place        = {Washington, D.C.},
	editor       = {Johnson, Anne and Grumbling, Emily}
}
@article{Akyildiz_Su_Sankarasubramaniam_Cayirci_2002,
	title        = {A survey on sensor networks},
	author       = {Akyildiz, I.F. and Su, W. and Sankarasubramaniam, Y. and Cayirci, E.},
	year         = 2002,
	month        = aug,
	journal      = {IEEE Communications Magazine},
	volume       = 40,
	number       = 8,
	pages        = {102--114,},
	note         = {Citation Key: akyildiz2002a tex.citation-number: 137}
}
@article{Al-Fuqaha_Guizani_Mohammadi_Aledhari_Ayyash_2015,
	title        = {Internet of things: A survey on enabling technologies, protocols, and applications},
	author       = {Al-Fuqaha, A. and Guizani, M. and Mohammadi, M. and Aledhari, M. and Ayyash, M.},
	year         = 2015,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 17,
	number       = 4,
	pages        = {2347--2376,},
	note         = {Citation Key: al-fuqaha2015a tex.citation-number: 138}
}
@article{Al-Kuwaiti_Kyriakopoulos_Hussein_2009,
	title        = {A comparative analysis of network dependability, fault-tolerance, reliability, security, and survivability},
	author       = {Al-Kuwaiti, M. and Kyriakopoulos, N. and Hussein, S.},
	year         = 2009,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 11,
	number       = 2,
	pages        = {106--124,},
	note         = {Citation Key: al-kuwaiti2009a tex.citation-number: 55}
}
@article{Al-Shaer_Khan_Ahmed_2008,
	title        = {A comprehensive objective network security metric framework for proactive security configuration},
	author       = {Al-Shaer, E. and Khan, L. and Ahmed, M.},
	year         = 2008,
	journal      = {Proc. CSIIRW'08},
	volume       = 42,
	number       = 1,
	note         = {Citation Key: al-shaer2008a tex.address: Google Scholar}
}
@inproceedings{Albanese_Jajodia_Noel_2012,
	title        = {Time-efficient and cost-effective network hardening using attack graphs},
	author       = {Albanese, M. and Jajodia, S. and Noel, S.},
	year         = 2012,
	booktitle    = {Proc. IEEE},
	volume       = {DSN'12},
	pages        = {1–12},
	note         = {Citation Key: albanese2012a}
}
@article{Albert_Barabasi_2002,
	title        = {Statistical mechanics of complex networks},
	author       = {Albert, R. and Barabasi, A.},
	year         = 2002,
	journal      = {Rev. Mod. Phys},
	volume       = 74,
	note         = {Citation Key: albert2002a}
}
@article{Alhazmi_Malaiya_2008,
	title        = {Application of vulnerability discovery models to major operating systems},
	author       = {Alhazmi, Omar H. and Malaiya, Yashwant K.},
	year         = 2008,
	journal      = {IEEE Transactions on Reliability},
	volume       = 57,
	number       = 1,
	pages        = {14–22},
	note         = {tex.ids: alhazmiApplicationVulnerabilityDiscovery2008a, alhazmiApplicationVulnerabilityDiscovery2008b}
}
@inproceedings{Almasizadeh_2009,
	title        = {Intrusion process modeling for security quantification},
	author       = {Almasizadeh, J.},
	year         = 2009,
	booktitle    = {2009 international conference on availability, reliability and security},
	publisher    = {IEEE},
	pages        = {114–121},
	note         = {Citation Key: almasizadeh2009b tex.citation-number: 74}
}
@inbook{Almasizadeh_Azgomi_2009,
	title        = {A method for estimation of the success probability of an intrusion process by considering the temporal aspects of the attacker behavior},
	author       = {Almasizadeh, J. and Azgomi, M.A.},
	year         = 2009,
	booktitle    = {Transactions on computational science IV},
	pages        = {200–214},
	note         = {Citation Key: almasizadeh2009a tex.citation-number: 73}
}
@article{Almasizadeh_Azgomi_2013,
	title        = {A stochastic model of attack process for the evaluation of security metrics},
	author       = {Almasizadeh, Jaafar and Azgomi, Mohammad Abdollahi},
	year         = 2013,
	month        = jul,
	journal      = {Computer Networks},
	series       = {Towards a Science of Cyber Security},
	volume       = 57,
	number       = 10,
	pages        = {2159–2180},
	doi          = {10.1016/j.comnet.2013.03.011},
	issn         = {1389-1286},
	note         = {tex.ids: almasizadeh2013a tex.citation-number: 40},
	abstractnote = {To trust a computer system that is supposed to be secure, it is necessary to predict the degree to which the system's security level can be achieved when operating in a specific environment under cyber attacks. In this paper, we propose a state-based stochastic model for obtaining quantitative security metrics representing the level of a system's security. The main focus of the study is on how to model the progression of an attack process over time. The basic assumption of our model is that the time parameter plays the essential role in capturing the nature of an attack process. In practice, the attack process will terminate successfully, possibly after a number of unsuccessful attempts. What is important is, indeed, the estimation of how long it takes to be conducted. The proposed stochastic model is parameterized based on a suitable definition of time distributions describing attacker's actions and system's reactions over time. For this purpose, probability distribution functions are defined and assigned to transitions of the model for characterizing the temporal aspects of the attacker and system behavior. With the definition of the distributions, the stochastic model will be recognized to be a semi-Markov chain. This mathematical model will be analytically solved to calculate the desirable quantitative security metrics, such as mean time to security failure and steady-state security. The proposed method shows a systematic development of the stochastic modeling techniques and concepts, used frequently in the area of dependability evaluation, for attack process modeling. Like any other modeling method, the proposed model is also constructed based on some underlying assumptions, which are specific to the context of security analysis.},
	collection   = {Towards a Science of Cyber Security}
}
@article{Almasizadeh_Azgomi_2013a,
	title        = {Mean privacy: A metric for security of computer systems},
	author       = {Almasizadeh, J. and Azgomi, M.Abdollahi},
	year         = 2013,
	month        = oct,
	journal      = {Computer Communications},
	volume       = 52,
	pages        = {47--59,},
	note         = {Citation Key: almasizadeh2013b tex.citation-number: 121}
}
@article{Amin_Schwartz_Hussain_2013,
	title        = {In quest of benchmarking security risks to cyber-physical systems},
	author       = {Amin, S. and Schwartz, G. A. and Hussain, A.},
	year         = 2013,
	month        = jan,
	journal      = {IEEE Network},
	volume       = 27,
	number       = 1,
	pages        = {19–24},
	doi          = {10.1109/MNET.2013.6423187},
	issn         = {0890-8044},
	abstractnote = {We present a generic yet practical framework for assessing security risks to cyberphysical systems (CPSs). Our framework can be used to benchmark security risks when information is less than perfect, and interdependencies of physical and computational components may result in correlated failures. Such environments are prone to externalities, and can cause huge societal losses. We focus on the risks that arise from interdependent reliability failures (faults) and security failures (attacks). We advocate that a sound assessment of these risks requires explicit modeling of the effects of both technology-based defenses and institutions necessary for supporting them. Thus, we consider technology-based security defenses grounded in information security tools and fault-tolerant control in conjunction with institutional structures. Our game-theoretic approach to estimating security risks facilitates more effective defenses, especially against correlated failures.}
}
@inproceedings{Ammann_Wijesekera_Kaushik_2002,
	title        = {Scalable, graph-based network vulnerability analysis},
	author       = {Ammann, P. and Wijesekera, D. and Kaushik, S.},
	year         = 2002,
	booktitle    = {Proc. ACM},
	volume       = {CCS'02},
	pages        = {217–224},
	note         = {Citation Key: ammann2002a tex.citation-number: 91}
}
@inproceedings{Anderson_2001,
	title        = {Why information security is hard-an economic perspective},
	author       = {Anderson, Ross},
	year         = 2001,
	booktitle    = {Seventeenth Annual Computer Security Applications Conference},
	publisher    = {IEEE},
	pages        = {358–365},
	issn         = {null},
	note         = {tex.ids: andersonWhyInformationSecurity2001a, andersonWhyInformationSecurity2001b}
}
@article{Anderson_Moore,
	title        = {The Economics of Information Security: A Survey and Open Questions},
	author       = {Anderson, Ross and Moore, Tyler},
	year         = 2007,
	booktitle    = {Fourth bi-annual Conference on the Economics of the Software and Internet Industries},
	pages        = 27,
	abstractnote = {The economics of information security has recently become a thriving and fastmoving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, we find incentives becoming as important to dependability as technical design is. The new field provides valuable insights not just into `security' topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of effort by programmers and testers), policy (particularly digital rights management) and more general security questions (such as law-enforcement strategy).}
}
@article{Anderson_Mooreb,
	title        = {Information Security Economics -- and Beyond},
	author       = {Anderson, Ross and Moore, Tyler},
	pages        = 24,
	abstractnote = {The economics of information security has recently become a thriving and fast-moving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, incentives are becoming as important to dependability as technical design. The new field provides valuable insights not just into `security' topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of effort by programmers and testers), and policy (particularly digital rights management). This research program has been starting to spill over into more general security questions (such as law-enforcement strategy), and into the interface between security and sociology. Most recently it has started to interact with psychology, both through the psychology-and-economics tradition and in response to phishing. The promise of this research program is a novel framework for analyzing information security problems – one that is both principled and effective.}
}
@inproceedings{Anisetti_Ardagna_Damiani_Gaudenzi_2017,
	title        = {A Security Benchmark for OpenStack},
	author       = {Anisetti, Marco and Ardagna, Claudio A. and Damiani, Ernesto and Gaudenzi, Filippo},
	year         = 2017,
	month        = jun,
	booktitle    = {2017 IEEE 10th International Conference on Cloud Computing (CLOUD)},
	publisher    = {IEEE},
	pages        = {294–301},
	doi          = {10.1109/CLOUD.2017.45},
	isbn         = {978-1-5386-1993-3},
	url          = {http://ieeexplore.ieee.org/document/8030601/},
	place        = {Honolulu, CA, USA},
	abstractnote = {The cloud computing paradigm entails a radical change in IT provisioning, which must be understood and correctly applied especially when security requirements are considered. Security requirements do not cover anymore just the application itself, but involve the whole cloud supply chain from the hosting infrastructure to the final applications. This scenario requires, on one side, new security mechanisms protecting the cloud against misbehaviors/malicious attacks and, on the other side, a continuous and adaptive assurance process evaluating the observed cloud security behavior against the expected one. In this paper, we focus on the evaluation of the security assurance of OpenStack, a major open source cloud infrastructure. We first define a security benchmark for OpenStack, inspired by Center for Internet Security (CIS) benchmark for cloud infrastructures. We then present a platform, called Moon Cloud, for cloud security assurance evaluation, showing an application of our benchmark and platform to the in-production OpenStack deployment of the University of Milan.}
}
@article{Association_2003,
	title        = {Four grand challenges in trustworthy computing},
	author       = {Association, Computing Research},
	year         = 2003,
	journal      = {Tech. Rep},
	url          = {http://archive.cra.org/reports/trustworthy.computing.pdf},
	note         = {Citation Key: association2003a tex.citation-number: 144}
}
@article{attacktrees.pdf,
	url          = {http://tnlandforms.us/cs594-cns96/attacktrees.pdf}
}
@inbook{Avizienis_Laprie_Randell_2001,
	title        = {Fundamental concepts of dependability},
	author       = {Avizienis, A. and Laprie, J.-c and Randell, B.},
	year         = 2001,
	booktitle    = {LAAS-CNRS N01145, Tech},
	publisher    = {Rep},
	note         = {Citation Key: avizienis2001a tex.citation-number: 49}
}
@article{Awduche_Agogbua_1999,
	title        = {Requirements for traffic engineering over MPLS},
	author       = {Awduche, Daniel O. and Agogbua, Johnson},
	year         = 1999
}
@inproceedings{Axelsson_2009,
	title        = {The base-rate fallacy and its implications for the difficulty of intrusion detection},
	author       = {Axelsson, S.},
	year         = 2009,
	booktitle    = {Proc. ACM CCS'09},
	pages        = {1–7},
	note         = {Citation Key: axelsson2009a}
}
@article{Azuwa_Ahmad_Sahib_2012,
	title        = {Technical security metrics model in compliance with ISO/IEC 27001 standard},
	author       = {MP Azuwa, Azuwa and Ahmad, Rabiah and Sahib, Sharin},
	year         = 2012,
	journal      = {International Journal of Cyber-Security and Digital Forensics},
	volume       = 1,
	pages        = {280–288}
}
@article{Bacciu_Errica_Micheli_Podda_2019,
	title        = {A Gentle Introduction to Deep Learning for Graphs},
	author       = {Bacciu, Davide and Errica, Federico and Micheli, Alessio and Podda, Marco},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1912.12693 [cs, stat]},
	url          = {http://arxiv.org/abs/1912.12693},
	note         = {arXiv: 1912.12693},
	abstractnote = {The adaptive processing of graph data is a long-standing research topic which has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is designed as a tutorial introduction to the field of deep learning for graphs. It favours a consistent and progressive introduction of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view to the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. It introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. The methodological exposition is complemented by a discussion of interesting research challenges and applications in the field.}
}
@article{Bacic_Froh_Henderson_2006,
	title        = {MulVAL Extensions for Dynamic Asset Protection},
	author       = {Bacic, Eugen and Froh, Michael and Henderson, Glen},
	year         = 2006,
	month        = {04},
	pages        = 68,
	abstractnote = {This paper documents research into extensions to the Multihost, Multistage Vulnerability Analysis (MulVAL) framework to support DRDC efforts to develop a feasible abstraction in the area of defensive posture technology. The results presented in this paper demonstrate that the MulVAL model is extensible and can be enhanced to include additional data representation and analysis features to tailor the model to meet the need of the DND defence community. The extensions evaluated in this effort have been shown to be both technically valid given the capabilities of logic-based programming and appropriate given the current model data representations. The primary extensions researched as part of this work are: improved representation of network path constructs and assignment of value to data assets in the model. This paper documents a substantial degree of progress in the development of each of the proposed MulVAL extensions.}
}
@inproceedings{Backes_Nurnberger_2014,
	title        = {Oxymoron: Making fine-grained memory randomization practical by allowing code sharing},
	author       = {Backes, M. and N\"{u}rnberger, S.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {433–447},
	note         = {Citation Key: backes2014a}
}
@article{Barik_Sengupta_Mazumdar_2016,
	title        = {Attack graph generation and analysis techniques},
	author       = {Barik, Mridul Sankar and Sengupta, Anirban and Mazumdar, Chandan},
	year         = 2016,
	journal      = {Defence science journal},
	volume       = 66,
	number       = 6,
	pages        = 559,
	note         = {tex.ids: barik2016a tex.citation-number: 94 publisher: Defence Scientific Information \& Documentation Centre}
}
@article{Basili_Briand_Melo_1996,
	title        = {A validation of object-oriented design metrics as quality indicators},
	author       = {Basili, V.R. and Briand, L.C. and Melo, W.L.},
	year         = 1996,
	month        = 10,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 22,
	number       = 10,
	pages        = {751–761},
	doi          = {10.1109/32.544352},
	issn         = {00985589},
	abstractnote = {This paper presents the results of a study conducted at the University of Maryland in which we experimentally investigated the suite of Object-Oriented (OO) design metrics introduced by [Chidamber\&Kemerer, 1994]. In order to do this, we assessed these metrics as predictors of fault-prone classes. This study is complementary to [Li\&Henry, 1993] where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on experimental results, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber\&Kemerer's OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. We also showed that they are, on our data set, better predictors than ``traditional'' code metrics, which can only be collected at a later phase of the software development processes.}
}
@article{Bayuk_2013,
	title        = {Security as a theoretical attribute construct},
	author       = {Bayuk, Jennifer L.},
	year         = 2013,
	month        = sep,
	journal      = {Computers \& Security},
	volume       = 37,
	pages        = {155–175},
	doi          = {10.1016/j.cose.2013.03.006},
	issn         = {01674048},
	note         = {tex.ids: bayuk2013a tex.citation-number: 11},
	abstractnote = {This paper provides an overview of the field of security metrics and discusses results of a survey of security experts on the topic. It describes a new framework for developing security metrics that focuses on effectiveness measures while maintaining measures of correctness. It introduces a view of security as a theoretical concept which encapsulates multiple aspects of a system. Viewing security as a theoretical attribute construct promotes the recognition that multiple characteristics and features of a system are required to make it secure. The view also motivates a sharp focus on system aspects which exhibit a measurable security attribute. The framework is illustrated with a case study.}
}
@inproceedings{Beck_2013,
	title        = {Manifesto for Agile Software Development},
	author       = {Beck, Kent M. and Beedle, Mike and Bennekum, Arie van and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andy and Jeffries, Ron and et al.},
	year         = 2013
}
@inproceedings{belkin2002laplacian,
	title        = {Laplacian eigenmaps and spectral techniques for embedding and clustering},
	author       = {Belkin, Mikhail and Niyogi, Partha},
	year         = 2002,
	booktitle    = {Advances in neural information processing systems},
	pages        = {585--591}
}
@book{Bell_LaPadula_1973,
	title        = {Secure computer systems: Mathematical foundations (volume 1)},
	author       = {Bell, D. and LaPadula, L.},
	year         = 1973,
	institution  = {Technical Report ESD-TR-73-278, Mitre Corporation}
}
@article{Bellovin_2006,
	title        = {On the Brittleness of Software and the Infeasibility of Security Metrics},
	author       = {Bellovin, S.M.},
	year         = 2006,
	month        = {07},
	journal      = {IEEE Security \& Privacy Magazine},
	volume       = 4,
	number       = 4,
	pages        = {96–96},
	doi          = {10.1109/MSP.2006.101},
	issn         = {1540-7993},
	note         = {tex.ids: bellovinBrittlenessSoftwareInfeasibility2006a}
}
@book{Benenson_Kuhn_Lucks_2008,
	title        = {Cryptographic attack metrics},
	author       = {Benenson, Z. and K\"{u}hn, U. and Lucks, S.},
	year         = 2008,
	publisher    = {Springer},
	note         = {Citation Key: benenson2008a tex.citation-number: 44},
	place        = {Berlin, Heidelberg},
	editor       = {Dependability Metrics, I.Eusgeld and Freiling, F.C. and Reussner, R.}
}
@article{Berinato_2002,
	title        = {Finally, a real return on security spending},
	author       = {Berinato, S.},
	year         = 2002,
	url          = {http://www.cio.com/article/2440999/metrics/finally--a-real-return-on-security-spending.html.},
	note         = {Citation Key: berinato2002a}
}
@article{Biggio_Fumera_Roli_2014,
	title        = {Security evaluation of patternclassifiers under attack},
	author       = {Biggio, B. and Fumera, G. and Roli, F.},
	year         = 2014,
	journal      = {IEEE Trans. Knowl. Data Eng},
	volume       = {26, 4},
	pages        = {984–996},
	note         = {Citation Key: biggio2014a}
}
@inproceedings{Bilge_Dumitras_2012,
	title        = {Before we knew it: An empirical study of zero-day attacks in the real world},
	author       = {Bilge, L. and Dumitras, T.},
	year         = 2012,
	booktitle    = {Proc. ACM CCS'12},
	pages        = {833–844},
	note         = {Citation Key: bilge2012a tex.citation-number: 135}
}
@article{Bishop_2003,
	title        = {What is computer security?},
	author       = {Bishop, M.},
	year         = 2003,
	month        = jan,
	journal      = {IEEE Security \& Privacy Magazine},
	volume       = 1,
	number       = 1,
	pages        = {67--69,},
	note         = {Citation Key: bishop2003a tex.citation-number: 5}
}
@inproceedings{Bo_Lin_Ru_2011,
	title        = {Quality of protection in web service: An overview},
	author       = {Bo, Y. and Lin, Y. and Ru, M.L.},
	year         = 2011,
	month        = oct,
	booktitle    = {Instrumentation, measurement, computer, communi- cation and control, 2011 first international conference on},
	pages        = {495–498},
	note         = {Citation Key: bo2011a tex.citation-number: 50}
}
@inproceedings{Boggs_Du_Stolfo_2014,
	title        = {Measuring drive-by download defense in depth},
	author       = {Boggs, N. and Du, S. and Stolfo, S.},
	year         = 2014,
	booktitle    = {Proc. RAID'14. 172–191.Google scholar},
	note         = {Citation Key: boggs2014a}
}
@inproceedings{Boggs_Stolfo_2011,
	title        = {ALDR: A new metric for measuring effective layering of defenses},
	author       = {Boggs, N. and Stolfo, S.},
	year         = 2011,
	booktitle    = {Proc. Layered assurance workshop (LAW'11},
	note         = {Citation Key: boggs2011a}
}
@inproceedings{Bohme_Felegyhazi_2010,
	title        = {Optimal information security investment with penetration testing},
	author       = {B\"{o}hme, Rainer and F\'{e}legyh\'{a}zi, M\'{a}rk},
	year         = 2010,
	booktitle    = {International Conference on Decision and Game Theory for Security},
	publisher    = {Springer},
	pages        = {21–37}
}
@article{Bohme_Freiling_2008,
	title        = {On Metrics and Measurements},
	author       = {B\"{o}hme, R. and Freiling, F.},
	year         = 2008,
	publisher    = {Springer},
	note         = {Citation Key: boehme2008b},
	place        = {Berlin, Heidelberg},
	editor       = {Dependability Metrics, I.Eusgeld and Freiling, F.C. and Reussner, R.}
}
@article{Bohme_Moore,
	title        = {Security Metrics and Security Investment},
	author       = {Bohme, Rainer and Moore, Tyler},
	year         = 2013,
	pages        = 36
}
@inbook{Bohme_Nowey_2008,
	title        = {Economic Security Metrics},
	author       = {B\"{o}hme, Rainer and Nowey, Thomas},
	year         = 2008,
	booktitle    = {Dependability Metrics},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 4909,
	pages        = {176–187},
	doi          = {10.1007/978-3-540-68947-8\_15},
	isbn         = {978-3-540-68946-1},
	url          = {http://link.springer.com/10.1007/978-3-540-68947-8\_15},
	note         = {Citation Key: boehme2008a},
	place        = {Berlin, Heidelberg},
	abstractnote = {This chapter surveys economic approaches for security metrics, among which we could identify two main areas of research. One has its roots in investment and decision theory and is mainly pursued in the field of information technology-oriented business administration. It has yielded a number of quantitative metrics that can be applied as guidelines in investment decisions as well as for the evaluation of existing security measures. The second area of research has ancestors in micro-economics. It deals with market concepts to gather security-relevant information and extract quantitative indicators on information security properties.},
	editor       = {Eusgeld, Irene and Freiling, Felix C. and Reussner, RalfEditors}
}
@inproceedings{Bonneau_2012a,
	title        = {Statistical metrics for individual password strength},
	author       = {Bonneau, J.},
	year         = 2012,
	booktitle    = {Proc. International conference on security protocols},
	pages        = {76–86},
	note         = {Citation Key: bonneau2012a}
}
@inproceedings{Bonneau_2012b,
	title        = {The science of guessing: Analyzing an anonymized corpus of 70 million passwords},
	author       = {Bonneau, J.},
	year         = 2012,
	booktitle    = {Proc. IEEE symposium on security and privacy},
	pages        = {538–552},
	note         = {Citation Key: bonneau2012b}
}
@inproceedings{Borbor_Wang_Jajodia_Singhal_2016,
	title        = {Diversifying net- work services under cost constraints for better resilience against unknown attacks},
	author       = {Borbor, D. and Wang, L. and Jajodia, S. and Singhal, A.},
	year         = 2016,
	booktitle    = {30th annual IFIP WG 11.3 conference, DBSec},
	publisher    = {Springer International Publishing},
	pages        = {295–312},
	note         = {Citation Key: borbor2016a tex.citation-number: 117},
	place        = {Trento}
}
@inbook{Bos_2019,
	title        = {The cyber security body of knowledge},
	author       = {Bos, Herbert},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Operating Systems \& Virtualisation}
}
@article{Boutaba_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
@inproceedings{Boyer_McQueen_2007,
	title        = {Ideal based cyber security technical metrics for control systems},
	author       = {Boyer, W. and McQueen, M.},
	year         = 2007,
	booktitle    = {Proceedings of the 9th interna- tional conference on critical information infrastructures security (CRITIS'07},
	note         = {Citation Key: boyer2007a tex.citation-number: 20}
}
@article{Bruna_Zaremba_Szlam_LeCun_2014,
	title        = {Spectral Networks and Locally Connected Networks on Graphs},
	author       = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	year         = 2014,
	month        = may,
	journal      = {arXiv:1312.6203 [cs]},
	url          = {http://arxiv.org/abs/1312.6203},
	note         = {arXiv: 1312.6203},
	abstractnote = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.}
}
@article{Buczak_Guven_2016,
	title        = {A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection},
	author       = {Buczak, Anna L. and Guven, Erhan},
	year         = 2016,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 18,
	number       = 2,
	pages        = {1153–1176},
	doi          = {10.1109/COMST.2015.2494502},
	issn         = {2373-745X},
	abstractnote = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@inbook{Burnap_2019,
	title        = {The cyber security body of knowledge},
	author       = {Burnap, Pete},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Risk Management \& Governance}
}
@article{Burow_Carr_Brunthaler_Payer_Nash_Larsen_Franz_2016,
	title        = {Control-flow integrity: Precision, security, and performance},
	author       = {Burow, N. and Carr, S. and Brunthaler, S. and Payer, M. and Nash, J. and Larsen, P. and Franz, M.},
	year         = 2016,
	note         = {Citation Key: burow2016a}
}
@article{Burr_Dodson_Polk_2006,
	title        = {Electronic authentication guideline},
	author       = {Burr, W. and Dodson, D. and Polk, W.},
	year         = 2006,
	url          = {http://csrc.nist.gov/publications/nistpubs/800-63/SP800-63V1\_0\_2.pdf.Google},
	note         = {Citation Key: burr2006a tex.type: NIST publication 800-63 version 1.0.2.}
}
@article{C.I.S._2010,
	title        = {The CIS security metrics},
	author       = {C.I.S.},
	year         = 2010,
	url          = {http://benchmarks.cisecurity.org/downloads/metrics/.},
	note         = {Citation Key: c2010a}
}
@inproceedings{cao2015grarep,
	title        = {Grarep: Learning graph representations with global structural information},
	author       = {Cao, Shaosheng and Lu, Wei and Xu, Qiongkai},
	year         = 2015,
	booktitle    = {Proceedings of CIKM},
	pages        = {891--900}
}
@inbook{Capkun_2019,
	title        = {The cyber security body of knowledge},
	author       = {\v{C}apkun, Srdjan},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Physical Layer \& Telecommunications}
}
@inbook{Cardenas_2019,
	title        = {The cyber security body of knowledge},
	author       = {Cardenas, Alvaro},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Cyber-Physical Systems Security}
}
@inproceedings{Cardenas_Baras_Seamon_2006,
	title        = {A framework for the evaluation of intrusion detection systems},
	author       = {Cardenas, A. and Baras, J. and Seamon, K.},
	year         = 2006,
	booktitle    = {Proc. IEEE 2006 symposium on security and privacy. Google scholar},
	note         = {Citation Key: cardenas2006a}
}
@article{Carin_Cybenko_Hughes_2008,
	title        = {Cybersecurity strategies: The QuERIES methodology},
	author       = {Carin, L. and Cybenko, G. and Hughes, J.},
	year         = 2008,
	journal      = {IEEE Comput},
	volume       = {41, 8},
	pages        = {20–26},
	note         = {Citation Key: carin2008a}
}
@inproceedings{Carlini_Barresi_Payer_Wagner_Gross_2015,
	title        = {Control-flow bending: On the effectiveness of control-flow integrity},
	author       = {Carlini, N. and Barresi, A. and Payer, M. and Wagner, D. and Gross, T.},
	year         = 2015,
	booktitle    = {24th USENIX security symposium},
	pages        = {161–176},
	note         = {Citation Key: carlini2015a}
}
@inproceedings{Carlini_Wagner_2014,
	title        = {ROP is still dangerous: Breaking modern defenses},
	author       = {Carlini, N. and Wagner, D.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {385–399},
	note         = {Citation Key: carlini2014a}
}
@article{Carnavalet_Mannan_2015,
	title        = {A large-scale evaluation of high-impact password strength meters},
	author       = {Carnavalet, X.De Carn\'{e} De and Mannan, M.},
	year         = 2015,
	journal      = {ACM TISSEC},
	volume       = {18, 1},
	number       = 1,
	note         = {Citation Key: carnavalet2015a}
}
@inbook{Carolina_2019,
	title        = {The cyber security body of knowledge},
	author       = {Carolina, Robert},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Law \& Regulation}
}
@inproceedings{Castelluccia_Durmuth_Perito_2012,
	title        = {Adaptive password-strength meters from markov models},
	author       = {Castelluccia, C. and D\"{u}rmuth, M. and Perito, D.},
	year         = 2012,
	booktitle    = {Proc. NDSS'12.Google scholar},
	note         = {Citation Key: castelluccia2012a}
}
@article{Chakrabarti_Govindarasu_2002,
	title        = {Internet infrastructure security: A taxonomy},
	author       = {Chakrabarti, A and Govindarasu, Manimaran},
	year         = 2002,
	month        = 12,
	journal      = {Network, IEEE},
	volume       = 16,
	pages        = {13–21},
	doi          = {10.1109/MNET.2002.1081761},
	abstractnote = {The pervasive and ubiquitous nature of the Internet coupled with growing concerns about cyber terrorism demand immediate solutions for securing the Internet infrastructure. So far, the research in Internet security primarily focused on. securing the information rather than securing the infrastructure itself. Given the prevailing threat situation, there is a compelling need to develop architectures, algorithms, and protocols to realize a dependable Internet infrastructure. In order to achieve this goal, the first and foremost step is to develop a comprehensive understanding of the security threats and existing solutions. This article attempts to fulfill this important step by providing a taxonomy of security attacks, which are classified into four main categories: DNS hacking, routing table poisoning, packet mistreatment, and denial-of-service attacks. The article discusses the existing solutions for each of these categories, and also outlines a methodology for developing secure protocols.}
}
@article{Chandola_Banerjee_Kumar_2009,
	title        = {Anomaly detection: A survey},
	author       = {Chandola, V. and Banerjee, A. and Kumar, V.},
	year         = 2009,
	journal      = {ACM Comput. Surv},
	volume       = {41, 3},
	number       = 1,
	note         = {Citation Key: chandola2009a tex.address: Google Scholar}
}
@article{Chandra_Harel_1985,
	title        = {Horn clause queries and generalizations},
	author       = {Chandra, Ashok K. and Harel, David},
	year         = 1985,
	journal      = {The Journal of Logic Programming},
	volume       = 2,
	number       = 1,
	pages        = {1–15}
}
@article{Chandramouli_Samarati_Ray_Ray_2018,
	title        = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	author       = {Chandramouli, Ramaswamy and Samarati, Pierangela and Ray, Indrakshi and Ray, Indrajit},
	year         = 2018,
	journal      = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	pages        = {55–77},
	doi          = {https://doi.org/10.1007/978-3-030-04834-1\_3},
	abstractnote = {Virtualization is the dominant technology employed in enterprise data centers and those used for offering cloud computing services. This technology has resulted in what is called a virtualized infrastructure.}
}

@book{Chang_2019,
	title        = {Implications of artificial intelligence for cybersecurity: Proceedings of a workshop},
	author       = {Sciences, National Academies of and Engineering and Medicine},
	year         = 2019,
	publisher    = {The National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488/implications-of-artificial-intelligence-for-cybersecurity-proceedings-of-a-workshop},
	note         = {Citation Key: NAP25488},
	place        = {Washington, DC},
	abstractnote = {In recent years, interest and progress in the area of artificial intelligence (AI) and machine learning (ML) have boomed, with new applications vigorously pursued across many sectors. At the same time, the computing and communications technologies on which we have come to rely present serious security concerns: cyberattacks have escalated in number, frequency, and impact, drawing increased attention to the vulnerabilities of cyber systems and the need to increase their security. In the face of this changing landscape, there is significant concern and interest among policymakers, security practitioners, technologists, researchers, and the public about the potential implications of AI and ML for cybersecurity.National Academies of Sciences, Engineering, and Medicine convened a workshop on March 12-13, 2019 to discuss and explore these concerns. This publication summarizes the presentations and discussions from the workshop.},
	editor       = {Johnson, Anne and Grumbling, Emily}
}

@article{Chatzipoulidis_Michalopoulos_Mavridis_2015,
	title        = {Information infrastructure risk prediction through platform vulnerability analysis},
	author       = {Chatzipoulidis, A. and Michalopoulos, D. and Mavridis, I.},
	year         = 2015,
	month        = aug,
	journal      = {Journal of Systems and Software},
	volume       = 106,
	number       = {C},
	pages        = {28--41,},
	note         = {Citation Key: chatzipoulidis2015a tex.citation-number: 120}
}
@inproceedings{Chawla_Lazarevic_Hall_Bowyer_2003,
	title        = {SMOTEBoost: Improving prediction of the minority class in boosting},
	author       = {Chawla, Nitesh V. and Lazarevic, Aleksandar and Hall, Lawrence O. and Bowyer, Kevin W.},
	year         = 2003,
	booktitle    = {European Conference on Principles of Data Mining and Knowledge Discovery},
	publisher    = {Springer},
	pages        = {107–119},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-39804-2\_12}
}
@article{Chen,
	title        = {Directed Graph Embedding},
	author       = {Chen, Mo},
	pages        = 6,
	abstractnote = {In this paper, we propose the Directed Graph Embedding (DGE) method that embeds vertices on a directed graph into a vector space by considering the link structure of graphs. The basic idea is to preserve the locality property of vertices on a directed graph in the embedded space. We use the transition probability together with the stationary distribution of Markov random walks to measure such locality property. It turns out that by exploring the directed links of the graph using random walks, we can get an optimal embedding on the vector space that preserves the local affinity which is inherent in the directed graph. Experiments on both synthetic data and real-world Web page data are considered. The application of our method to Web page classification problems gets a significant improvement comparing with state-of-art methods.}
}
@inproceedings{Chen_Ji_2007,
	title        = {Measuring network-aware worm spreading ability},
	author       = {Chen, Z. and Ji, C.},
	year         = 2007,
	booktitle    = {Proc. INFOCOM'2007},
	pages        = {116–124},
	note         = {Citation Key: chen2007a}
}
@inproceedings{Cheng_Deng_Li_DeLoach_Singhal_Ou_2014,
	title        = {Metrics of Security},
	author       = {Cheng, Yi and Deng, Julia and Li, Jason H. and DeLoach, Scott A. and Singhal, Anoop and Ou, Xinming},
	year         = 2014,
	journal      = {Cyber Defense and Situational Awareness},
	booktitle    = {Cyber Defense and Situational Awareness},
	volume       = 62,
	pages        = {263–295},
	doi          = {10.1007/978-3-319-11391-3\_13},
	note         = {tex.ids: cheng2014a},
	abstractnote = {Discussion of challenges and ways of improving Cyber Situational Awareness dominated our previous chapters. However, we have not yet touched on how to quantify any improvement we might achieve. Indeed, to get an accurate assessment of network security and provide sufficient Cyber Situational Awareness (CSA), simple but meaningful metrics--the focus of the Metrics of Security chapter--are necessary. The adage, ``what can't be measured can't be effectively managed,'' applies here. Without good metrics and the corresponding evaluation methods, security analysts and network operators cannot accurately evaluate and measure the security status of their networks and the success of their operations. In particular, this chapter explores two distinct issues: (i) how to define and use metrics as quantitative characteristics to represent the security state of a network, and (ii) how to define and use metrics to measure CSA from a defender's point of view.},
	editor       = {Kott, Alexander and Wang, Cliff and Erbacher, Robert F.}
}
@inproceedings{Cheng_Wang_Jajodia_Singhal_2012,
	title        = {Aggregating CVSS Base Scores for Semantics-Rich Network Security Metrics},
	author       = {Cheng, Pengsu and Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop},
	year         = 2012,
	month        = oct,
	booktitle    = {2012 IEEE 31st Symposium on Reliable Distributed Systems},
	publisher    = {IEEE},
	pages        = {31–40},
	doi          = {10.1109/SRDS.2012.4},
	isbn         = {978-1-4673-2397-0},
	url          = {http://ieeexplore.ieee.org/document/6424837/},
	note         = {tex.ids: cheng2012a},
	place        = {Irvine, CA, USA},
	abstractnote = {A network security metric is desirable in evaluating the effectiveness of security solutions in distributed systems. Aggregating CVSS scores of individual vulnerabilities provides a practical approach to network security metric. However, existing approaches to aggregating CVSS scores usually cause useful semantics of individual scores to be lost in the aggregated result. In this paper, we address this issue through two novel approaches. First, instead of taking each base score as an input, our approach drills down to the underlying base metric level where dependency relationships have well-defined semantics. Second, our approach interprets and aggregates the base metrics from three different aspects in order to preserve corresponding semantics of the individual scores. Finally, we confirm the advantages of our approaches through simulation.}
}
@article{Cherdantseva_2016,
	title        = {A review of cyber security risk assessment methods for SCADA systems},
	author       = {Cherdantseva, Y.},
	year         = 2016,
	month        = feb,
	journal      = {Comput. Security},
	volume       = 56,
	pages        = {1–27},
	note         = {tex.ids: cherdantseva2016a tex.citation-number: 143.}
}
@article{Chew_Swanson_Stine_Bartol_Brown_Robinson_2008,
	title        = {Performance Measurement Guide for Information Security},
	author       = {Chew, Elizabeth and Swanson, Marianne M. and Stine, Kevin M. and Bartol, N. and Brown, Anthony and Robinson, W.},
	year         = 2008,
	month        = {07},
	booktitle    = {National Institute of Standards and Technology (NIST), Tech},
	publisher    = {Rep},
	url          = {https://www.nist.gov/publications/performance-measurement-guide-information-security},
	note         = {Citation Key: chew2008a},
	abstractnote = {This document provides guidance on how an organization, through the use of metrics, identifies the adequacy of in-place security controls, policies, and procedu}
}
@inproceedings{Cho_Cam_Oltramari_2016,
	title        = {Effect of personality traits on trust and risk to phishing vulnerability: Modeling and analysis},
	author       = {Cho, J. and Cam, H. and Oltramari, A.},
	year         = 2016,
	booktitle    = {Proc. IEEE CogSIMA'16.Google scholar},
	note         = {Citation Key: cho2016a}
}
@inproceedings{Cho_Hurley_Xu_2016,
	title        = {Metrics and measurement of trustworthy systems},
	author       = {Cho, Jin-Hee and Hurley, Patrick M. and Xu, Shouhuai},
	year         = 2016,
	month        = nov,
	booktitle    = {MILCOM 2016 - 2016 IEEE Military Communications Conference},
	publisher    = {IEEE},
	pages        = {1237–1242},
	doi          = {10.1109/MILCOM.2016.7795500},
	isbn         = {978-1-5090-3781-0},
	url          = {http://ieeexplore.ieee.org/document/7795500/},
	place        = {Baltimore, MD, USA},
	abstractnote = {Accurate measurement of the quality of systems is crucial to building trustworthy systems. Such a measurement indicates whether a system is working properly and meeting its requirements. Although security and dependability metrics are regarded as key metrics for measuring the quality of systems, they are not sufficient for measuring the quality of systems that are placed in a multi-domain environment including hardware, software, network, human factors, and physical environments. In order to embrace multidimensional aspects of the quality of a system, we introduce a trustworthiness metric framework that supports three key submetrics of trust, resilience, and agility, and propose an ontology-based framework with three corresponding sub-ontologies. We also discuss how the key metrics are related to the severity of threats and the quality of assessment tools. This work is part of the cyber defense effort conducted by the Trustworthy Systems Working Group (TSWG) under the Cyber Strategic Challenge Group (CSCG) of The Technical Cooperation Program (TTCP), which is an international cooperation organization for enhancing defense science and technology.}
}
@inproceedings{Chowdhary_Pisharody_Huang_2016,
	title        = {SDN based Scalable MTD solution in Cloud Network},
	author       = {Chowdhary, Ankur and Pisharody, Sandeep and Huang, Dijiang},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 ACM Workshop on Moving Target Defense  - MTD'16},
	publisher    = {ACM Press},
	pages        = {27–36},
	doi          = {10.1145/2995272.2995274},
	isbn         = {978-1-4503-4570-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2995272.2995274},
	place        = {Vienna, Austria},
	abstractnote = {Software-Defined Networking (SDN) has emerged as a framework for centralized command and control in cloud data centric environments. SDN separates data and control plane, which provides network administrator better visibility and policy enforcement capability compared to traditional networks. The SDN controller can assess reachability information of all the hosts in a network. There are many critical assets in a network which can be compromised by a malicious attacker through a multistage attack. Thus we make use of centralized controller to assess the security state of the entire network and pro-actively perform attack analysis and countermeasure selection. This approach is also known as Moving Target Defense (MTD). We use the SDN controller to assess the attack scenarios through scalable Attack Graphs (AG) and select necessary countermeasures to perform network reconfiguration to counter network attacks. Moreover, our framework has a comprehensive conflict detection and resolution module that ensures that no two flow rules in a distributed SDN-based cloud environment have conflicts at any layer; thereby assuring consistent conflict-free policy implementation and preventing information leakage.}
}
@inproceedings{cipher_benchmark,
	title        = {Survey and Benchmark of Lightweight Block Ciphers for Wireless Sensor Networks},
	year         = 2013,
	booktitle    = {Proceedings of the 10th International Conference on Security and Cryptography},
	publisher    = {SCITEPRESS - Science and and Technology Publications},
	pages        = {543–548},
	doi          = {10.5220/0004530905430548},
	isbn         = {978-989-8565-73-0},
	url          = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0004530905430548},
	place        = {Reykjav\'{\i}k, Iceland}
}
@article{cis_cic,
	title        = {CIS Controls V7 Measures \& Metrics},
	journal      = {CIS},
	url          = {https://www.cisecurity.org/white-papers/cis-controls-v7-measures-metrics/},
	abstractnote = {CIS Controls are updated \& reviewed in collaboration with international cybersecurity experts and IT professionals in various industries.}
}
@article{Corporation,
	title        = {Structured Threat Information eXpression (STIX\texttrademark{})},
	author       = {Corporation, The MITRE},
	pages        = 18
}
@article{Costa_Russo_Armando,
	title        = {Automating the Generation of Cyber Range Virtual Scenarios with VSDL},
	author       = {Costa, Gabriele and Russo, Enrico and Armando, Alessandro},
	pages        = 19,
	abstractnote = {A cyber range is an environment used for training security experts and testing attack and defence tools and procedures. Usually, a cyber range simulates one or more critical infrastructures that attacking (red) and defending (blue) teams must compromise and protect, respectively. The infrastructure can be physically assembled, but much more convenient is to rely on the Infrastructure as a Service (IaaS) paradigm. Although some modern technologies support the IaaS, the design and deployment of scenarios of interest is mostly a manual operation. As a consequence, it is a common practice to have a cyber range hosting few (sometimes only one), consolidated scenarios. However, reusing the same scenario may significantly reduce the effectiveness of the training and testing sessions.}
}
@article{Council_2007,
	title        = {Hard problem list},
	author       = {Council, I.N.F.O.S.E.C.Research},
	year         = 2007,
	url          = {http://www.infosec-research.org/},
	note         = {Citation Key: council2007a}
}
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@inproceedings{Da_Xu_Xu_2014,
	title        = {A new approach to modeling and analyzing security of networked systems},
	author       = {Da, G. and Xu, M. and Xu, S.},
	year         = 2014,
	booktitle    = {Proc. HotSoS'14. Google scholar},
	note         = {Citation Key: da2014a}
}
@inproceedings{Dacier_1994,
	title        = {Privilege Graph: An Extension to the Typed Access Matrix Model},
	author       = {Dacier, Marc and Deswarte, Yves},
	year         = 1994,
	booktitle    = {Proceedings of the Third European Symposium on Research in Computer Security},
	publisher    = {Springer-Verlag},
	address      = {London, UK, UK},
	series       = {ESORICS '94},
	pages        = {319--334},
	isbn         = {3-540-58618-0},
	url          = {http://dl.acm.org/citation.cfm?id=646645.699167},
	numpages     = 16,
	acmid        = 699167
}
@article{Dacier_Deswarte_Kaaniche,
	title        = {Quantitative Assessment of Operational Security: Models and Tools},
	author       = {Dacier, Marc and Deswarte, Yves and Ka\^{a}niche, Mohamed},
	year         = 1996,
	journal      = {Information Systems Security, ed. by SK Katsikas and D. Gritzalis, London, Chapman \& Hall},
	pages        = 23,
	note         = {Citation Key: dacier1996b tex.citation-number: 71},
	abstractnote = {This paper proposes a novel approach to help computing system administrators in monitoring the security of their systems. This approach is based on modeling the system as a privilege graph exhibiting operational security vulnerabilities and on transforming this privilege graph into a Markov chain corresponding to all possible successful attack scenarios. A set of tools has been developed to generate automatically the privilege graph of a Unix system, to transform it into the corresponding Markov chain and to compute characteristic measures of the operational system security.}
}
@inbook{Dacier_Deswarte_Kaaniche_1996a,
	title        = {Information Systems Secu- rity: Facing the information society of the 21st century},
	author       = {Dacier, M. and Deswarte, Y. and Ka\^{a}niche, M.},
	year         = 1996,
	booktitle    = {ch. Models and tools for quantitative assessment of operational security},
	publisher    = {Springer US},
	pages        = {177–186},
	note         = {Citation Key: dacier1996a tex.citation-number: 70},
	place        = {Boston, MA}
}
@inproceedings{Dagon_Gu_Lee_Lee_2007,
	title        = {A taxonomy of botnet structures},
	author       = {Dagon, D. and Gu, G. and Lee, C. and Lee, W.},
	year         = 2007,
	booktitle    = {Proc. ACSAC'07. 325–339.Google Scholar},
	note         = {Citation Key: dagon2007a}
}
@inproceedings{Dagon_Zou_Lee_2006,
	title        = {Modeling botnet propagation using time zones},
	author       = {Dagon, D. and Zou, C. and Lee, W.},
	year         = 2006,
	booktitle    = {Proc. NDSS'06.Google Scholar},
	note         = {Citation Key: dagon2006a}
}
@article{Dai_Li_Tian_Huang_Wang_Zhu_Song_2018,
	title        = {Adversarial Attack on Graph Structured Data},
	author       = {Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.02371 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.02371},
	note         = {arXiv: 1806.02371},
	abstractnote = {Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.}
}
@inbook{Dalvi_Domingos_Mausam_Verma_2004,
	title        = {Adversarial classification},
	author       = {Dalvi, N. and Domingos, P. and Mausam, S.Sanghai and Verma, D.},
	year         = 2004,
	booktitle    = {Proc},
	volume       = {KDD'04},
	pages        = {99–108},
	note         = {Citation Key: dalvi2004a}
}
@book{Dantu_Kolan_2005,
	title        = {Risk Management Using Behavior Based Bayesian Networks},
	author       = {Dantu, R. and Kolan, P.},
	year         = 2005,
	publisher    = {Springer},
	note         = {Citation Key: dantu2005a tex.citation-number: 110},
	place        = {Berlin, Heidelberg}
}
@article{Dantu_Kolan_Cangussu_2009,
	title        = {Network risk management using attacker profiling},
	author       = {Dantu, R. and Kolan, P. and Cangussu, J.},
	year         = 2009,
	month        = jan,
	journal      = {Security and Communication Networks},
	volume       = 2,
	number       = 1,
	pages        = {83--96,},
	note         = {Citation Key: dantu2009a tex.citation-number: 109}
}
@inproceedings{Dantu_Loper_Kolan_2004,
	title        = {Risk management using behavior based attack graphs},
	author       = {Dantu, R. and Loper, K. and Kolan, P.},
	year         = 2004,
	month        = apr,
	booktitle    = {International Conference on Information Technology: Coding and Computing, 2004. Proceedings. ITCC 2004.},
	volume       = 1,
	pages        = {445--449 Vol.1},
	doi          = {10.1109/ITCC.2004.1286496},
	note         = {tex.ids: dantu2004a tex.citation-number: 111 ISSN: null},
	abstractnote = {Security administration is an uphill task to implement in an enterprise network providing secured corporate services. With the slew of patches being released by Microsoft, HP and other vendors, system administrators require a barrage of tools for analyzing the risk due to these vulnerabilities. In addition to this, criticalities in patching some end hosts (e.g., in hospitals) raises serious security issues about the network to which the end hosts are connected. In this context, it would be imperative to know the risk level of all critical resources (e.g., Oracle Server in HR department) keeping in view the everyday emerging new vulnerabilities. We hypothesize that sequence of network actions by an attacker depends on the social behavior (e.g., skill level, tenacity, financial ability). By verifying our hypothesis on hacker email communications, we extended this methodology and calculated risk level for a small network. Towards this goal, we formulated a mechanism to estimate the risk level of critical resources that may be compromised based on attacker behavior. This estimation is accomplished using behavior based attack graphs. These graphs represent all the possible attack paths to all the critical resources. Based on these graphs, we calculate the risk level of a critical resource using Bayesian methodology and periodically update the subjective beliefs about the occurrence of an attack. Such a calculated risk level would be a measure of the vulnerability of the resource and it forms an effective basis for a system administrator to perform suitable changes to network configuration. Thus suitable vulnerability analysis and risk management strategies can be formulated to efficiently curtail the risk from different types of attacker (script kiddies, hackers, criminals and insiders).}
}
@inproceedings{DaSilva_Ferreira_deGeus_2012,
	title        = {A methodology for management of cloud computing using security criteria},
	author       = {Da Silva, Carlos Alberto and Ferreira, Anderson Soares and de Geus, Paulo Licio},
	year         = 2012,
	booktitle    = {2012 IEEE Latin America Conference on Cloud Computing and Communications (LatinCloud)},
	publisher    = {IEEE},
	pages        = {49–54}
}
@inproceedings{Davi_Sadeghi_Lehmann_Monrose_2014,
	title        = {Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection},
	author       = {Davi, L. and Sadeghi, A. and Lehmann, D. and Monrose, F.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {401–416},
	note         = {Citation Key: davi2014a}
}
@inbook{Debar_2019,
	title        = {The cyber security body of knowledge},
	author       = {Debar, Herv\'{e}},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Security Operations \& Inicident Management}
}
@article{Debievre_2009,
	title        = {The 2007 International Vocabulary of Metrology (VIM), JCGM 200:2008 [ISO/IEC Guide 99]: Meeting the need for intercontinentally understood concepts and their associated intercontinentally agreed terms},
	author       = {De Bi\`{e}vre, Paul},
	year         = 2009,
	month        = mar,
	journal      = {Clinical Biochemistry},
	series       = {Highlight Section: Quality \& Accreditation in Laboratory Medicine},
	volume       = 42,
	number       = 4,
	pages        = {246–248},
	doi          = {10.1016/j.clinbiochem.2008.09.007},
	issn         = {0009-9120},
	abstractnote = {Unambiguous and consistent concepts and terms such as measurand, metrological traceability, measurement uncertainty, comparability of measurement results, target measurement uncertainty, etc., must govern the description of measurements in order to enable a valid comparison of measurement results. That is not yet the case as numerous workshops over the last decade have shown worldwide and as chemical literature continuously displays. For international trade in food and feed to be fair, for border-crossing implementation of environmental regulations to be the same for all parties concerned, for interchangeability of results of clinical measurements to become a reality, for any border-crossing interpretation of measurement results in chemistry to become possible, well understood and mutually accepted, common and well defined concepts and terms are essential. Similarly, their translations from one language – English – to 30–40 other languages, must be realized and fixed unequivocally. Countries using English as common language have not yet fully realized that they are at a considerable advantage over countries where such translated terms describing concepts may not yet be available, let alone understood and accepted. A number of ambiguities in the definitions and terms are described which illustrate the importance of the revision (1997–2007) of the International Vocabulary of Metrology (VIM), henceforth conveniently called ``VIM3'', especially since chemical measurement is covered in this VIM for the first time in history:`measurand'`metrological comparability of measurement results'`metrology'`metrological compatibility of measurement results'`measurement result'`metrological traceability' (incl `to the SI')`measurement uncertainty'`target measurement uncertainty'`calibration hierarchy'`quantity'and many others. It is concluded that the revised VIM is of primordial importance for good understanding within and between the measurement communities worldwide.},
	collection   = {Highlight Section: Quality \& Accreditation in Laboratory Medicine}
}
@inbook{deFranco_Rosa_Jino_2017,
	title        = {A Survey of Security Assessment Ontologies},
	author       = {de Franco Rosa, Ferrucio and Jino, Mario},
	year         = 2017,
	booktitle    = {Recent Advances in Information Systems and Technologies},
	publisher    = {Springer International Publishing},
	volume       = 569,
	pages        = {166–173},
	doi          = {10.1007/978-3-319-56535-4\_17},
	isbn         = {978-3-319-56534-7},
	url          = {http://link.springer.com/10.1007/978-3-319-56535-4\_17},
	place        = {Cham},
	abstractnote = {A literature survey on ontologies concerning the Security Assessment domain has been carried out to uncover initiatives that aim at formalizing concepts from the ``Security Assessment'' field of research. A preliminary analysis and a discussion on the selected works are presented. Our main contribution is an updated literature review, describing key characteristics, results, research issues, and application domains of the papers. We have also detected gaps in the Security Assessment literature that could be the subject of further studies in the field. This work is meant to be useful for security researchers who wish to adopt a formal approach in their methods.},
	editor       = {Rocha, \'{A}lvaro and Correia, Ana Maria and Adeli, Hojjat and Reis, Lu\'{\i}s Paulo and Costanzo, SandraEditors}
}
@inproceedings{DellAmico_Michiardi_Roudier_2010,
	title        = {Password strength: An empirical analysis},
	author       = {DellAmico, M. and Michiardi, P. and Roudier, Y.},
	year         = 2010,
	booktitle    = {Proc. INFOCOM'10},
	pages        = {983–991},
	note         = {Citation Key: dellamico2010a}
}
@article{Denker,
	title        = {Large Automatic Learning, Rule Extraction, and Generalization},
	author       = {Denker, John},
	pages        = 46
}
@inproceedings{Desmedt_Frankel_1989,
	title        = {Threshold cryptosystems},
	author       = {Desmedt, Y. and Frankel, Y.},
	year         = 1989,
	booktitle    = {Proc. Crypto},
	pages        = {307–315},
	note         = {Citation Key: desmedt1989a}
}
@article{Dhillon_2011,
	title        = {Developer-Driven Threat Modeling: Lessons Learned in the Trenches},
	author       = {Dhillon, Danny},
	year         = 2011,
	month        = {07},
	journal      = {IEEE Security \& Privacy},
	volume       = 9,
	number       = 4,
	pages        = {41–47},
	doi          = {10.1109/MSP.2011.47},
	issn         = {1540-7993}
}
@article{Dijkstra_1959,
	title        = {A note on two problems in connexion with graphs},
	author       = {Dijkstra, Edsger W.},
	year         = 1959,
	journal      = {Numerische mathematik},
	volume       = 1,
	number       = 1,
	pages        = {269–271}
}
@book{Donovan_Prabhu_2017,
	title        = {Building the Network of the Future: Getting Smarter, Faster, and More Flexible with a Software Centric Approach},
	author       = {Donovan, John and Prabhu, Krish},
	year         = 2017,
	publisher    = {CRC Press}
}
@inproceedings{Dua_Du_2011,
	title        = {Data Mining and Machine Learning in Cybersecurity},
	author       = {Dua, Sumeet and Du, Xian},
	year         = 2011,
	doi          = {10.1201/b10867},
	abstractnote = {With the rapid advancement of information discovery techniques, machine learning and data mining continue to play a significant role in cybersecurity. Although several conferences, workshops, and journals focus on the fragmented research topics in this area, there has been no single interdisciplinary resource on past and current works and possible paths for future research in this area. This book fills this need. From basic concepts in machine learning and data mining to advanced problems in the machine learning domain, Data Mining and Machine Learning in Cybersecurity provides a unified reference for specific machine learning solutions to cybersecurity problems. It supplies a foundation in cybersecurity fundamentals and surveys contemporary challengesdetailing cutting-edge machine learning and data mining techniques. It also: Unveils cutting-edge techniques for detectingnew attacks Contains in-depth discussions of machine learning solutions to detection problems Categorizes methods for detecting, scanning, and profiling intrusions and anomalies Surveys contemporary cybersecurity problems and unveils state-of-the-art machine learning and data mining solutions Details privacy-preserving data mining methods This interdisciplinary resource includes technique review tables that allow for speedy access to common cybersecurity problems and associated data mining methods. Numerous illustrative figures help readers visualize the workflow of complex techniques and more than forty case studies provide a clear understanding of the design and application of data mining and machine learning techniques in cybersecurity.}
}
@inproceedings{Duan_Wang_Mohsen_Al-Shaer_2013,
	title        = {Private and anony- mous data storage and distribution in cloud},
	author       = {Duan, Q. and Wang, Y. and Mohsen, F. and Al-Shaer, E.},
	year         = 2013,
	month        = jun,
	booktitle    = {Services computing (SCC), 2013 IEEE international conference on},
	pages        = {264–271},
	note         = {Citation Key: duan2013a tex.citation-number: 37}
}
@article{Duggan_Michalski,
	title        = {Threat Analysis Framework},
	author       = {Duggan, David P and Michalski, John T},
	pages        = 31,
	abstractnote = {The need to protect national critical infrastructure has led to the development of a threat analysis framework. The threat analysis framework can be used to identify the elements required to quantify threats against critical infrastructure assets and provide a means of distributing actionable threat information to critical infrastructure entities for the protection of infrastructure assets. This document identifies and describes five key elements needed to perform a comprehensive analysis of threat: the identification of an adversary, the development of generic threat profiles, the identification of generic attack paths, the discovery of adversary intent, and the identification of mitigation strategies.}
}
@inproceedings{Dumitras_Shou_2011,
	title        = {Toward a standard benchmark for computer security research: the worldwide intelligence network environment (WINE)},
	author       = {Dumitras, Tudor and Shou, Darren},
	year         = 2011,
	booktitle    = {Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security - BADGERS '11},
	publisher    = {ACM Press},
	pages        = {89–96},
	doi          = {10.1145/1978672.1978683},
	isbn         = {978-1-4503-0768-0},
	url          = {http://portal.acm.org/citation.cfm?doid=1978672.1978683},
	place        = {Salzburg, Austria},
	abstractnote = {Unlike benchmarks that focus on performance or reliability evaluations, a benchmark for computer security must necessarily include sensitive code and data. Because these artifacts could damage systems or reveal personally identifiable information about the users affected by cyber attacks, publicly disseminating such a benchmark raises several scientific, ethical and legal challenges. We propose the Worldwide Intelligence Network Environment (WINE), a security-benchmarking approach based on rigorous experimental methods. WINE includes representative field data, collected worldwide from 240,000 sensors, for new empirical studies, and it will enable the validation of research on all the phases in the lifecycle of security threats. We tackle the key challenges for security benchmarking by designing a platform for repeatable experimentation on the WINE data sets and by collecting the metadata required for understanding the results. In this paper, we review the unique characteristics of the WINE data, we discuss why rigorous benchmarking will provide fresh insights on the security arms race and we propose a research agenda for this area.}
}
@inproceedings{durumeric2014a,
	title        = {The matter of heartbleed},
	author       = {Durumeric, Z. and Kasten, J. and Adrian, D. and Halderman, J. and Bailey, M. and Li, F. and Weaver, N. and Amann, J. and Beekman, J. and Payer, M. and et al.},
	year         = 2014,
	booktitle    = {Proc. ACM IMC'14},
	pages        = {475–488},
	note         = {Citation Key: durumeric2014a}
}
@inbook{Edwards_Hofmeyr_Forrest_2015,
	title        = {Hype and heavy tails: A closer look at data breaches},
	author       = {Edwards, B. and Hofmeyr, S. and Forrest, S.},
	year         = 2015,
	booktitle    = {Proc WEIS'15. 67–78.Google Scholar},
	note         = {Citation Key: edwards2015a}
}
@article{Ellison,
	title        = {Ceremony Design and Analysis},
	author       = {Ellison, Carl},
	pages        = 17,
	abstractnote = {The concept of ceremony is introduced as an extension of the concept of network protocol, with human nodes alongside computer nodes and with communication links that include UI, human-to-human communication and transfers of physical objects that carry data. What is out-of-band to a protocol is in-band to a ceremony, and therefore subject to design and analysis using variants of the same mature techniques used for the design and analysis of protocols. Ceremonies include all protocols, as well as all applications with a user interface, all workflow and all provisioning scenarios. A secure ceremony is secure against both normal attacks and social engineering. However, some secure protocols imply ceremonies that cannot be made secure.}
}
@inproceedings{Eskridge_Carvalho_Stoner_Toggweiler_Granados_2015,
	title        = {VINE: A cyber emulation environment for MTD experimentation},
	author       = {Eskridge, T. and Carvalho, M. and Stoner, E. and Toggweiler, T. and Granados, A.},
	year         = 2015,
	booktitle    = {Proc. ACM MTD'15},
	pages        = {43–47},
	note         = {Citation Key: eskridge2015a}
}
@article{Evans_2008,
	title        = {NSF/IARPA/NSA Workshop on the Science of Security},
	author       = {Evans, D.},
	year         = 2008,
	journal      = {Also see http://sos. cs. virginia. edu/., University of Virginia}
}
@article{F.I.R.S.T._2015,
	title        = {Forum of incident response and security teams: Common vulnerability scoring system (CVSS) version 3.0},
	author       = {F.I.R.S.T.},
	year         = 2015,
	url          = {https://www.first.org/cvss.},
	note         = {Citation Key: f2015a}
}
@inbook{Fahl_2019,
	title        = {The cyber security body of knowledge},
	author       = {Fahl, Sascha},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Web \& Mobile Security}
}
@article{Fleming_Wallace_1986,
	title        = {How not to lie with statistics: the correct way to summarize benchmark results},
	author       = {Fleming, Philip J. and Wallace, John J.},
	year         = 1986,
	month        = mar,
	journal      = {Communications of the ACM},
	volume       = 29,
	number       = 3,
	pages        = {218–221},
	doi          = {10.1145/5666.5673},
	issn         = {00010782}
}
@inproceedings{Foley_Bistarelli_OSullivan_Herbert_Swart_2005,
	title        = {Multilevel security and quality of protection},
	author       = {Foley, S.N. and Bistarelli, S. and O'Sullivan, B. and Herbert, J. and Swart, G.},
	year         = 2005,
	booktitle    = {Quality of protection workshop at ESORICS 2005, the flagship european symposium on research in computer security},
	publisher    = {Springer US},
	pages        = {93–105},
	note         = {Citation Key: foley2005a tex.citation-number: 56},
	place        = {Boston, MA}
}
@inproceedings{Ford_Keefe_LeMay_Sanders_Muehrcke_2013,
	title        = {Implementing the advise security modeling formalism in mobius},
	author       = {Ford, M.D. and Keefe, K. and LeMay, E. and Sanders, W.H. and Muehrcke, C.},
	year         = 2013,
	month        = jun,
	booktitle    = {2013 43rd annual IEEE/IFIP international conference on dependable systems and networks (DSN},
	pages        = {1–8},
	note         = {Citation Key: ford2013a tex.citation-number: 128}
}
@article{Franks_Hallam-Baker_Hostetler_Lawrence_Leach_Luotonen_Stewart_1999,
	title        = {HTTP authentication: Basic and digest access authentication},
	author       = {Franks, J. and Hallam-Baker, P. and Hostetler, J. and Lawrence, S. and Leach, P. and Luotonen, A. and Stewart, L.},
	year         = 1999,
	note         = {Citation Key: franks1999a tex.citation-number: 60 tex.type: Internet RFC 2617,}
}
@article{Frei_Feb_2010,
	title        = {The security exposure of SOoftware portfolios},
	author       = {Frei, S. and Feb, T.Kristensen},
	year         = 2010,
	url          = {https://secunia.com/gfx/pdf/Secunia\_RSA\_Software\_Portfolio\_Security\_Exposure.pdf.},
	note         = {Citation Key: frei2010a}
}
@inproceedings{Frigault_Wang_2008,
	title        = {Measuring Network Security Using Bayesian Network-Based Attack Graphs},
	author       = {Frigault, Marcel and Wang, Lingyu},
	year         = 2008,
	month        = jan,
	booktitle    = {Computer software and applications, 2008. COMPSAC '08. 32nd annual IEEE international},
	pages        = {698–703},
	doi          = {10.1109/COMPSAC.2008.88},
	isbn         = {978-0-7695-3262-2},
	note         = {tex.ids: frigault2008b, frigaultMeasuringNetworkSecurity2008a},
	abstractnote = {Given the increasing dependence of our societies on information systems, the overall security of these systems should be measured and improved. Existing work generally focuses on measuring individual vulnerabilities instead of measuring their combined effects. Recent research has explored the application of attack graphs and probabilistic security metrics to address this challenge. However, such work usually assumes metrics of individual vulnerabilities to be independently distributed and combines them in an arbitrary manner. They cannot address more realistic cases, such as exploiting one vulnerability makes another vulnerability easier to exploit. In this paper, we propose to model probability metrics based on attack graphs as a special Bayesian Network. This approach provides a sound theoretical foundation to such metrics. It can also provide the capabilities of using conditional probabilities to address the general cases of interdependency between vulnerabilities.}
}
@inproceedings{Frigault_Wang_Singhal_Jajodia_2008,
	title        = {Measuring network security using dynamic bayesian network},
	author       = {Frigault, M. and Wang, L. and Singhal, A. and Jajodia, S.},
	year         = 2008,
	booktitle    = {Proc. QoP'08},
	pages        = {23–30},
	note         = {Citation Key: frigault2008a tex.ids: frigault2008b tex.citation-number: 106}
}
@inproceedings{Gaffney,
	title        = {Evaluation of intrusion detectors: A decision theory approach},
	author       = {Gaffney, Jr, J. and Ulvila, J.},
	year         = 2001,
	booktitle    = {Proc. IEEE symposium on security and privacy},
	pages        = {50–61},
	note         = {Citation Key: gaffney2001a},
	jr_ulvila_2001 = {null}
}
@inproceedings{Gerstel_Sasaki_2001,
	title        = {Quality of protection (QoP): a quanti- tative unifying paradigm to protection service grades},
	author       = {Gerstel, O. and Sasaki, G.H.},
	year         = 2001,
	month        = aug,
	booktitle    = {Proc. SPIE 4599, OptiComm 2001: Optical networking and communications},
	pages        = 12,
	note         = {Citation Key: gerstel2001a tex.citation-number: 63}
}
@article{Ghosh_Bhattacharya_2012,
	title        = {Analytical framework for measuring network security using exploit dependency graph},
	author       = {Ghosh, S. and Bhattacharya, P.},
	year         = 2012,
	month        = dec,
	journal      = {IET Information Security},
	volume       = 6,
	number       = 4,
	pages        = {264--270,},
	note         = {Citation Key: ghosh2012a tex.citation-number: 112}
}
@inproceedings{Goktas_Athanasopoulos_Bos_Portokalidis_2014,
	title        = {Out of control: Overcoming control-flow integrity},
	author       = {G\"{o}ktas, E. and Athanasopoulos, E. and Bos, H. and Portokalidis, G.},
	year         = 2014,
	booktitle    = {Proc. IEEE Security and Privacy},
	pages        = {575–589},
	note         = {Citation Key: goektas2014a}
}
@inbook{Gollmann_2019,
	title        = {The cyber security body of knowledge},
	author       = {Gollmann, Dieter},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Authentication, Authorisation \& Accountability}
}
@article{Gordon_Loeb,
	title        = {The economics of information security investment},
	author       = {Gordon, Lawrence A and Loeb, Martin P},
	journal      = {ACM Transactions on Information and System Security},
	volume       = 5,
	number       = 4,
	pages        = 20
}
@article{Gordon_Loeb_2006,
	title        = {Budgeting process for information security expenditures},
	author       = {Gordon, L. and Loeb, M.},
	year         = 2006,
	journal      = {Communications of the ACM},
	volume       = {49, 1},
	pages        = {121–125},
	note         = {Citation Key: gordon2006a}
}
@article{Goyal_Ferrara_2018,
	title        = {Graph Embedding Techniques, Applications, and Performance: A Survey},
	author       = {Goyal, Palash and Ferrara, Emilio},
	year         = 2018,
	month        = jul,
	journal      = {Knowledge-Based Systems},
	volume       = 151,
	pages        = {78–94},
	doi          = {10.1016/j.knosys.2018.03.022},
	issn         = {09507051},
	note         = {arXiv: 1705.02801},
	abstractnote = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.}
}
@article{Granjal_Monteiro_Silva_2015,
	title        = {Security for the internet of things: A survey of existing protocols and open research issues},
	author       = {Granjal, J. and Monteiro, E. and Silva, J.S.},
	year         = 2015,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 17,
	number       = 3,
	pages        = {1294--1312,},
	note         = {Citation Key: granjal2015a tex.citation-number: 139}
}
@inproceedings{grover2016node2vec,
	title        = {node2vec: Scalable feature learning for networks},
	author       = {Grover, Aditya and Leskovec, Jure},
	year         = 2016,
	booktitle    = {Proceedings of KDD},
	pages        = {855--864}
}
@article{Grubesic_Matisziw_Murray_Snediker_2008a,
	title        = {Comparative approaches for assessing network vulnerability},
	author       = {Grubesic, Tony H. and Matisziw, Timothy C. and Murray, Alan T. and Snediker, Diane},
	year         = 2008,
	month        = jan,
	journal      = {International Regional Science Review},
	volume       = 31,
	number       = 1,
	pages        = {88–112},
	doi          = {10.1177/0160017607308679},
	abstractnote = {A common theme in analysis and evaluation of network-based critical infrastructure is the assessment of system vulnerability. Graph theoretic, simulation, and optimization-based tech-niques have played a significant role in examining potential network vulnerabilities given the insights they can provide for mitigating facility loss and prioritizing fortification efforts. Cen-tral to these approaches is the concept of facility (arc–node) importance or criticality to sys-tem survivability. Assessments of network vulnerability can dramatically differ based on how facility importance is characterized. In this review, various approaches for assessing facility importance and network vulnerability are examined. The key differences in these approaches are the ways in which a facility's role in maintaining network operability is evaluated given arc–node disruption. Comparative results suggest significant differences exist among mea-sures of facility importance and network performance. Furthermore, the subsequent incon-gruities in these measures and their implications need to be clearly understood to support interdiction risk and vulnerability assessment for critical infrastructures.}
}
@inproceedings{Gu_Cardenas_Lee_2008,
	title        = {Principled reasoning and practical applications of alert fusion in intrusion detection systems},
	author       = {Gu, G. and C\'{a}rdenas, A. and Lee, W.},
	year         = 2008,
	booktitle    = {Proc. ACM ASIACCS'08},
	pages        = {136–147},
	note         = {Citation Key: gu2008a}
}
@inproceedings{Gu_Fogla_Dagon_Lee_Skoric_2006,
	title        = {Measuring intrusion detection capability: An information-theoretic approach},
	author       = {Gu, G. and Fogla, P. and Dagon, D. and Lee, W. and Skori\'{c}, B.},
	year         = 2006,
	booktitle    = {Proc. AsiaCCS'06},
	pages        = {90–101},
	note         = {Citation Key: gu2006a tex.citation-number: 39}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@book{Hall:2013:ACM:2601666,
	title        = {Ansible Configuration Management},
	author       = {Hall, Daniel},
	year         = 2013,
	publisher    = {Packt Publishing},
	isbn         = 9781783280810
}
@article{Hamilton_Ying_Leskovec,
	title        = {Representation Learning on Graphs: Methods and Applications},
	author       = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
	pages        = 23,
	abstractnote = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph convolutional networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.}
}
@article{Han_Lu_Xu_2014,
	title        = {Characterizing the power of moving target defense via cyber epidemic dynamics},
	author       = {Han, Y. and Lu, W. and Xu, S.},
	year         = 2014,
	journal      = {Proc. HotSoS'14},
	volume       = 10,
	number       = 1,
	note         = {Citation Key: han2014a}
}
@article{Hansman_Hunt_2005,
	title        = {A taxonomy of network and computer attacks},
	author       = {Hansman, Simon and Hunt, Ray},
	year         = 2005,
	journal      = {Computers \& Security},
	volume       = 24,
	number       = 1,
	pages        = {31–43},
	note         = {tex.ids: hansman2005a tex.citation-number: 1}
}
@inproceedings{Haque_Keffeler_Atkison_2017,
	title        = {An Evolutionary Approach of Attack Graphs and Attack Trees: A Survey of Attack Modeling},
	author       = {Haque, S. and Keffeler, M. and Atkison, T.},
	year         = 2017,
	booktitle    = {Proceedings of the International Conference on Security and Management (SAM); Athens},
	publisher    = {The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp)},
	pages        = {224–229},
	url          = {https://search.proquest.com/docview/2139471619/abstract/7169E9EF244F4076PQ/1},
	place        = {Athens, United States, Athens},
	abstractnote = {The advancement of modern day computing has led to an increase of threats and intrusions. As a result, advanced security measures and threat analysis models are necessary to detect these threats and identify protective measures needed to secure a system. The most popular forms of attack modeling today are attack graphs and attack trees. This literature summarizes the different approaches through an extensive survey of the relevant papers and identifies the current challenges, requirements and limitations of efficient attack modeling.}
}
@inproceedings{Hardy_Crete-Nishihata_Kleemola_Senft_Sonne_Wiseman_Gill_Deibert_2014,
	title        = {Targeted threat index: Characterizing and quantifying politically-motivated targeted malware},
	author       = {Hardy, S. and Crete-Nishihata, M. and Kleemola, K. and Senft, A. and Sonne, B. and Wiseman, G. and Gill, P. and Deibert, R.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium. Google scholar},
	note         = {Citation Key: hardy2014a}
}
@inproceedings{Hecker_2008,
	title        = {On System Security Metrics and the Definition Approaches},
	author       = {Hecker, Artur},
	year         = 2008,
	month        = aug,
	booktitle    = {2008 Second International Conference on Emerging Security Information, Systems and Technologies},
	pages        = {412–419},
	doi          = {10.1109/SECURWARE.2008.37},
	issn         = {2162-2116},
	note         = {tex.ids: hecker2008a tex.citation-number: 13 ISSN: 2162-2116},
	abstractnote = {In this survey paper, we assess existing approaches to security metric definition. We classify proposed definitions and discuss their advantages and problems. We argue that without a more restrictive definition, the apparently common term degenerates to a mere buzzword, which can be dangerous in terms of suggested comparability. We conclude with some guidelines on IS metric definition and sketch an alternative concept for the operational IS security evaluation.}
}
@inproceedings{Heinzle_Furnell_2013,
	title        = {Assessing the feasibility of security metrics},
	author       = {Heinzle, Bernhard and Furnell, Steven},
	year         = 2013,
	booktitle    = {International Conference on Trust, Privacy and Security in Digital Business},
	publisher    = {Springer},
	pages        = {149–160},
	note         = {tex.ids: heinzle2013a tex.citation-number: 19}
}
@article{Henderson_Bacic_Froh_2005,
	title        = {Dynamic Asset Protection and Risk Management Abstraction Study},
	author       = {Henderson, G and Bacic, E and Froh, M},
	year         = 2005,
	pages        = 50
}
@inbook{Herlands_Hobson_Donovan_2014,
	title        = {Effective entropy: Security-centric metric for memory randomization techniques},
	author       = {Herlands, W. and Hobson, T. and Donovan, P.},
	year         = 2014,
	booktitle    = {Workshop on Cyber Security Experimentation and Test. Google Scholar},
	note         = {Citation Key: herlands2014a}
}
@book{Herrmann_2007,
	title        = {Complete guide to security and privacy metrics: Measuring regulatory compliance, operational resilience, and ROI},
	author       = {Herrmann, D.S.},
	year         = 2007,
	publisher    = {Auerbach Publication},
	note         = {Citation Key: herrmann2007a tex.citation-number: 38}
}
@inproceedings{Hlyne_Zavarsky_Butakov_2015,
	title        = {SCAP benchmark for Cisco router security configuration compliance},
	author       = {Hlyne, Chit Nyi Nyi and Zavarsky, Pavol and Butakov, Sergey},
	year         = 2015,
	month        = dec,
	booktitle    = {2015 10th International Conference for Internet Technology and Secured Transactions (ICITST)},
	publisher    = {IEEE},
	pages        = {270–276},
	doi          = {10.1109/ICITST.2015.7412104},
	isbn         = {978-1-908320-52-0},
	url          = {http://ieeexplore.ieee.org/document/7412104/},
	place        = {London, United Kingdom},
	abstractnote = {Information security management is timeconsuming and error-prone. Apart from day-to-day operations, organizations need to comply with industrial regulations or government directives. Thus, organizations are looking for security tools to automate security management tasks and daily operations. Security Content Automation Protocol (SCAP) is a suite of specifications that help to automate security management tasks such as vulnerability measurement and policy compliance evaluation. SCAP benchmark provides detailed guidance on setting the security configuration of network devices, operating systems, and applications. Organizations can use SCAP benchmark to perform automated configuration compliance assessment on network devices, operating systems, and applications. This paper discusses SCAP benchmark components and the development of a SCAP benchmark for automating Cisco router security configuration compliance.}
}
@article{Holm_2014,
	title        = {A large-scale study of the time required to compromise a computer system},
	author       = {Holm, H.},
	year         = 2014,
	journal      = {IEEE TDSC},
	volume       = {11, 1},
	pages        = {2–15},
	note         = {Citation Key: holm2014a}
}
@article{Holm_Ekstedt_Andersson_2012,
	title        = {Empirical analysis of system-level vulnerability metrics through actual attacks},
	author       = {Holm, H. and Ekstedt, M. and Andersson, D.},
	year         = 2012,
	month        = nov,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 9,
	number       = 6,
	pages        = {825--837,},
	note         = {Citation Key: holm2012a tex.citation-number: 134}
}
@article{Homer_Zhang_Ou_Schmidt_Du_Rajagopalan_Singhal_2013,
	title        = {Aggregating vulnerability metrics in enterprise networks using attack graphs},
	author       = {Homer, John and Zhang, Su and Ou, Xinming and Schmidt, David and Du, Yanhui and Rajagopalan, S. Raj and Singhal, Anoop},
	year         = 2013,
	month        = sep,
	journal      = {Journal of Computer Security},
	volume       = 21,
	number       = 4,
	pages        = {561–597},
	doi          = {10.3233/JCS-130475},
	issn         = {18758924, 0926227X},
	note         = {tex.ids: homer2013a, homerAggregatingVulnerabilityMetrics2013a, homerAggregatingVulnerabilityMetrics2013b tex.citation-number: 102.},
	abstractnote = {Quantifying security risk is an important and yet difficult task in enterprise network security management. While metrics exist for individual software vulnerabilities, there is currently no standard way of aggregating such metrics. We present a model that can be used to aggregate vulnerability metrics in an enterprise network, producing quantitative metrics that measure the likelihood breaches can occur within a given network configuration. A clear semantic model for this aggregation is an important first step toward a comprehensive network security metric model. We utilize existing work in attack graphs and apply probabilistic reasoning to produce an aggregation that has clear semantics and sound computation. We ensure that shared dependencies between attack paths have a proportional effect on the final calculation. We correctly reason over cycles, ensuring that privileges are evaluated without any self-referencing effect. We introduce additional modeling artifacts in our probabilistic graphical model to capture and account for hidden correlations among exploit steps. The paper shows that a clear semantic model for aggregation is critical in interpreting the results, calibrating the metric model, and explaining insights gained from empirical evaluation. Our approach has been rigorously evaluated using a number of network models, as well as data from production systems.}
}
@inproceedings{Hong_Kim_Takaoka_2013,
	title        = {Scalable Attack Representation Model Using Logic Reduction Techniques},
	author       = {Hong, J. B. and Kim, D. S. and Takaoka, T.},
	year         = 2013,
	month        = {07},
	booktitle    = {2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications},
	pages        = {404–411},
	doi          = {10.1109/TrustCom.2013.51},
	abstractnote = {Automated construction methods of attack graphs (AGs) and their improved attack representation models (ARMs) have been proposed, but the AG has a state space explosion when analysing the security of very large sized networked systems. Instead, attack trees (ATs) and their improved ARMs can be used (e.g., Defense Trees, Protection Trees, Attack Response Trees, and Attack Countermeasure Trees), because they are a non-state-space model. However, there are no known methods to construct ATs in a scalable manner automatically while maintaining all possible attack scenarios. We can use an AG generation tools, and transform the AG into the AT using min-cuts. However, this method requires a transformation (i.e., an overhead), and computing min-cuts is a NP-hard problem. Another way is to construct ATs directly with given network information. A naive approach is to compute all possible attack paths and populate the AT branches using logic gates (e.g., AND and OR gates), but this method generates an exponential number of nodes, causing a scalability problem. We propose two logic reduction techniques to automate the ATs construction and to reduce the size of the AT. The computational complexity is calculated. The simulation result shows the construction time for the naive method and two logic reduction techniques. The trade-off between the construction time and the memory usage of simplified ATs are also shown.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker's goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@inbook{Howe_Ray_Roberts_Urbanska_Byrne_2012,
	title        = {The psychology of security for the home computer user},
	author       = {Howe, A. and Ray, I. and Roberts, M. and Urbanska, M. and Byrne, Z.},
	year         = 2012,
	booktitle    = {IEEE symp. on security and privacy},
	pages        = {209–223},
	note         = {Citation Key: howe2012a}
}
@article{Huang_Joseph_Nelson_Rubinstein_Tygar,
	title        = {Adversarial machine learning},
	author       = {Huang, Ling and Joseph, Anthony D and Nelson, Blaine and Rubinstein, Benjamin I P and Tygar, J D},
	pages        = 15,
	note         = {tex.ids: huang2011a},
	abstractnote = {In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning--the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques.}
}
@article{Hutchins_Cloppert_Amin,
	title        = {Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains},
	author       = {Hutchins, Eric M and Cloppert, Michael J and Amin, Rohan M},
	pages        = 14,
	abstractnote = {Conventional network defense tools such as intrusion detection systems and anti-virus focus on the vulnerability component of risk, and traditional incident response methodology presupposes a successful intrusion. An evolution in the goals and sophistication of computer network intrusions has rendered these approaches insufficient for certain actors. A new class of threats, appropriately dubbed the ``Advanced Persistent Threat'' (APT), represents well-resourced and trained adversaries that conduct multi-year intrusion campaigns targeting highly sensitive economic, proprietary, or national security information. These adversaries accomplish their goals using advanced tools and techniques designed to defeat most conventional computer network defense mechanisms. Network defense techniques which leverage knowledge about these adversaries can create an intelligence feedback loop, enabling defenders to establish a state of information superiority which decreases the adversary's likelihood of success with each subsequent intrusion attempt. Using a kill chain model to describe phases of intrusions, mapping adversary kill chain indicators to defender courses of action, identifying patterns that link individual intrusions into broader campaigns, and understanding the iterative nature of intelligence gathering form the basis of intelligence-driven computer network defense (CND). Institutionalization of this approach reduces the likelihood of adversary success, informs network defense investment and resource prioritization, and yields relevant metrics of performance and effectiveness. The evolution of advanced persistent threats necessitates an intelligence-based model because in this model the defenders mitigate not just vulnerability, but the threat component of risk, too.}
}
@article{I.S.O./I.E.C._2002,
	title        = {Information technology - systems security engineering - capability maturity model (SSE-CMM), ISO/IEC 21827},
	author       = {I.S.O./I.E.C.},
	year         = 2002,
	pages        = {132,},
	note         = {Citation Key: i2002a tex.address: Geneva, Switzerland tex.citation-number: 30}
}
@article{Idika_Bhargava_2012,
	title        = {Extending attack graph-based security metrics and aggregating their application},
	author       = {Idika, Nwokedi and Bhargava, Bharat},
	year         = 2012,
	journal      = {IEEE Transactions on dependable and secure computing},
	volume       = 9,
	number       = 1,
	pages        = {75–85},
	note         = {tex.ids: idika2012a, idikaExtendingAttackGraphBased2012 tex.citation-number: 10}
}
@inproceedings{Idika_Marshall_Bhargava_2009,
	title        = {Maximizing network security given a limited budget},
	author       = {Idika, N.C. and Marshall, B.H. and Bhargava, B.K.},
	year         = 2009,
	booktitle    = {The fifth richard tapia celebration of diversity in computing conference: Intellect, initiatives, insight, and innovations, ser. TAPIA '09},
	publisher    = {ACM},
	pages        = {12–17},
	note         = {Citation Key: idika2009a tex.citation-number: 136},
	place        = {New York, NY, USA}
}
@inbook{Isaksson_Dunham_Hahsler_2012,
	title        = {SOStream: Self Organizing Density-Based Clustering over Data Stream},
	author       = {Isaksson, Charlie and Dunham, Margaret H. and Hahsler, Michael},
	year         = 2012,
	booktitle    = {Machine Learning and Data Mining in Pattern Recognition},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 7376,
	pages        = {264–278},
	isbn         = {978-3-642-31536-7},
	url          = {http://link.springer.com/10.1007/978-3-642-31537-4\_21},
	place        = {Berlin, Heidelberg},
	editor       = {Perner, PetraEditor}
}
@article{iso_27004,
	title        = {ISO/IEC 27004:2016},
	author       = {14:00-17:00},
	journal      = {ISO},
	url          = {http://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/06/41/64120.html},
	abstractnote = {Information technology -- Security techniques -- Information security management -- Monitoring, measurement, analysis and evaluation}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@inproceedings{Jaatun_2012,
	title        = {Hunting for aardvarks: Can software security be measured?'' in IFIP WG 8.4, 8.9/TC 5},
	author       = {Jaatun, M.G.},
	year         = 2012,
	booktitle    = {International cross-domain conference and workshop on availability, reliability, and security, CD-ARES 2012},
	note         = {Citation Key: jaatun2012a tex.citation-number: 24}
}
@inproceedings{Jajodia_2007,
	title        = {Topological analysis of network attack vulnerability},
	author       = {Jajodia, S.},
	year         = 2007,
	booktitle    = {Proceedings of the 2Nd ACM symposium on information, computer and communications security, ser. ASIACCS '07},
	publisher    = {ACM},
	pages        = {2–2},
	note         = {Citation Key: jajodia2007a tex.citation-number: 9},
	place        = {New York, NY, USA}
}
@article{Jansen_2009,
	title        = {Directions in Security Metrics Research},
	author       = {Jansen, Wayne},
	year         = 2009,
	month        = apr,
	doi          = {https://doi.org/10.6028/NIST.IR.7564},
	url          = {https://csrc.nist.gov/publications/detail/nistir/7564/final},
	note         = {tex.ids: jansen2009a, jansenDirectionsSecurityMetrics2009a},
	abstractnote = {More than 100 years ago, Lord Kelvin insightfully observed that measurement is vital to deep knowledge and understanding in physical science. During the last few decades, researchers have made various attempts to develop measures and systems of measurement for computer security with varying degrees of success. This paper provides an overview of the security metrics area and looks at possible avenues of research that could be pursued to advance the state of the art.},
	institution  = {U.S. National Institute of Standards and Technology}
}
@book{Jaquith_2007,
	title        = {Security Metrics: Replacing Fear, Uncertainty, and Doubt},
	author       = {Jaquith, Andrew},
	year         = 2007,
	month        = mar,
	publisher    = {Pearson Education},
	isbn         = {978-0-13-271577-5},
	note         = {tex.ids: jaquith2007a, jaquithSecurityMetricsReplacing2007a tex.citation-number: 7 googlebooksid: Af8F00gTRN4C tex.publisher: Addison-Wesley Professional},
	abstractnote = {The Definitive Guide to Quantifying, Classifying, and Measuring Enterprise IT Security Operations      Security Metrics is the first comprehensive best-practice guide to defining, creating, and utilizing security metrics in the enterprise.    Using sample charts, graphics, case studies, and war stories, Yankee Group Security Expert Andrew Jaquith demonstrates exactly how to establish effective metrics based on your organization's unique requirements. You'll discover how to quantify hard-to-measure security activities, compile and analyze all relevant data, identify strengths and weaknesses, set cost-effective priorities for improvement, and craft compelling messages for senior management.     Security Metrics successfully bridges management's quantitative viewpoint with the nuts-and-bolts approach typically taken by security professionals. It brings together expert solutions drawn from Jaquith's extensive consulting work in the software, aerospace, and financial services industries, including new metrics presented nowhere else. You'll learn how to:   \textbullet{} Replace nonstop crisis response with a systematic approach to security improvement \textbullet{} Understand the differences between ``good'' and ``bad'' metrics \textbullet{} Measure coverage and control, vulnerability management, password quality, patch latency, benchmark scoring, and business-adjusted risk \textbullet{} Quantify the effectiveness of security acquisition, implementation, and other program activities  \textbullet{} Organize, aggregate, and analyze your data to bring out key insights \textbullet{} Use visualization to understand and communicate security issues more clearly  \textbullet{} Capture valuable data from firewalls and antivirus logs, third-party auditor reports, and other resources \textbullet{} Implement balanced scorecards that present compact, holistic views of organizational security effectiveness}
}
@inbook{Jha_2019,
	title        = {The cyber security body of knowledge},
	author       = {Jha, Sanjah},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Network Security}
}
@article{Jha_Sheyner_Wing,
	title        = {Minimization and Reliability Analyses of Attack Graphs},
	author       = {Jha, Somesh and Sheyner, Oleg and Wing, Jeannette M},
	pages        = 31
}
@inproceedings{Jha_Sheyner_Wing_2002,
	title        = {Two formal analys s of attack graphs},
	author       = {Jha, S. and Sheyner, O. and Wing, J.},
	year         = 2002,
	booktitle    = {Proc. IEEE CSF},
	pages        = {49–59},
	note         = {Citation Key: jha2002a tex.citation-number: 79}
}
@inproceedings{Jibao_Huiqiang_Liang_2006,
	title        = {Study of network security situa- tion awareness model based on simple additive weight and grey theory},
	author       = {Jibao, L. and Huiqiang, W. and Liang, Z.},
	year         = 2006,
	month        = nov,
	booktitle    = {2006 international conference on computational intelligence and security},
	volume       = 2,
	pages        = {1545–1548},
	note         = {Citation Key: jibao2006a tex.citation-number: 51}
}
@inproceedings{Johnson_2013,
	title        = {Why don't software developers use static analysis tools to find bugs?},
	author       = {Johnson, Brittany and Song, Yoonki and Murphy-Hill, Emerson and Bowdidge, Robert},
	year         = 2013,
	month        = {05},
	booktitle    = {2013 35th International Conference on Software Engineering (ICSE)},
	publisher    = {IEEE},
	pages        = {672–681},
	doi          = {10.1109/ICSE.2013.6606613},
	isbn         = {978-1-4673-3076-3},
	url          = {http://ieeexplore.ieee.org/document/6606613/},
	place        = {San Francisco, CA, USA}
}
@inproceedings{Johnson_Chuang_Grossklags_Christin_2012,
	title        = {Metrics for measuring ISP badness: The case of spam},
	author       = {Johnson, B. and Chuang, J. and Grossklags, J. and Christin, N.},
	year         = 2012,
	booktitle    = {Proc. FC'12. 89–97.Google scholar},
	note         = {Citation Key: johnson2012a}
}
@article{Jonsson_Olovsson_1997,
	title        = {A quantitative model of the security intrusion process based on attacker behavior},
	author       = {Jonsson, Erland and Olovsson, Tomas},
	year         = 1997,
	month        = apr,
	journal      = {IEEE Transactions on Software Engineering; New York},
	volume       = 23,
	number       = 4,
	pages        = {235–245},
	doi          = {http://dx.doi.org/10.1109/32.588541},
	issn         = {00985589},
	note         = {tex.ids: jonsson1997a, jonssonQuantitativeModelSecurity1997a tex.citation-number: 69},
	abstractnote = {The conceptual framework in which security can be split into 2 generic types of characteristics, behavioral and preventive, is discussed. Based on empirical data collected from intrusion experts, a hypothesis is worked out on typical attacker behavior. The hypothesis suggests that the attacking process can be split into 3 phases: 1. the learning phase, 2. the standard attack phase and 3. the innovative attack phase. The probability for successful attacks during the learning and innovative phases is expected to be small, although for different reasons. During the standard attack phase it is expected to be considerably higher.}
}
@article{journa_1,
	volume       = 2,
	number       = 2,
	pages        = 6,
	abstractnote = {An intrusion detection system is software that monitors a single or a network of computers for malicious activities that are aimed at stealing or censoring information or corrupting network protocols. Most technique used in today's intrusion detection system are not able to deal with the dynamic and complex nature of cyber-attacks on computer networks. Even though efficient adaptive methods like various techniques of machine learning can result in higher detection rates, lower false alarm rates and reasonable computation and communication cost. With the use of data mining can result in frequent pattern mining, classification, clustering and mini data stream. This survey paper describes a focused literature survey of machine learning and data mining methods for cyber analytics in support of intrusion detection. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in machine learning and data mining approaches, some well-known cyber data sets used in machine learning and data mining are described for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@inproceedings{Kaaniche_Alata_Nicomette_Deswarte_Dacier_2006,
	title        = {Empirical analysis and statistical modeling of attack processes based on honeypots},
	author       = {Kaaniche, M. and Alata, E. and Nicomette, V. and Deswarte, Y. and Dacier, M.},
	year         = 2006,
	booktitle    = {IEEE/IFIP international conference on dependable systems and networks (DSN-2006},
	pages        = {119–124},
	note         = {Citation Key: kaaniche2006a tex.citation-number: 129}
}
@inproceedings{Kang_Hauswald_Gao_Rovinski_Mudge_Mars_Tang_2017,
	title        = {Neurosurgeon: Collaborative intelligence between the cloud and mobile edge},
	author       = {Kang, Yiping and Hauswald, Johann and Gao, Cao and Rovinski, Austin and Mudge, Trevor and Mars, Jason and Tang, Lingjia},
	year         = 2017,
	booktitle    = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher    = {ACM},
	pages        = {615–629}
}
@inproceedings{Kanoun_Cuppens_Boulahia_Cuppens_Dubus_Martin_2009,
	title        = {Success Likelihood of Ongoing Attacks for Intrusion Detection and Response Systems},
	author       = {Kanoun, Wael and Cuppens-Boulahia, Nora and Cuppens, Fr\'{e}d\'{e}ric and Dubus, Samuel and Martin, Antony},
	year         = 2009,
	month        = aug,
	booktitle    = {2009 International Conference on Computational Science and Engineering},
	volume       = 3,
	pages        = {83–91},
	doi          = {10.1109/CSE.2009.233},
	issn         = {null},
	abstractnote = {Intrusion Detection and Response Systems have become a core component in modern security architectures. Current researches are combining intrusion detection and response systems with risk analysis or cost-sensitive approaches to enhance the detection and the response procedure, by assessing the risk of detected attacks and candidate countermeasures. The Risk has two primary dimensions: (i) the likelihood of success of the attack(s), and (ii) the impact of the attack(s) and the countermeasure(s).In this paper, we present a model to assess the success likelihood of attack objectives. This model can be used by intrusion detection and response systems to identify candidate ongoing scenarios, calculate dynamically the likelihood of success for each of them considering the progress of the attack and the state of the target system, and finally prioritize candidate intrusion objectives and associated countermeasures.}
}
@article{Kanoun_Dubus_Papillon_Cuppens_Boulahia_Cuppens_2012,
	title        = {Towards Dynamic Risk Management: Success Likelihood of Ongoing Attacks},
	author       = {Kanoun, Wael and Dubus, Samuel and Papillon, Serge and Cuppens-Boulahia, Nora and Cuppens, Fr\'{e}d\'{e}ric},
	year         = 2012,
	journal      = {Bell Labs Technical Journal},
	volume       = 17,
	number       = 3,
	pages        = {61–78},
	doi          = {10.1002/bltj.21558},
	issn         = {1538-7305},
	note         = {tex.ids: kanoun2012a tex.citation-number: 80},
	abstractnote = {The proliferation of sophisticated cyberattacks, coupled with the steady growth of information and communication technology (ICT) systems in size and complexity, provides motivation for continuous improvements in security management. For day-to-day operation, security officers and administrators need an effective response (or decision aid) system to handle ongoing cyberattacks. Effective countermeasures must minimize the risks induced by these attacks, noting that the risk is evaluated as a function of the success likelihood and the impact of an attack. In this paper, we demonstrate how to dynamically calculate the success likelihood (SL) for an ongoing attack by considering the progress of an attacker towards his objective. Afterwards, we present a response/decision aid system based on the SL metric. Finally, we present the Success Likelihood Assessment Module (SLAM), which implements and highlights the relevance of our work for real time security management. This paper focuses on the operational aspects of a security by design approach. \textcopyright{} 2012 Alcatel-Lucent.}
}
@inbook{Karjoth_Pfitzmann_Schunter_Waidner_2006,
	title        = {Service- oriented assurance comprehensive security by explicit assurances},
	author       = {Karjoth, G. and Pfitzmann, B. and Schunter, M. and Waidner, M.},
	year         = 2006,
	booktitle    = {Quality of protection},
	publisher    = {Springer US},
	pages        = {13–24},
	note         = {Citation Key: karjoth2006a tex.citation-number: 62},
	place        = {Boston, MA},
	editor       = {Gollmann, D. and Massacci, F. and Yautsiukhin, A.}
}
@inproceedings{Kelley_Komanduri_Mazurek_Shay_Vidas_Bauer_Christin_Cranor_Lopez,
	title        = {Guess again (and again and again): Measuring password strength by simulating password-cracking algorithms},
	author       = {Kelley, Patrick Gage and Komanduri, Saranga and Mazurek, Michelle L and Shay, Richard and Vidas, Timothy and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Lopez, Julio},
	pages        = 15,
	issn         = {1081-6011},
	note         = {tex.ids: kelley2012a, kelleyGuessAgainAgain2012},
	abstractnote = {Text-based passwords remain the dominant authentication method in computer systems, despite significant advancement in attackers' capabilities to perform password cracking. In response to this threat, password composition policies have grown increasingly complex. However, there is insufficient research defining metrics to characterize password strength and using them to evaluate password-composition policies. In this paper, we analyze 12,000 passwords collected under seven composition policies via an online study. We develop an efficient distributed method for calculating how effectively several heuristic password-guessing algorithms guess passwords. Leveraging this method, we investigate (a) the resistance of passwords created under different conditions to guessing; (b) the performance of guessing algorithms under different training sets; (c) the relationship between passwords explicitly created under a given composition policy and other passwords that happen to meet the same requirements; and (d) the relationship between guessability, as measured with password-cracking algorithms, and entropy estimates. Our findings advance understanding of both password-composition policies and metrics for quantifying password security.}
}
@book{Khosravi_Anderson_2003,
	title        = {Requirements for separation of IP control and forwarding},
	author       = {Khosravi, Horzmud and Anderson, Todd},
	year         = 2003,
	publisher    = {RFC 3654, November}
}
@article{King_Zeng_2001,
	title        = {Logistic regression in rare events data},
	author       = {King, Gary and Zeng, Langche},
	year         = 2001,
	journal      = {Political analysis},
	volume       = 9,
	number       = 2,
	pages        = {137–163}
}
@article{Kingma_Ba_2014,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik and Ba, Jimmy},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.6980},
	url          = {https://arxiv.org/abs/1412.6980}
}
@article{kipf2016semi,
	title        = {Semi-Supervised Classification with Graph Convolutional Networks},
	author       = {Kipf, Thomas N and Welling, Max},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1609.02907}
}
@book{Kirkham_2012,
	title        = {Issues with Private IP Addressing in the Internet},
	author       = {Kirkham, Anthony},
	year         = 2012
}
@article{Knowles_Prince_Hutchison_Disso_Jones_2015,
	title        = {A survey of cyber security management in industrial control systems},
	author       = {Knowles, W. and Prince, D. and Hutchison, D. and Disso, J.F.P. and Jones, K.},
	year         = 2015,
	month        = jun,
	journal      = {International Journal of Critical Infrastructure Protection},
	volume       = 9,
	number       = {C},
	pages        = {52--80,},
	note         = {Citation Key: knowles2015a tex.citation-number: 142}
}
@inproceedings{Konte_Perdisci_Feamster_2015,
	title        = {ASwatch: An AS Reputation System to Expose Bulletproof Hosting ASes},
	author       = {Konte, Maria and Perdisci, Roberto and Feamster, Nick},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication - SIGCOMM '15},
	publisher    = {ACM Press},
	pages        = {625–638},
	doi          = {10.1145/2785956.2787494},
	isbn         = {978-1-4503-3542-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2785956.2787494},
	note         = {tex.ids: konte2015a},
	place        = {London, United Kingdom},
	abstractnote = {Bulletproof hosting Autonomous Systems (ASes)--malicious ASes fully dedicated to supporting cybercrime--provide freedom and resources for a cyber-criminal to operate. Their services include hosting a wide range of illegal content, botnet C\&C servers, and other malicious resources. Thousands of new ASes are registered every year, many of which are often used exclusively to facilitate cybercrime. A natural approach to squelching bulletproof hosting ASes is to develop a reputation system that can identify them for takedown by law enforcement and as input to other attack detection systems (e.g., spam filters, botnet detection systems). Unfortunately, current AS reputation systems rely primarily on data-plane monitoring of malicious activity from IP addresses (and thus can only detect malicious ASes after attacks are underway), and are not able to distinguish between malicious and legitimate but abused ASes.}
}
@article{Kordy_2013,
	title        = {DAG-Based Attack and Defense Modeling: Don't Miss the Forest for the Attack Trees},
	author       = {Kordy, Barbara and Pi\`{e}tre-Cambac\'{e}d\`{e}s, Ludovic and Schweitzer, Patrick},
	year         = 2013,
	month        = {03},
	journal      = {arXiv:1303.7397 [cs]},
	url          = {http://arxiv.org/abs/1303.7397},
	note         = {arXiv: 1303.7397},
	abstractnote = {This paper presents the current state of the art on attack and defense modeling approaches that are based on directed acyclic graphs (DAGs). DAGs allow for a hierarchical decomposition of complex scenarios into simple, easily understandable and quantifiable actions. Methods based on threat trees and Bayesian networks are two well-known approaches to security modeling. However there exist more than 30 DAG-based methodologies, each having different features and goals. The objective of this survey is to present a complete overview of graphical attack and defense modeling techniques based on DAGs. This consists of summarizing the existing methodologies, comparing their features and proposing a taxonomy of the described formalisms. This article also supports the selection of an adequate modeling technique depending on user requirements.}
}
@inbook{Kotenko_Doynikova_2014a,
	title        = {Security Assessment of Computer Networks Based on Attack Graphs and Security Events},
	author       = {Kotenko, Igor and Doynikova, Elena},
	year         = 2014,
	booktitle    = {Information and Communication Technology},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 8407,
	pages        = {462–471},
	doi          = {10.1007/978-3-642-55032-4\_47},
	isbn         = {978-3-642-55031-7},
	url          = {http://link.springer.com/10.1007/978-3-642-55032-4\_47},
	place        = {Berlin, Heidelberg},
	abstractnote = {Security assessment is an important task for operation of modern computer networks. The paper suggests the security assessment technique based on attack graphs which can be implemented in contemporary SIEM systems. It is based on the security metrics taxonomy and different techniques for calculation of security metrics according to the data about current events. Proposed metrics form the basis for security awareness and reflect current security situation, including development of attacks, attacks sources and targets, attackers' characteristics. The technique suggested is demonstrated on a case study.},
	editor       = {Linawati and Mahendra, Made Sudiana and Neuhold, Erich J. and Tjoa, A Min and You, IlsunEditors}
}
@inproceedings{Kotenko_Polubelova_Saenko_Doynikova_2013,
	title        = {The Ontology of Metrics for Security Evaluation and Decision Support in SIEM Systems},
	author       = {Kotenko, Igor and Polubelova, Olga and Saenko, Igor and Doynikova, Elena},
	year         = 2013,
	month        = sep,
	pages        = {638–645},
	doi          = {10.1109/ARES.2013.84},
	abstractnote = {Analysis of computer network security is a serious challenge. Many security metrics has been proposed for this purpose, but their effective use for rapid and reliable security evaluation and generation of countermeasures in SIEM systems remains an important problem. The use of ontologies for security information representation in SIEM systems contributes largely to the success of this task. However, most of works on ontological security data representation does not take into account the ontologies of security metrics. This paper proposes a new approach on using security metrics which is based on their ontological representation and serves for comprehensive security evaluation and subsequent countermeasure generation. The novelty of the proposed approach is that ontology of security metrics is viewed as a core component of a countermeasure decision support system. The proposed solutions are tested on a specific example.}
}
@inbook{Kott_2014,
	title        = {Towards fundamental science of cyber security},
	author       = {Kott, Alexander},
	year         = 2014,
	booktitle    = {Network science and cybersecurity},
	publisher    = {Springer},
	pages        = {1–13}
}
@article{Ksiezopolski_2012,
	title        = {QoP-ML: Quality of protection modelling language for cryptographic protocols},
	author       = {Ksiezopolski, B.},
	year         = 2012,
	month        = jun,
	journal      = {Computers \& Security},
	volume       = 31,
	number       = 4,
	pages        = {569--596,},
	note         = {Citation Key: ksiezopolski2012a tex.citation-number: 58}
}
@inproceedings{Kuhrer_Rossow_Holz_2014,
	title        = {Paint It Black: Evaluating the Effectiveness of Malware Blacklists},
	author       = {K\"{u}hrer, Marc and Rossow, Christian and Holz, Thorsten},
	year         = 2014,
	booktitle    = {Research in Attacks, Intrusions and Defenses},
	publisher    = {Springer International Publishing},
	volume       = 8688,
	pages        = {1–21},
	doi          = {10.1007/978-3-319-11379-1\_1},
	isbn         = {978-3-319-11378-4},
	url          = {http://link.springer.com/10.1007/978-3-319-11379-1\_1},
	note         = {tex.ids: kuehrer2014a},
	place        = {Cham},
	abstractnote = {Blacklists are commonly used to protect computer systems against the tremendous number of malware threats. These lists include abusive hosts such as malware sites or botnet Command \& Control and dropzone servers to raise alerts if suspicious hosts are contacted. Up to now, though, little is known about the effectiveness of malware blacklists. In this paper, we empirically analyze 15 public malware blacklists and 4 blacklists operated by antivirus (AV) vendors. We aim to categorize the blacklist content to understand the nature of the listed domains and IP addresses. First, we propose a mechanism to identify parked domains in blacklists, which we find to constitute a substantial number of blacklist entries. Second, we develop a graph-based approach to identify sinkholes in the blacklists, i.e., servers that host malicious domains which are controlled by security organizations. In a thorough evaluation of blacklist effectiveness, we show to what extent real-world malware domains are actually covered by blacklists. We find that the union of all 15 public blacklists includes less than 20\% of the malicious domains for a majority of prevalent malware families and most AV vendor blacklists fail to protect against malware that utilizes Domain Generation Algorithms.},
	editor       = {Stavrou, Angelos and Bos, Herbert and Portokalidis, Georgios}
}
@inproceedings{Kundu_Ghosh_Chokshi_Ghosh_2012,
	title        = {Analysis of attack graph-based metrics for quantification of network security},
	author       = {Kundu, A. and Ghosh, N. and Chokshi, I. and Ghosh, S. K.},
	year         = 2012,
	month        = dec,
	booktitle    = {2012 Annual IEEE India Conference (INDICON)},
	pages        = {530–535},
	doi          = {10.1109/INDCON.2012.6420675},
	abstractnote = {Computer network has grown both in size and complexity with the advent of Internet. It facilitates easy access to vast store of reference materials, collaborative computing, and information sharing. However, this requires a secure interconnected world of computing where confidentiality, integrity, and availability of information and resources are restored. Traditionally, security mechanism is enforced by access control and authentication. However, these security best practices do not take operating system, or network service-based or application vulnerabilities (programming flaws) into account. With the evolution of sophisticated hacking tools, attackers exploit these vulnerabilities and can gain legitimate access to network resources, bypassing the access control and authentication policies. One tool that presents a succinct representation of different attack scenarios specific to a network is attack graph. Attack graph models service or application-based attacks and depicts all possible multihost multi-step attack scenarios that an attacker can launch to penetrate into an enterprise network. The severity associated with each attack scenario can be evaluated following some attack graph-based security metrics. A good number of security metrics are prevalent in the literature, however, there exists no reported work which determines their efficacy and applicability. In this paper, a survey on attack graph-based metrics has been done and comparative analysis of the existing metrics has been presented to facilitate understanding of a given network's level of security strength. A case study has been perceived for the purpose of analysis.}
}
@inproceedings{Kutuzov_Dorgham_Oliynyk_Biemann_Panchenko_2019,
	title        = {Making Fast Graph\-based Algorithms with Graph Metric Embeddings},
	author       = {Kutuzov, Andrey and Dorgham, Mohammad and Oliynyk, Oleksiy and Biemann, Chris and Panchenko, Alexander},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	pages        = {3349–3355},
	doi          = {10.18653/v1/P19-1325},
	url          = {https://www.aclweb.org/anthology/P19-1325},
	place        = {Florence, Italy},
	abstractnote = {The computation of distance measures between nodes in graphs is inefficient and does not scale to large graphs. We explore dense vector representations as an effective way to approximate the same information: we introduce a simple yet efficient and effective approach for learning graph embeddings. Instead of directly operating on the graph structure, our method takes structural measures of pairwise node similarities into account and learns dense node representations reflecting user-defined graph distance measures, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings on semantic similarity and word sense disambiguation tasks and show evaluations on the WordNet graph and two knowledge base graphs.}
}
@article{Lampson,
	title        = {Practical Principles for Computer Security},
	author       = {Lampson, Butler},
	pages        = 47,
	note         = {tex.ids: lampson2006a}
}
@inproceedings{Lan_Chunlei_Guoqing_2010,
	title        = {A framework for network secu- rity situation awareness based on knowledge discovery},
	author       = {Lan, F. and Chunlei, W. and Guoqing, M.},
	year         = 2010,
	month        = apr,
	booktitle    = {2010 2nd international conference on computer engineering and technology},
	volume       = 1,
	pages        = {1--226--1–231},
	note         = {Citation Key: lan2010a tex.citation-number: 67}
}
@article{Landwehr_Bull_McDermott_Choi_1994,
	title        = {A taxonomy of computer program security flaws},
	author       = {Landwehr, Carl E. and Bull, Alan R. and McDermott, John P. and Choi, William S.},
	year         = 1994,
	month        = sep,
	journal      = {ACM Computing Surveys},
	volume       = 26,
	number       = 3,
	pages        = {211–254},
	doi          = {10.1145/185403.185412},
	issn         = {03600300},
	note         = {tex.ids: landwehr1994a}
}
@inproceedings{Larsen_Homescu_Brunthaler_Franz_2014,
	title        = {SoK: Automated Software Diversity},
	author       = {Larsen, Per and Homescu, Andrei and Brunthaler, Stefan and Franz, Michael},
	year         = 2014,
	month        = may,
	booktitle    = {2014 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {276–291},
	doi          = {10.1109/SP.2014.25},
	isbn         = {978-1-4799-4686-0},
	url          = {http://ieeexplore.ieee.org/document/6956570/},
	note         = {tex.ids: larsen2014a},
	place        = {San Jose, CA},
	abstractnote = {The idea of automatic software diversity is at least two decades old. The deficiencies of currently deployed defenses and the transition to online software distribution (the ``App store'' model) for traditional and mobile computers has revived the interest in automatic software diversity. Consequently, the literature on diversity grew by more than two dozen papers since 2008.}
}
@article{Latora_Marchiori_2005,
	title        = {Vulnerability and Protection of Critical Infrastructures},
	author       = {Latora, Vito and Marchiori, Massimo},
	year         = 2005,
	month        = jan,
	journal      = {Physical Review E},
	volume       = 71,
	number       = 1,
	pages        = {015103},
	doi          = {10.1103/PhysRevE.71.015103},
	issn         = {1539-3755, 1550-2376},
	note         = {arXiv: cond-mat/0407491},
	abstractnote = {Critical infrastructure networks are a key ingredient of modern society. We discuss a general method to spot the critical components of a critical infrastructure network, i.e. the nodes and the links fundamental to the perfect functioning of the network. Such nodes, and not the most connected ones, are the targets to protect from terrorist attacks. The method, used as an improvement analysis, can also help to better shape a planned expansion of the network.}
}
@article{LeCun_Bengio_Hinton_2015,
	title        = {Deep learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	month        = {05},
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436–444},
	doi          = {10.1038/nature14539},
	issn         = {0028-0836},
	abstractnote = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}
@inbook{Lee_2019,
	title        = {The cyber security body of knowledge},
	author       = {Lee, Wenke},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Malware \& Attack Technology}
}
@article{Lee_Fan_Miller_Stolfo_Zadok_2002,
	title        = {Toward cost-sensitive modeling for intrusion detection and response},
	author       = {Lee, Wenke and Fan, Wei and Miller, Matthew and Stolfo, Salvatore J. and Zadok, Erez},
	year         = 2002,
	month        = mar,
	journal      = {Journal of Computer Security},
	volume       = 10,
	number       = {1/2},
	pages        = 5,
	doi          = {10.3233/JCS-2002-101-202},
	issn         = {0926227X},
	note         = {tex.ids: lee2002a},
	abstractnote = {Intrusion detection systems (IDSs) must maximize the realization of security goals while minimizing costs. In this paper, we study the problem of building cost-sensitive intrusion detection models. We examine the major cost factors associated with an IDS, which include development cost, operational cost, damage cost due to successful intrusions, and the cost of manual and automated response to intrusions. These cost factors can be qualified according to a defined attack taxonomy and site-specific security policies and priorities. We define cost models to formulate the total expected cost of an IDS, and present cost-sensitive machine learning techniques that can produce detection models that are optimized for user-defined cost metrics. Empirical experiments show that our cost-sensitive modeling and deployment techniques are effective in reducing the overall cost of intrusion detection.}
}
@inproceedings{LeMay_Ford_Keefe_Sanders_Muehrcke_2011,
	title        = {Model-based Security Metrics Using ADversary VIew Security Evaluation (ADVISE)},
	author       = {LeMay, Elizabeth and Ford, Michael D. and Keefe, Ken and Sanders, William H. and Muehrcke, Carol},
	year         = 2011,
	month        = sep,
	booktitle    = {2011 Eighth International Conference on Quantitative Evaluation of SysTems},
	publisher    = {IEEE},
	pages        = {191–200},
	doi          = {10.1109/QEST.2011.34},
	issn         = {null},
	note         = {tex.ids: lemay2011a},
	abstractnote = {System architects need quantitative security metrics to make informed trade-off decisions involving system security. The security metrics need to provide insight on weak points in the system defense, considering characteristics of both the system and its adversaries. To provide such metrics, we formally define the ADversary View Security Evaluation (ADVISE) method. Our approach is to create an executable state-based security model of a system and an adversary that represents how the adversary is likely to attack the system and the results of such an attack. The attack decision function uses information about adversary attack preferences and possible attacks against the system to mimic how the adversary selects the most attractive next attack step. The adversary's decision involves looking ahead some number of attack steps. System architects can use ADVISE to compare the security strength of system architecture variants and analyze the threats posed by different adversaries. We demonstrate the feasibility and benefits of ADVISE using a case study. To produce quantitative model-based security metrics, we have implemented the ADVISE method in a tool that facilitates user input of system and adversary data and automatically generates executable models.}
}
@article{Leversage_Byres_2008,
	title        = {Estimating a system's mean time- to-Compromise},
	author       = {Leversage, D.J. and Byres, E.J.},
	year         = 2008,
	journal      = {IEEE Security \& Privacy Magazine},
	volume       = 6,
	number       = 1,
	pages        = {52--60,},
	note         = {Citation Key: leversage2008a tex.citation-number: 76}
}
@inproceedings{levesque2013a,
	title        = {A clinical study of risk factors related to malware infections},
	author       = {Lalonde Levesque, Fanny and Nsiempba, Jude and Fernandez, Jos\'{e} M. and Chiasson, Sonia and Somayaji, Anil},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 ACM SIGSAC conference on Computer \& communications security - CCS '13},
	publisher    = {ACM Press},
	pages        = {97–108},
	doi          = {10.1145/2508859.2516747},
	isbn         = {978-1-4503-2477-9},
	url          = {http://dl.acm.org/citation.cfm?doid=2508859.2516747},
	note         = {tex.ids: levesque2013a},
	place        = {Berlin, Germany},
	abstractnote = {The success of malicious software (malware) depends upon both technical and human factors. The most security conscious users are vulnerable to zero-day exploits; the best security mechanisms can be circumvented by poor user choices. While there has been significant research addressing the technical aspects of malware attack and defense, there has been much less research reporting on how human behavior interacts with both malware and current malware defenses. In this paper we describe a proof-of-concept field study designed to examine the interactions between users, antivirus (anti-malware) software, and malware as they occur on deployed systems. The 4-month study, conducted in a fashion similar to the clinical trials used to evaluate medical interventions, involved 50 subjects whose laptops were instrumented to monitor possible infections and gather data on user behavior. Although the population size was limited, this initial study produced some intriguing, non-intuitive insights into the efficacy of current defenses, particularly with regards to the technical sophistication of end users. We assert that this work shows the feasibility and utility of testing security software through long-term field studies with greater ecological validity than can be achieved through other means.}
}
@inproceedings{Levin_2003,
	title        = {Lessons learned in using live red teams in IA experiments},
	author       = {Levin, D.},
	year         = 2003,
	booktitle    = {Proceedings DARPA Information Survivability Conference and Exposition},
	publisher    = {IEEE Comput. Soc},
	pages        = {110–119},
	doi          = {10.1109/DISCEX.2003.1194877},
	isbn         = {978-0-7695-1897-8},
	url          = {http://ieeexplore.ieee.org/document/1194877/},
	note         = {tex.ids: levin2003a},
	place        = {Washington, DC, USA},
	abstractnote = {The DARPA Information Assurance (IA) and Operational Partners in Experimentation (OPX) Programs have conducted over a dozen experiments involving live red teams since April 1999. This paper explores some of the lessons learned that are common among those experiments.}
}
@article{Li_Parker_Xu_2011,
	title        = {A Stochastic Model for Quantitative Security Analyses of Networked Systems},
	author       = {Li, Xiaohu and Parker, Paul and Xu, Shouhuai},
	year         = 2011,
	month        = mar,
	journal      = {IEEE Transactions on Dependable and Secure Computing; Washington},
	volume       = 8,
	number       = 1,
	pages        = {28–43},
	doi          = {http://dx.doi.org/10.1109/TDSC.2008.75},
	issn         = 15455971,
	note         = {Citation Key: li2011a},
	abstractnote = {Traditional security analyses are often geared toward cryptographic primitives or protocols. Although such analyses are necessary, they cannot address a defender's need for insight into which aspects of a networked system having a significant impact on its security, and how to tune its configurations or parameters so as to improve security. This question is known to be notoriously difficult to answer, and the state of the art is that we know little about it. Toward ultimately addressing this question, this paper presents a stochastic model for quantifying security of networked systems. The resulting model captures two aspects of a networked system: 1. the strength of deployed security mechanisms such as intrusion detection systems and 2. the underlying vulnerability graph, which reflects how attacks may proceed. The resulting model brings the following insights: 1. How should a defender tune system configurations (e.g., network topology) so as to improve security? 2).How should a defender ``tune'' system parameters (e.g., by upgrading which security mechanisms) so as to improve security? 3. Under what conditions is the steady-state number of compromised entities of interest below a given threshold with a high probability? Simulation studies are conducted to confirm the analytic results, and to show the tightness of the bounds of certain important metric that cannot be resolved analytically.}
}
@article{Li_Tarlow_Brockschmidt_Zemel_2017,
	title        = {Gated Graph Sequence Neural Networks},
	author       = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
	year         = 2017,
	month        = sep,
	journal      = {arXiv:1511.05493 [cs, stat]},
	url          = {http://arxiv.org/abs/1511.05493},
	note         = {arXiv: 1511.05493},
	abstractnote = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be described as abstract data structures.}
}
@inproceedings{Li_Vaughn_2006,
	title        = {Cluster security research involving the modeling of network exploitations using exploitation graphs},
	author       = {Li, Wei and Vaughn, Rayford B.},
	year         = 2006,
	month        = may,
	booktitle    = {Sixth IEEE International Symposium on Cluster Computing and the Grid (CCGRID'06)},
	publisher    = {IEEE},
	volume       = 2,
	pages        = {26–26},
	note         = {Citation Key: li2006a tex.citation-number: 95}
}
@inproceedings{Lindqvist_Jonsson_1997,
	title        = {How to systematically classify computer security intrusions},
	author       = {Lindqvist, U. and Jonsson, E.},
	year         = 1997,
	booktitle    = {Proceedings. 1997 IEEE Symposium on Security and Privacy (Cat. No.97CB36097)},
	publisher    = {IEEE Comput. Soc. Press},
	pages        = {154–163},
	doi          = {10.1109/SECPRI.1997.601330},
	isbn         = {978-0-8186-7828-8},
	url          = {http://ieeexplore.ieee.org/document/601330/},
	note         = {tex.ids: lindqvist1997a tex.citation-number: 2},
	place        = {Oakland, CA, USA},
	abstractnote = {This paper presents a classification of intrusions with respect to technique as well as to result. The taxonomy is intended to be a step on the road to an established taxonomy of intrusions for use in incident reporting, statistics, warning bulletins, intrusion detection systems etc. Unlike previous schemes, it takes the viewpoint of the system owner and should therefore be suitable to a wider community than that of system developers and vendors only. It is based on data from a realistic intrusion experiment, a fact that supports the practical applicability of the scheme. The paper also discusses general aspects of classification, and introduces a concept called dimension. After having made a broad survey of previous work in the field, we decided to base our classification of intrusion techniques on a scheme proposed by Neumann and Parker in 1989 and to further refine relevant parts of their scheme. Our classification of intrusion results is derived from the traditional three aspects of computer security: confidentiality, availability and integrity.}
}
@inproceedings{Lippmann_2006,
	title        = {Validating and restoring defense in depth using attack graphs},
	author       = {Lippmann, R.},
	year         = 2006,
	month        = oct,
	booktitle    = {Proc. IEEE mil. Commun. Conf. (MILCOM},
	pages        = {1–10},
	note         = {tex.ids: lippmann2006a tex.citation-number: 97.}
}
@book{Lippmann_Ingols_2005,
	title        = {An annotated review of past papers on attack graphs},
	author       = {Lippmann, Richard Paul and Ingols, Kyle William},
	year         = 2005,
	note         = {Citation Key: lippmann2005a tex.citation-number: 92},
	institution  = {MASSACHUSETTS INST OF TECH LEXINGTON LINCOLN LAB},
	place        = {Lexington, MA}
}
@book{Lippmann_Riordan_Yu_Watson_2012,
	title        = {Continuous Security Metrics for Prevalent Network Threats: Introduction and First Four Metrics:},
	author       = {Lippmann, R. P. and Riordan, J. F. and Yu, T. H. and Watson, K. K.},
	year         = 2012,
	month        = may,
	doi          = {10.21236/ADA565825},
	url          = {http://www.dtic.mil/docs/citations/ADA565825},
	note         = {tex.ids: lippmann2012a},
	place        = {Fort Belvoir, VA},
	institution  = {Defense Technical Information Center}
}
@article{Littlewood_Brocklehurst_Fenton_Mellor_Page_Wright_Dobson_McDermid_Gollmann_1993,
	title        = {Towards Operational Measures of Computer Security},
	author       = {Littlewood, Bev and Brocklehurst, Sarah and Fenton, Norman and Mellor, Peter and Page, Stella and Wright, David and Dobson, John and McDermid, John and Gollmann, Dieter},
	year         = 1993,
	month        = apr,
	journal      = {Journal of Computer Security},
	volume       = 2,
	number       = {2–3},
	pages        = {211–229},
	doi          = {10.3233/JCS-1993-22-308},
	issn         = {18758924, 0926227X},
	note         = {tex.ids: littlewood1993a tex.citation-number: 68. tex.publisher: ScholarDigital Library},
	abstractnote = {Ideally, a measure of the security of a system should capture quantitatively the intuitive notion of `the ability of the system to resist attack'. That is, it should be operational, reflecting the degree to which the system can be expected to remain free of security breaches under particular conditions of operation (including attack). Instead, current security levels at best merely reflect the extensiveness of safeguards introduced during the design and development of a system. Whilst we might expect a system developed to a higher level than another to exhibit `more secure behaviour' in operation, this cannot be guaranteed; more particularly, we cannot infer what the actual security behaviour will be from knowledge of such a level. In the paper we discuss similarities between reliability and security with the intention of working towards measures of `operational security' similar to those that we have for reliability of systems. Very informally, these measures could involve expressions such as the rate of occurrence of security breaches (cf rate of occurrence of failures in reliability), or the probability that a specified `mission' can be accomplished without a security breach (cf reliability function). This new approach is based on the analogy between system failure and security breach. A number of other analogies to support this view are introduced. We examine this duality critically, and have identified a number of important open questions that need to be answered before this quantitative approach can be taken further. The work described here is therefore somewhat tentative, and one of our major intentions is to invite discussion about the plausibility and feasibility of this new approach.}
}
@inproceedings{Liu_Man_2005,
	title        = {Network vulnerability assessment using Bayesian networks},
	author       = {Liu, Yu and Man, Hong},
	year         = 2005,
	month        = mar,
	booktitle    = {Data Mining, Intrusion Detection, Information Assurance, and Data Networks Security 2005},
	publisher    = {International Society for Optics and Photonics},
	volume       = 5812,
	pages        = {61–71},
	doi          = {10.1117/12.604240},
	url          = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5812/0000/Network-vulnerability-assessment-using-Bayesian-networks/10.1117/12.604240.short},
	note         = {tex.ids: liu2005a, liuNetworkVulnerabilityAssessment2005a, liuNetworkVulnerabilityAssessment2005b tex.citation-number: 104},
	abstractnote = {While computer vulnerabilities have been continually reported in laundry-list format by most commercial scanners, a comprehensive network vulnerability assessment has been an increasing challenge to security analysts. Researchers have proposed a variety of methods to build attack trees with chains of exploits, based on which post-graph vulnerability analysis can be performed. The most recent approaches attempt to build attack trees by enumerating all potential attack paths, which are space consuming and result in poor scalability. This paper presents an approach to use Bayesian network to model potential attack paths. We call such graph as ``Bayesian attack graph''. It provides a more compact representation of attack paths than conventional methods. Bayesian inference methods can be conveniently used for probabilistic analysis. In particular, we use the Bucket Elimination algorithm for belief updating, and we use Maximum Probability Explanation algorithm to compute an optimal subset of attack paths relative to prior knowledge on attackers and attack mechanisms. We tested our model on an experimental network. Test results demonstrate the effectiveness of our approach.}
}
@inproceedings{Liu_Sarabi_Zhang_Naghizadeh_Karir_Bailey_Liu,
	title        = {Cloudy with a Chance of Breach:   Forecasting Cyber Security Incidents},
	author       = {Liu, Yang and Sarabi, Armin and Zhang, Jing and Naghizadeh, Parinaz and Karir, Manish and Bailey, Michael and Liu, Mingyan},
	pages        = 50,
	note         = {tex.ids: liu2015a}
}
@article{Liu_Singhal_Wijesekera,
	title        = {A Logic Based Network Forensics Model for Evidence Analysis},
	author       = {Liu, Changwei and Singhal, Anoop and Wijesekera, Duminda},
	pages        = 19,
	abstractnote = {Modern-day attackers tend to use sophisticated multi-stage/multi-host attack techniques and anti-forensics tools to cover their attack traces. Due to the limitations of current intrusion detection and forensic analysis tools, reconstructing attack scenarios from evidence left behind by the attackers of an enterprise system is challenging. In particular, reconstructing attack scenarios by using intrusion detection system (IDS) alerts and system logs that have too many false positives is a big challenge. In this paper, we present a model and an accompanying software tool that systematically addresses how to resolve the above problems to reconstruct attack scenarios that could stand up in court. These problems include a large amount of data including non-relevant data, missing evidence and incomplete evidence destroyed by using anti-forensic techniques. Our system is based on a Prolog system using known vulnerability databases and an anti-forensic database that we plan to extend to a standardized database like the existing NIST National Vulnerability Database (NVD). In this model, we use different methods, including mapping the evidence to system vulnerabilities, inductive reasoning and abductive reasoning, to reconstruct attack scenarios. The goal of this work is to reduce the security investigators' time and effort in reaching definite conclusion about how an attack occurred. Our results indicate that such a reasoning system can be useful for network forensics analysis.}
}
@inproceedings{Lowd_Meek_2005,
	title        = {Adversarial learning},
	author       = {Lowd, Daniel and Meek, Christopher},
	year         = 2005,
	booktitle    = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining  - KDD '05},
	publisher    = {ACM Press},
	pages        = 641,
	doi          = {10.1145/1081870.1081950},
	isbn         = {978-1-59593-135-1},
	url          = {http://portal.acm.org/citation.cfm?doid=1081870.1081950},
	note         = {tex.ids: lowd2005a tex.publisher: Google Scholar},
	place        = {Chicago, Illinois, USA},
	abstractnote = {Many classification tasks, such as spam filtering, intrusion detection, and terrorism detection, are complicated by an adversary who wishes to avoid detection. Previous work on adversarial classification has made the unrealistic assumption that the attacker has perfect knowledge of the classifier [2]. In this paper, we introduce the adversarial classifier reverse engineering (ACRE) learning problem, the task of learning sufficient information about a classifier to construct adversarial attacks. We present efficient algorithms for reverse engineering linear classifiers with either continuous or Boolean features and demonstrate their effectiveness using real data from the domain of spam filtering.}
}
@inproceedings{Lu_Song_Lee_Chung_Kim_Lee_2015,
	title        = {ASLR-Guard: Stopping Address Space Leakage for Code Reuse Attacks},
	author       = {Lu, Kangjie and Song, Chengyu and Lee, Byoungyoung and Chung, Simon P. and Kim, Taesoo and Lee, Wenke},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {280–291},
	doi          = {10.1145/2810103.2813694},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813694},
	note         = {tex.ids: lu2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {A general prerequisite for a code reuse attack is that the attacker needs to locate code gadgets that perform the desired operations and then direct the control flow of a vulnerable application to those gadgets. Address Space Layout Randomization (ASLR) attempts to stop code reuse attacks by making the first part of the prerequisite unsatisfiable. However, research in recent years has shown that this protection is often defeated by commonly existing information leaks, which provides attackers clues about the whereabouts of certain code gadgets. In this paper, we present ASLR-GUARD, a novel mechanism that completely prevents the leaks of code pointers, and render other information leaks (e.g., the ones of data pointers) useless in deriving code address. The main idea behind ASLR-GUARD is to render leak of data pointer useless in deriving code address by separating code and data, provide a secure storage for code pointers, and encode the code pointers when they are treated as data. ASLR-GUARD can either prevent code pointer leaks or render their leaks harmless. That is, ASLR-GUARD makes it impossible to overwrite code pointers with values that point to or will hijack the control flow to a desired address when the code pointers are dereferenced. We have implemented a prototype of ASLR-GUARD, including a compilation toolchain and a C/C++ runtime. Our evaluation results show that (1) ASLR-GUARD supports normal operations correctly; (2) it completely stops code address leaks and can resist against recent sophisticated attacks; (3) it imposes almost no runtime overhead (< 1\%) for C/C++ programs in the SPEC benchmark. Therefore, ASLR-GUARD is very practical and can be applied to secure many applications.}
}
@inproceedings{Lu_Xu_Yi_2013,
	title        = {Optimizing active cyber defense dynamics},
	author       = {Lu, W. and Xu, S. and Yi, X.},
	year         = 2013,
	booktitle    = {Proc. GameSec'13},
	pages        = {206–225},
	note         = {Citation Key: lu2013a}
}
@article{Lunt_1993,
	title        = {A survey of intrusion detection techniques},
	author       = {Lunt, T.F.},
	year         = 1993,
	month        = jun,
	journal      = {Computers \& Security},
	volume       = 12,
	number       = 4,
	pages        = {405--418,},
	note         = {Citation Key: lunt1993a tex.citation-number: 6}
}
@article{M.I.T.R.E._2014,
	title        = {Common weakness scoring system (CWSS version 1.0.1},
	author       = {M.I.T.R.E.},
	year         = 2014,
	url          = {https://cwe.mitre.},
	note         = {Citation Key: m2014a}
}
@inproceedings{Maclaurin_Duvenaud_Adams_2015,
	title        = {Gradient-based Hyperparameter Optimization through Reversible Learning.},
	author       = {Maclaurin, Dougal and Duvenaud, David K. and Adams, Ryan P.},
	year         = 2015,
	booktitle    = {ICML},
	pages        = {2113–2122},
	url          = {http://www.jmlr.org/proceedings/papers/v37/maclaurin15.pdf}
}
@inproceedings{Madan_Gogeva-Popstojanova_Vaidyanathan_Trivedi_2002,
	title        = {Modeling and quantification of security attributes of software systems},
	author       = {Madan, Bharat B. and Gogeva-Popstojanova, K. and Vaidyanathan, Kalyanaraman and Trivedi, Kishor S.},
	year         = 2002,
	booktitle    = {Proceedings International Conference on Dependable Systems and Networks},
	publisher    = {IEEE},
	pages        = {505–514},
	note         = {tex.ids: madan2002a, madanModelingQuantificationSecurity2002a, madanModelingQuantificationSecurity2002b tex.citation-number: 131}
}
@article{Madan_Goseva-Popstojanova_Vaidyanathan_Trivedi_2004,
	title        = {A method for modeling and quantifying the security attributes of intrusion tolerant systems},
	author       = {Madan, Bharat B. and Goseva-Popstojanova, Katerina and Vaidyanathan, Kalyanaraman and Trivedi, Kishor S.},
	year         = 2004,
	journal      = {Perform. Eval},
	volume       = 56,
	number       = {1–4},
	note         = {Citation Key: madan2004b tex.ids: madan2004a tex.citation-number: 132}
}
@book{Mahalingam_Abdollah_Sahib_2014,
	title        = {Learner Centric in M-Learning: Integration of Security, Dependability and Trust.},
	author       = {Mahalingam, Sheila and Abdollah, Faizal Mohd and Sahib, Shahrin},
	year         = 2014,
	publisher    = {ERIC}
}
@article{Manadhata_Wing_2010,
	title        = {An attack surface metric},
	author       = {Manadhata, Pratyusa K. and Wing, Jeannette M.},
	year         = 2010,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 37,
	number       = 3,
	pages        = {371–386},
	note         = {tex.ids: manadhata2011a, manadhataAttackSurfaceMetric, manadhataAttackSurfaceMetric2011, manadhataAttackSurfaceMetric2011a tex.citation-number: 32}
}
@article{Marconato_Kaaniche_Nicomette_2013,
	title        = {A vulnerability life cycle-based security modeling and evaluation approach},
	author       = {Marconato, G. Vache and Ka\^{a}niche, Mohamed and Nicomette, Vincent},
	year         = 2013,
	journal      = {The Computer Journal},
	publisher    = {OUP},
	volume       = 56,
	number       = 4,
	pages        = {422–439}
}
@inproceedings{Marczak_Scott-Railton_Paxson_Marquis-Boire,
	title        = {When Governments Hack Opponents: A Look at Actors and Technology},
	author       = {Marczak, William R and Scott-Railton, John and Paxson, Vern and Marquis-Boire, Morgan},
	pages        = 16,
	note         = {tex.ids: marczak2014a, marczakWhenGovernmentsHacka},
	abstractnote = {Repressive nation-states have long monitored telecommunications to keep tabs on political dissent. The Internet and online social networks, however, pose novel technical challenges to this practice, even as they open up new domains for surveillance. We analyze an extensive collection of suspicious files and links targeting activists, opposition members, and nongovernmental organizations in the Middle East over the past several years. We find that these artifacts reflect efforts to attack targets' devices for the purposes of eavesdropping, stealing information, and/or unmasking anonymous users. We describe attack campaigns we have observed in Bahrain, Syria, and the United Arab Emirates, investigating attackers, tools, and techniques. In addition to off-the-shelf remote access trojans and the use of third-party IP-tracking services, we identify commercial spyware marketed exclusively to governments, including Gamma's FinSpy and Hacking Team's Remote Control System (RCS). We describe their use in Bahrain and the UAE, and map out the potential broader scope of this activity by conducting global scans of the corresponding command-and-control (C\&C) servers. Finally, we frame the real-world consequences of these campaigns via strong circumstantial evidence linking hacking to arrests, interrogations, and imprisonment.}
}
@inproceedings{McDermott_2000,
	title        = {Attack net penetration testing},
	author       = {McDermott, J. P.},
	year         = 2000,
	booktitle    = {Proceedings of the 2000 workshop on New security paradigms  - NSPW '00},
	publisher    = {ACM Press},
	pages        = {15–21},
	doi          = {10.1145/366173.366183},
	isbn         = {978-1-58113-260-1},
	url          = {http://portal.acm.org/citation.cfm?doid=366173.366183},
	place        = {Ballycotton, County Cork, Ireland},
	abstractnote = {The modeling of penetration testing as a Petri net is surprisingly useful. It retains key advantages of the flaw hypothesis and attack tree approaches while providing some new benefits.}
}
@inproceedings{McHugh_2006,
	title        = {Quality of protection: measuring the unmeasurable?},
	author       = {McHugh, John},
	year         = 2006,
	booktitle    = {Proceedings of the 2nd ACM workshop on Quality of protection  - QoP '06},
	publisher    = {ACM Press},
	pages        = {1–2},
	doi          = {10.1145/1179494.1179495},
	isbn         = {978-1-59593-553-3},
	url          = {http://portal.acm.org/citation.cfm?doid=1179494.1179495},
	note         = {tex.ids: mchugh2006a tex.citation-number: 145.},
	place        = {Alexandria, Virginia, USA}
}
@inproceedings{McQueen_Boyer_Flynn_Beitel_2005,
	title        = {Time-to- compromise model for cyber risk reduction estimation},
	author       = {McQueen, M.A. and Boyer, W.F. and Flynn, M.A. and Beitel, G.A.},
	year         = 2005,
	booktitle    = {Quality of protection workshop at ESORICS 2005, the flagship european symposium on research in computer security},
	publisher    = {Springer US},
	volume       = 23,
	pages        = {49–64},
	doi          = {10.1007/978-0-387-36584-8\_5},
	isbn         = {978-0-387-29016-4},
	url          = {http://link.springer.com/10.1007/978-0-387-36584-8\_5},
	note         = {Citation Key: mcqueen2005a tex.citation-number: 8},
	place        = {Boston, MA},
	abstractnote = {We propose a new model for estimating the time to compromise a system component that is visible to an attacker. The model provides an estimate of the expected value of the time-to-compromise as a function of known and visible vulnerabilities, and attacker skill level. The time-to-compromise random process model is a composite of three subprocesses associated with attacker actions aimed at the exploitation of vulnerabilities. In a case study, the model was used to aid in a risk reduction estimate between a baseline Supervisory Control and Data Acquisition (SCADA) system and the baseline system enhanced through a specific set of control system security remedial actions. For our case study, the total number of system vulnerabilities was reduced by 86 but the dominant attack path was through a component where the number of vulnerabilities was reduced by only 42 and the time-to-compromise of that component was increased by only 13 to 30 depending on attacker skill level.},
	editor       = {Gollmann, Dieter and Massacci, Fabio and Yautsiukhin, ArtsiomEditors}
}
@inproceedings{Mehta_Bartzis_Zhu_Clarke_Wing_2006,
	title        = {Ranking attack graphs},
	author       = {Mehta, Vaibhav and Bartzis, Constantinos and Zhu, Haifeng and Clarke, Edmund and Wing, Jeannette},
	year         = 2006,
	booktitle    = {International Workshop on Recent Advances in Intrusion Detection},
	publisher    = {Springer},
	pages        = {127–144},
	note         = {tex.ids: mehta2006a tex.citation-number: 98}
}
@article{Mell_Scarfone_Romanosky,
	title        = {A Complete Guide to the Common Vulnerability Scoring System Version 2.0},
	author       = {Mell, Peter and Scarfone, Karen and Romanosky, Sasha},
	pages        = 24,
	note         = {tex.ids: mell2007a, mellCompleteGuideCommona tex.citation-number: 47}
}
@article{Mell_Scarfone_Romanosky_2006,
	title        = {Common Vulnerability Scoring System},
	author       = {Mell, Peter and Scarfone, Karen and Romanosky, Sasha},
	year         = 2006,
	month        = nov,
	journal      = {IEEE Security and Privacy Magazine},
	volume       = 4,
	number       = 6,
	pages        = {85–89},
	doi          = {10.1109/MSP.2006.145},
	issn         = {1540-7993},
	note         = {tex.ids: mell2006a tex.citation-number: 27}
}
@book{Mell_Scarfone_Romanosky_2007,
	title        = {The common vulnerability scoring system (CVSS) and its applicability to federal agency systems},
	author       = {Mell, Peter and Scarfone, Karen and Romanosky, Sasha},
	year         = 2007,
	number       = {NIST IR 7435},
	pages        = {NIST IR 7435},
	doi          = {10.6028/NIST.IR.7435},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nistir7435.pdf},
	place        = {Gaithersburg, MD},
	abstractnote = {The Common Vulnerability Scoring System (CVSS) provides an open framework for communicating the characteristics and impacts of IT vulnerabilities. The National Vulnerability Database (NVD) provides specific CVSS scores for publicly known vulnerabilities. Federal agencies can use the Federal Information Processing Standards (FIPS) 199 security categories with the NVD CVSS scores to obtain impact scores that are tailored to each agency's environment. CVSS consists of three groups: Base, Temporal and Environmental. Each group produces a numeric score ranging from 0.0 to 10.0, and a vector, a compressed textual representation that reflects the values used to derive the score. The Base group represents the intrinsic qualities of a vulnerability. The Temporal group reflects the characteristics of a vulnerability that change over time. The Environmental group represents the characteristics of a vulnerability that are unique to any user's environment. CVSS enables IT managers, vulnerability bulletin providers, security vendors, application vendors and researchers to all benefit by adopting this common language of scoring IT vulnerabilities.},
	institution  = {National Institute of Standards and Technology}
}
@misc{Mell07thecommon,
	title        = {The Common Vulnerability Scoring System (CVSS) and Its Applicability to Federal Agency Systems},
	author       = {Peter Mell and Karen Scarfone and Sasha Romanosky and Peter Mell and Karen Scarfone and Sasha Romanosky and Carlos M. Gutierrez and William Jeffrey Director},
	year         = 2007
}
@inproceedings{Mellado_Fernandez-Medina_Piattini_2010,
	title        = {A comparison of software design security metrics},
	author       = {Mellado, Daniel and Fern\'{a}ndez-Medina, Eduardo and Piattini, Mario},
	year         = 2010,
	month        = aug,
	booktitle    = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
	publisher    = {Association for Computing Machinery},
	series       = {ECSA '10},
	pages        = {236–242},
	doi          = {10.1145/1842752.1842797},
	isbn         = {978-1-4503-0179-4},
	url          = {https://doi.org/10.1145/1842752.1842797},
	note         = {tex.ids: d2010a tex.citation-number: 23},
	place        = {Copenhagen, Denmark},
	abstractnote = {A lack of security metrics signifies that it is not possible to measure the success of security policies, mechanisms and implementations, and security cannot, in turn, be improved if it cannot be measured. The importance of the use of metrics to obtain security quality is thus widely accepted. However, the definition of security metrics concerns a discipline which is still in its first stages of development, meaning that few documented resources or works centring on this subject exist to date. In this paper we shall therefore study the latest existing models with which to define security metrics and their components as aspects that have a bearing on the quality of software products with the intention that this will serve as a basis for continued advancement in research into this area of knowledge.},
	collection   = {ECSA '10}
}
@inproceedings{Meneely_Williams_2010,
	title        = {Strengthening the empirical analysis of the relationship between Linus' Law and software security},
	author       = {Meneely, Andrew and Williams, Laurie},
	year         = 2010,
	booktitle    = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
	pages        = {1–10}
}
@book{Merkow_Breithaupt_2005,
	title        = {Computer security assurance, using the common criteria},
	author       = {Merkow, M.S. and Breithaupt, J.},
	year         = 2005,
	publisher    = {Thomson Delmar Learning},
	note         = {Citation Key: merkow2005a tex.citation-number: 42},
	place        = {Clifton Park, NY}
}
@inproceedings{Mezzour_Carley_Carley_2015,
	title        = {An empirical study of global malware encounters},
	author       = {Mezzour, Ghita and Carley, Kathleen M. and Carley, L. Richard},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 Symposium and Bootcamp on the Science of Security - HotSoS '15},
	publisher    = {ACM Press},
	pages        = {1–11},
	doi          = {10.1145/2746194.2746202},
	isbn         = {978-1-4503-3376-4},
	url          = {http://dl.acm.org/citation.cfm?doid=2746194.2746202},
	note         = {tex.ids: mezzour2015a, mezzourEmpiricalStudyGlobal2015a},
	place        = {Urbana, Illinois},
	abstractnote = {The number of trojans, worms, and viruses that computers encounter varies greatly across countries. Empirically identifying factors behind such variation can provide a scientific empirical basis to policy actions to reduce malware encounters in the most affected countries. However, our understanding of these factors is currently mainly based on expert opinions, not empirical evidence.}
}
@inproceedings{Michael_Williams_2007,
	title        = {Toward the Use of Automated Static Analysis Alerts for Early Identification of Vulnerability- and Attack-prone Components},
	author       = {Michael and Williams, Laurie},
	year         = 2007,
	month        = {07},
	booktitle    = {Second International Conference on Internet Monitoring and Protection (ICIMP 2007)},
	publisher    = {IEEE},
	pages        = {18–18},
	doi          = {10.1109/ICIMP.2007.46},
	url          = {https://ieeexplore.ieee.org/document/4271764/},
	place        = {San Jose, CA},
	abstractnote = {Extensive research has shown that software metrics can be used to identify fault- and failure-prone components. These metrics can also give early indications of overall software quality. We seek to parallel the identification and prediction of fault- and failure-prone components in the reliability context with vulnerability- and attack-prone components in the security context. Our research will correlate the quantity and severity of alerts generated by source code static analyzers to vulnerabilities discovered by manual analyses and testing. A strong correlation may indicate that automated static analyzers (ASA), a potentially early technique for vulnerability identification in the development phase, can identify high risk areas in the software system. Based on the alerts, we may be able to predict the presence of more complex and abstract vulnerabilities involved with the design and operation of the software system. An early knowledge of vulnerability can allow software engineers to make informed risk management decisions and prioritize redesign, inspection, and testing efforts. This paper presents our research objective and methodology.}
}
@article{Microsoft_2013,
	title        = {Security intelligence report},
	author       = {Microsoft},
	year         = 2013,
	url          = {http://www.microsoft.com/security/sir/},
	note         = {Citation Key: microsoft2013a}
}
@book{Mihajlovic_Petkovic_2001,
	title        = {Dynamic bayesian networks: A state of the art, TR-CTI},
	author       = {Mihajlovic, V. and Petkovic, M.},
	year         = 2001,
	note         = {Citation Key: mihajlovic2001a tex.citation-number: 103},
	institution  = {University of Twente, Centre for Telematics and Information Technology}
}
@article{Milenkoski_Vieira_Kounev_Avritzer_Payne_2015,
	title        = {Evaluating Computer Intrusion Detection Systems: A Survey of Common Practices},
	author       = {Milenkoski, Aleksandar and Vieira, Marco and Kounev, Samuel and Avritzer, Alberto and Payne, Bryan D.},
	year         = 2015,
	month        = sep,
	journal      = {ACM Computing Surveys},
	volume       = 48,
	number       = 1,
	pages        = {1–41},
	doi          = {10.1145/2808691},
	issn         = {03600300},
	note         = {tex.ids: milenkoski2015a},
	abstractnote = {In Appendix A, we provide an overview of major developments in the area of IDS evaluation in a chronological manner.}
}
@article{Mir_2013,
	title        = {Modeling of Security Measurement Metrics in an Information System},
	author       = {Mir, Irshad Ahmad},
	year         = 2013
}
@inproceedings{Mohaisen_Alrawi_2014,
	title        = {AV-Meter: An Evaluation of Antivirus Scans and Labels},
	author       = {Mohaisen, Aziz and Alrawi, Omar},
	year         = 2014,
	booktitle    = {Detection of Intrusions and Malware, and Vulnerability Assessment},
	publisher    = {Springer International Publishing},
	volume       = 8550,
	pages        = {112–131},
	doi          = {10.1007/978-3-319-08509-8\_7},
	isbn         = {978-3-319-08508-1},
	url          = {http://link.springer.com/10.1007/978-3-319-08509-8\_7},
	note         = {tex.ids: mohaisen2014a, mohaisenAVMeterEvaluationAntivirus2014a},
	place        = {Cham},
	abstractnote = {Antivirus scanners are designed to detect malware and, to a lesser extent, to label detections based on a family association. The labeling provided by AV vendors has many applications such as guiding efforts of disinfection and countermeasures, intelligence gathering, and attack attribution, among others. Furthermore, researchers rely on AV labels to establish a baseline of ground truth to compare their detection and classification algorithms. This is done despite many papers pointing out the subtle problem of relying on AV labels. However, the literature lacks any systematic study on validating the performance of antivirus scanners, and the reliability of those labels or detection.},
	editor       = {Dietrich, Sven}
}
@inproceedings{Mohamed_Salleh_Omar_2012,
	title        = {A comparative study of Reduced Error Pruning method in decision tree algorithms},
	author       = {Mohamed, W. Nor Haizan W. and Salleh, Mohd Najib Mohd and Omar, Abdul Halim},
	year         = 2012,
	month        = nov,
	booktitle    = {2012 IEEE International Conference on Control System, Computing and Engineering},
	pages        = {392–397},
	doi          = {10.1109/ICCSCE.2012.6487177},
	issn         = {null},
	abstractnote = {Decision tree is one of the most popular and efficient technique in data mining. This technique has been established and well-explored by many researchers. However, some decision tree algorithms may produce a large structure of tree size and it is difficult to understand. Furthermore, misclassification of data often occurs in learning process. Therefore, a decision tree algorithm that can produce a simple tree structure with high accuracy in term of classification rate is a need to work with huge volume of data. Pruning methods have been introduced to reduce the complexity of tree structure without decrease the accuracy of classification. One of pruning methods is the Reduced Error Pruning (REP). To better understand pruning methods, an experiment was conducted using Weka application to compare the performance in term of complexity of tree structure and accuracy of classification for J 48, REPTree, PART, JRip, and Ridor algorithms using seven standard datasets from UCI machine learning repository. In data modeling, J48 and REPTree generate tree structure as an output while PART, Ridor and JRip generate rules. In additional J48, REPTree and PART using REP method for pruning while Ridor and JRip using improvement of REP method, namely IREP and RIPPER methods. The experiment result shown performance of J48 and REPTree are competitive in producing better result. Between J48 and REPTree, average differences performance of accuracy of classification is 7.1006\% and 6.285\% for complexity of tree structure. For classification rules algorithms, Ridor is the best algorithms compare to PART and JRip due to highest percentage of accuracy of classification in five dataset from seven datasets. An algorithm that produces high accuracy with simple tree structure or simple rules can be awarded as the best algorithm in decision tree.}
}
@article{Morales_Xu_Sandhu_2012,
	title        = {Analyzing malware detection eciency with multiple anti-malware programs},
	author       = {Morales, J. and Xu, S. and Sandhu, R.},
	year         = 2012,
	journal      = {ASE Sci. J},
	volume       = {1, 2},
	note         = {Citation Key: morales2012a}
}
@book{Morana_2015,
	title        = {Risk centric threat modeling: process for attack simulation and threat analysis},
	author       = {Morana, Marco M. and Uceda V\'{e}lez, Tony},
	year         = 2015,
	publisher    = {Wiley},
	isbn         = {978-1-118-98835-0},
	place        = {Hoboken, New Jersey},
	abstractnote = {``This book describes how to apply application threat modeling as an advanced preventive form of security''--}
}
@book{Morris_2001,
	title        = {Measurement and instrumentation principles},
	author       = {Morris, Alan S.},
	year         = 2001,
	publisher    = {Butterworth-Heinemann},
	isbn         = {978-0-7506-5081-6},
	place        = {Oxford [England] ; Boston}
}
@article{Morrison_Moye_Pandita_Williams_2018,
	title        = {Mapping the field of software life cycle security metrics},
	author       = {Morrison, Patrick and Moye, David and Pandita, Rahul and Williams, Laurie},
	year         = 2018,
	month        = oct,
	journal      = {Information and Software Technology},
	volume       = 102,
	pages        = {146–159},
	doi          = {10.1016/j.infsof.2018.05.011},
	issn         = {09505849},
	abstractnote = {Objective: The goal of this research is to support practitioner and researcher use of security measurement in the software life cycle by cataloging security metrics presented in the literature, their validation, and the subjects they measure. Method: We conducted a systematic mapping study, beginning with 4818 papers and narrowing down to 71 papers reporting on 324 unique security metrics. For each metric, we identified the subject being measured, how the metric has been validated, and how the metric is used. We categorized the metrics, and give examples of metrics for each category. Results: In our data, 85\% of security metrics have been proposed and evaluated solely by their authors, leaving room for replication and confirmation through field studies. Approximately 60\% of the metrics have been empirically evaluated, by their authors or by others. The available metrics are weighted heavily toward the implementation and operations phases, with relatively few metrics for requirements, design, and testing phases of software development. Some artifacts and processes remain unmeasured. Measured by phase, Testing received the least attention, with 1.5\% of the metrics. Conclusions: At present, the primary application of security metrics to the software development life cycle in the literature is to study the relationship between properties of source code and reported vulnerabilities. The most-cited and most used metric, vulnerability count, has multiple definitions and operationalizations. We suggest that researchers must check vulnerability count definitions when making comparisons between papers. In addition to refining vulnerability measurement, we see research opportunities for greater attention to metrics for the requirement, design, and testing phases of development. We conjecture from our data that the field of software life cycle security metrics has yet to converge on an accepted set of metrics.}
}
@article{Moses_2002,
	title        = {Web services security quality of protection},
	author       = {Moses, T.},
	year         = 2002,
	url          = {http://xml.coverpages.org/ni2002-09-21-a.html},
	note         = {Citation Key: moses2002a tex.citation-number: 61}
}
@article{Musman_Turner_2018,
	title        = {A game theoretic approach to cyber security risk management},
	author       = {Musman, Scott and Turner, Andrew},
	year         = 2018,
	month        = {04},
	journal      = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	volume       = 15,
	number       = 2,
	pages        = {127–146},
	doi          = {10.1177/1548512917699724},
	issn         = {1548-5129, 1557-380X},
	abstractnote = {This paper describes the Cyber Security Game (CSG). Cyber Security Game is a method that has been implemented in software that quantitatively identifies cyber security risks and uses this metric to determine the optimal employment of security methods for any given investment level. Cyber Security Game maximizes a system's ability to operate in today's contested cyber environment by minimizing its mission risk. The risk score is calculated by using a mission impact model to compute the consequences of cyber incidents and combining that with the likelihood that attacks will succeed. The likelihood of attacks succeeding is computed by applying a threat model to a system topology model and defender model. Cyber Security Game takes into account the widespread interconnectedness of cyber systems, where defenders must defend all multi-step attack paths and an attacker only needs one to succeed. It employs a game theoretic solution using a game formulation that identifies defense strategies to minimize the maximum cyber risk (MiniMax). This paper discusses the methods and models that compose Cyber Security Game . A limited example of a Point of Sale system is used to provide specific demonstrations of Cyber Security Game models and analyses.}
}
@misc{Muthukrishnan_Malis,
	title        = {A Core MPLS IP VPN Architecture},
	author       = {Muthukrishnan, Karthik and Malis, Andrew},
	url          = {https://tools.ietf.org/html/rfc2917}
}
@inproceedings{Nappa_Johnson_Bilge_Caballero_Dumitras_2015,
	title        = {The Attack of the Clones: A Study of the Impact of Shared Code on Vulnerability Patching},
	author       = {Nappa, Antonio and Johnson, Richard and Bilge, Leyla and Caballero, Juan and Dumitras, Tudor},
	year         = 2015,
	month        = may,
	booktitle    = {2015 IEEE Symposium on Security and Privacy},
	pages        = {692–708},
	doi          = {10.1109/SP.2015.48},
	issn         = {2375-1207},
	note         = {tex.ids: nappa2015a},
	abstractnote = {Vulnerability exploits remain an important mechanism for malware delivery, despite efforts to speed up the creation of patches and improvements in software updating mechanisms. Vulnerabilities in client applications (e.g., Browsers, multimedia players, document readers and editors) are often exploited in spear phishing attacks and are difficult to characterize using network vulnerability scanners. Analyzing their lifecycle requires observing the deployment of patches on hosts around the world. Using data collected over 5 years on 8.4 million hosts, available through Symantec's WINE platform, we present the first systematic study of patch deployment in client-side vulnerabilities. We analyze the patch deployment process of 1,593 vulnerabilities from 10 popular client applications, and we identify several new threats presented by multiple installations of the same program and by shared libraries distributed with several applications. For the 80 vulnerabilities in our dataset that affect code shared by two applications, the time between patch releases in the different applications is up to 118 days (with a median of 11 days). Furthermore, as the patching rates differ considerably among applications, many hosts patch the vulnerability in one application but not in the other one. We demonstrate two novel attacks that enable exploitation by invoking old versions of applications that are used infrequently, but remain installed. We also find that the median fraction of vulnerable hosts patched when exploits are released is at most 14\%. Finally, we show that the patching rate is affected by user-specific and application-specific factors, for example, hosts belonging to security analysts and applications with an automated updating mechanism have significantly lower median times to patch.}
}
@inproceedings{Nayak_Marino_Efstathopoulos_Dumitras_2014,
	title        = {Some Vulnerabilities Are Different Than Others},
	author       = {Nayak, Kartik and Marino, Daniel and Efstathopoulos, Petros and Dumitra\c{s}, Tudor},
	year         = 2014,
	volume       = 8688,
	pages        = {426–446},
	doi          = {10.1007/978-3-319-11379-1\_21},
	url          = {http://link.springer.com/10.1007/978-3-319-11379-1\_21},
	note         = {tex.ids: nayak2014a},
	abstractnote = {The security of deployed and actively used systems is a moving target, influenced by factors not captured in the existing security metrics. For example, the count and severity of vulnerabilities in source code, as well as the corresponding attack surface, are commonly used as measures of a software product's security. But these measures do not provide a full picture. For instance, some vulnerabilities are never exploited in the wild, partly due to security technologies that make exploiting them difficult. As for attack surface, its effectiveness has not been validated empirically in the deployment environment. We introduce several security metrics derived from field data that help to complete the picture. They include the count of vulnerabilities exploited and the size of the attack surface actually exercised in real-world attacks. By evaluating these metrics on nearly 300 million reports of intrusion-protection telemetry, collected on more than six million hosts, we conduct an empirical study of security in the deployment environment. We find that none of the products in our study have more than 35\% of their disclosed vulnerabilities exploited in the wild. Furthermore, the exploitation ratio and the exercised attack surface tend to decrease with newer product releases. We also find that hosts that quickly upgrade to newer product versions tend to have reduced exercised attack-surfaces. The metrics proposed enable a more complete assessment of the security posture of enterprise infrastructure. Additionally, they open up new research directions for improving security by focusing on the vulnerabilities and attacks that have the highest impact in practice.}
}
@article{Nessus,
	title        = {The nessus security scanner},
	author       = {Nessus},
	url          = {http://www.nessus.org},
	note         = {Citation Key: nessus-a tex.citation-number: 85 tex.type: [Online].}
}
@inproceedings{Neupane_Rahman_Saxena_Hirshfield_2015,
	title        = {A Multi-Modal Neuro-Physiological Study of Phishing Detection and Malware Warnings},
	author       = {Neupane, Ajaya and Rahman, Md. Lutfor and Saxena, Nitesh and Hirshfield, Leanne},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {479–491},
	doi          = {10.1145/2810103.2813660},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813660},
	note         = {tex.ids: neupane2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Detecting phishing attacks (identifying fake vs. real websites) and heeding security warnings represent classical user-centered security tasks subjected to a series of prior investigations. However, our understanding of user behavior underlying these tasks is still not fully mature, motivating further work concentrating at the neurophysiological level governing the human processing of such tasks. We pursue a comprehensive three-dimensional study of phishing detection and malware warnings, focusing not only on what users' task performance is but also on how users process these tasks based on: (1) neural activity captured using Electroencephalogram (EEG) cognitive metrics, and (2) eye gaze patterns captured using an eyetracker. Our primary novelty lies in employing multi-modal neurophysiological measures in a single study and providing a near realistic set-up (in contrast to a recent neuro-study conducted inside an fMRI scanner). Our work serves to advance, extend and support prior knowledge in several significant ways. Specifically, in the context of phishing detection, we show that users do not spend enough time analyzing key phishing indicators and often fail at detecting these attacks, although they may be mentally engaged in the task and subconsciously processing real sites differently from fake sites. In the malware warning tasks, in contrast, we show that users are frequently reading, possibly comprehending, and eventually heeding the message embedded in the warning.}
}
@article{Nicol_Sanders_Katz_Scherlis_Dumitra_Williams_Singh_2015,
	title        = {The science of security 5 hard problems},
	author       = {Nicol, D. and Sanders, B. and Katz, J. and Scherlis, B. and Dumitra, T. and Williams, L. and Singh, M.},
	year         = 2015,
	url          = {http://cps-vo.org/node/21590.},
	note         = {Citation Key: nicol2015a}
}
@article{Nicol_Sanders_Trivedi_2004,
	title        = {Model-based evaluation: from dependability to security},
	author       = {Nicol, D.M. and Sanders, W.H. and Trivedi, K.S.},
	year         = 2004,
	month        = jan,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 1,
	number       = 1,
	pages        = {48–65},
	doi          = {10.1109/TDSC.2004.11},
	issn         = {2160-9209},
	note         = {tex.ids: nicol2004a, nicolModelbasedEvaluationDependability2004a tex.citation-number: 52},
	abstractnote = {The development of techniques for quantitative, model-based evaluation of computer system dependability has a long and rich history. A wide array of model-based evaluation techniques is now available, ranging from combinatorial methods, which are useful for quick, rough-cut analyses, to state-based methods, such as Markov reward models, and detailed, discrete-event simulation. The use of quantitative techniques for security evaluation is much less common, and has typically taken the form of formal analysis of small parts of an overall design, or experimental red team-based approaches. Alone, neither of these approaches is fully satisfactory, and we argue that there is much to be gained through the development of a sound model-based methodology for quantifying the security one can expect from a particular design. In this work, we survey existing model-based techniques for evaluating system dependability, and summarize how they are now being extended to evaluate system security. We find that many techniques from dependability evaluation can be applied in the security domain, but that significant challenges remain, largely due to fundamental differences between the accidental nature of the faults commonly assumed in dependability evaluation, and the intentional, human nature of cyber attacks.}
}
@article{NIST,
	title        = {``National vulnerability database},
	url          = {https://nvd.nist.gov/},
	note         = {Citation Key: unknown-a tex.citation-number: 45 tex.type: [Online].}
}
@inproceedings{Niu_Tan_2015,
	title        = {Per-Input Control-Flow Integrity},
	author       = {Niu, Ben and Tan, Gang},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {914–926},
	doi          = {10.1145/2810103.2813644},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813644},
	note         = {tex.ids: niu2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Control-Flow Integrity (CFI) is an effective approach to mitigating control-flow hijacking attacks. Conventional CFI techniques statically extract a control-flow graph (CFG) from a program and instrument the program to enforce that CFG. The statically generated CFG includes all edges for all possible inputs; however, for a concrete input, the CFG may include many unnecessary edges.}
}
@inbook{Noel_2018,
	title        = {Text Mining for Modeling Cyberattacks},
	author       = {Noel, Steven},
	year         = 2018,
	month        = jan,
	booktitle    = {Handbook of Statistics},
	doi          = {10.1016/bs.host.2018.06.001},
	abstractnote = {This chapter examines how natural language processing can be applied for building rich models for cybersecurity analytics. For this, it applies text mining to the natural-language content of Common Attack Pattern Enumeration and Classification (CAPECTM), a standardized corpus of cyberattack patterns. We adopt a vector-space model in which CAPEC attack patterns are treated as documents with term vectors. This provides a space in which to define distance measures, such as for retrieving attack patterns through term queries or finding clusters of related attack patterns. Analysis of clustering patterns, i.e., cluster hierarchies (clusters within clusters) is aided through tree visualization techniques. These analytic and visual techniques provide a range of capabilities for leveraging the content and relationships in CAPEC, e.g., for building more complex security models such as network attack graphs.}
}
@article{Noel_Jajodia,
	title        = {Measuring Security Risk of Networks Using Attack Graphs},
	author       = {Noel, Steven and Jajodia, Sushil},
	volume       = 1,
	number       = 1,
	pages        = 13,
	note         = {tex.ids: noel2010a tex.citation-number: 99},
	abstractnote = {Today's computer systems face sophisticated attackers who combine multiple vulnerabilities to penetrate networks with devastating impact. The overall security of a network cannot be determined by simply counting the number of vulnerabilities. To accurately assess the security of networked systems, one must understand how vulnerabilities can be combined to stage an attack. We model such composition of vulnerabilities through attack graphs. By simulating incremental network penetration, and propagating attack likelihoods, we measure the overall security of a networked system. From this, we score risk mitigation options in terms of maximizing security and minimizing cost. We populate our attack graph models from live network scans and databases that have knowledge about properties such as vulnerability likelihood, impact, severity, and ease of exploitation. Our flexible model can be used to quantify overall security of networked systems, and to study cost/benefit tradeoffs for analyzing return on security investment.}
}
@inproceedings{Noel_Jajodia_2004,
	title        = {Managing attack graph complexity through visual hierarchical aggregation},
	author       = {Noel, Steven and Jajodia, Sushil},
	year         = 2004,
	booktitle    = {Proceedings of the 2004 ACM workshop on Visualization and data mining for computer security},
	publisher    = {ACM},
	pages        = {109–118},
	url          = {http://dl.acm.org/citation.cfm?id=1029225},
	note         = {tex.ids: noel2004a tex.citation-number: 87}
}
@inproceedings{Noel_Jajodia_2014,
	title        = {Metrics suite for network attack graph analytics},
	author       = {Noel, Steven and Jajodia, Sushil},
	year         = 2014,
	booktitle    = {Proceedings of the 9th Annual Cyber and Information Security Research Conference on - CISR '14},
	publisher    = {ACM Press},
	pages        = {5–8},
	doi          = {10.1145/2602087.2602117},
	isbn         = {978-1-4503-2812-8},
	url          = {http://dl.acm.org/citation.cfm?doid=2602087.2602117},
	note         = {tex.ids: noel2014a, noelMetricsSuiteNetwork2014a},
	place        = {Oak Ridge, Tennessee},
	abstractnote = {We describe a suite of metrics for measuring network-wide cyber security risk based on a model of multi-step attack vulnerability (attack graphs). Our metrics are grouped into families, with family-level metrics combined into an overall metric for network vulnerability risk. The Victimization family measures risk in terms of key attributes of risk across all known network vulnerabilities. The Size family is an indication of the relative size of the attack graph. The Containment family measures risk in terms of minimizing vulnerability exposure across protection boundaries. The Topology family measures risk through graph theoretic properties (connectivity, cycles, and depth) of the attack graph. We display these metrics (at the individual, family, and overall levels) in interactive visualizations, showing multiple metrics trends over time.}
}
@article{Oltramari_Henshel_Cains_Hoffman,
	title        = {Towards a Human Factors Ontology for Cyber Security},
	author       = {Oltramari, Alessandro and Henshel, Diane and Cains, Mariana and Hoffman, Blaine},
	pages        = 8,
	abstractnote = {Traditional cybersecurity risk assessment is reactive and based on business risk assessment approach. The 2014 NIST Cybersecurity Framework provides businesses with an organizational tool to catalog cybersecurity efforts and areas that need additional support. As part of an on-going effort to develop a holistic, predictive cyber security risk assessment model, the characterization of human factors, which includes human behavior, is needed to understand how the actions of users, defenders (IT personnel), and attackers affect cybersecurity risk. Trust has been found to be a crucial element affecting an individual's role within a cyber system. The use of trust as a human factor in holistic cybersecurity risk assessment relies on an understanding how differing mental models, risk postures, and social biases impact the level trust given to an individual and the biases affecting the ability to give said trust. The Human Factors Ontology illustrates the individual characteristics, situational characteristics, and relationships that influence the trust given to an individual. Furthering the incorporation of ontologies into the science of cybersecurity will help decision-makers build the foundation needed for predictive and quantitative risk assessments.}
}
@inproceedings{Ong_Nahrstedt_Yuan_2003,
	title        = {Quality of protection for mobile multimedia applications},
	author       = {Ong, C.S. and Nahrstedt, K. and Yuan, W.},
	year         = 2003,
	month        = jul,
	booktitle    = {Multimedia and expo, 2003. ICME '03. Proceedings. 2003 international conference on},
	volume       = 2,
	pages        = {137--40},
	note         = {Citation Key: ong2003a tex.citation-number: 57}
}
@article{Oppenheimer_Brown_Traupman_Broadwell_Patterson,
	title        = {Practical Issues in Dependability Benchmarking},
	author       = {Oppenheimer, David and Brown, Aaron B and Traupman, Jonathan and Broadwell, Pete and Patterson, David A},
	pages        = 6,
	abstractnote = {Much of the work to date on dependability benchmarks has focused on costly, comprehensive measurements of whole-system dependability. But benchmarks should also be useful for developers and researchers to quickly evaluate incremental improvements to their systems. To address both audiences, we propose dividing the space of dependability benchmarks into two categories: competitive benchmarks that take the holistic approach, and less expensive developer benchmarks aimed at day-to-day development tasks. In this paper we differentiate the goals of these two types of benchmarks, discuss how each type might be appropriately realized, and propose simplifying assumptions for making them cost-effective.}
}
@article{Oroojlooyjadid_2019,
	title        = {A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning algorithm to Solve Inventory Optimization Problems},
	author       = {Oroojlooyjadid, Afshin and Nazari, MohammadReza and Snyder, Lawrence and Tak\'{a}\v{c}, Martin},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1708.05924 [cs]},
	url          = {http://arxiv.org/abs/1708.05924},
	note         = {arXiv: 1708.05924},
	abstractnote = {The beer game is a widely used in-class game that is played in supply chain management classes to demonstrate the bullwhip effect. The game is a decentralized, multi-agent, cooperative problem that can be modeled as a serial supply chain network in which agents cooperatively attempt to minimize the total cost of the network even though each agent can only observe its own local information. Each agent chooses order quantities to replenish its stock. Under some conditions, a base-stock replenishment policy is known to be optimal. However, in a decentralized supply chain in which some agents (stages) may act irrationally (as they do in the beer game), there is no known optimal policy for an agent wishing to act optimally. We propose a machine learning algorithm, based on deep Q-networks, to optimize the replenishment decisions at a given stage. When playing alongside agents who follow a base-stock policy, our algorithm obtains near-optimal order quantities. It performs much better than a base-stock policy when the other agents use a more realistic model of human ordering behavior. Unlike most other algorithms in the literature, our algorithm does not have any limits on the beer game parameter values. Like any deep learning algorithm, training the algorithm can be computationally intensive, but this can be performed ahead of time; the algorithm executes in real time when the game is played. Moreover, we propose a transfer learning approach so that the training performed for one agent and one set of cost coefficients can be adapted quickly for other agents and costs. Our algorithm can be extended to other decentralized multi-agent cooperative games with partially observed information, which is a common type of situation in real-world supply chain problems.}
}
@article{Ortalo_1999,
	title        = {Experimenting with quantitative evaluation tools for monitoring operational security},
	author       = {Ortalo, Rodolphe and Deswarte, Yves and Ka\^{a}niche, Mohamed},
	year         = 1999,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 25,
	number       = 5,
	pages        = {633–650},
	note         = {tex.ids: ortalo1999a, ortaloExperimentingQuantitativeEvaluation1999a}
}
@book{Ou_Appel_2005,
	title        = {A logic-programming approach to network security analysis},
	author       = {Ou, Xinming and Appel, Andrew W.},
	year         = 2005,
	publisher    = {Princeton University Princeton}
}
@inproceedings{Ou_Boyer_McQueen_2006,
	title        = {A scalable approach to attack graph generation},
	author       = {Ou, Xinming and Boyer, Wayne F. and McQueen, Miles A.},
	year         = 2006,
	booktitle    = {Proceedings of the 13th ACM conference on Computer and communications security},
	publisher    = {ACM},
	pages        = {336–345},
	url          = {http://dl.acm.org/citation.cfm?id=1180446}
}
@article{Ou_Govindavajhala_Appel,
	title        = {MulVAL: A Logic-based Network Security Analyzer},
	author       = {Ou, Xinming and Govindavajhala, Sudhakar and Appel, Andrew W},
	year         = 2005,
	booktitle    = {Proceedings of the 14th conference on USENIX security symposium},
	publisher    = {USENIX Association},
	volume       = 14,
	pages        = 16,
	note         = {Citation Key: ou2005a tex.citation-number: 84},
	abstractnote = {To determine the security impact software vulnerabilities have on a particular network, one must consider interactions among multiple network elements. For a vulnerability analysis tool to be useful in practice, two features are crucial. First, the model used in the analysis must be able to automatically integrate formal vulnerability specifications from the bug-reporting community. Second, the analysis must be able to scale to networks with thousands of machines.},
	place        = {Berkeley, CA, USA}
}
@book{Ou_Singhal_2011,
	title        = {Quantitative Security Risk Assessment of Enterprise Networks},
	author       = {Ou, Xinming and Singhal, Anoop},
	year         = 2011,
	publisher    = {Springer New York},
	series       = {SpringerBriefs in Computer Science},
	doi          = {10.1007/978-1-4614-1860-3},
	isbn         = {978-1-4614-1859-7},
	url          = {http://link.springer.com/10.1007/978-1-4614-1860-3},
	note         = {tex.ids: ou2011a},
	place        = {New York, NY},
	collection   = {SpringerBriefs in Computer Science}
}
@inproceedings{ou2016asymmetric,
	title        = {Asymmetric transitivity preserving graph embedding},
	author       = {Ou, Mingdong and Cui, Peng and Pei, Jian and Zhang, Ziwei and Zhu, Wenwu},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd ACM SIGKDD},
	pages        = {1105--1114},
	organization = {ACM}
}
@article{Ouchani_Debbabi_2015,
	title        = {Specification, verification, and quantifi- cation of security in model-based systems},
	author       = {Ouchani, S. and Debbabi, M.},
	year         = 2015,
	month        = jul,
	journal      = {Computing},
	volume       = 97,
	number       = 7,
	pages        = {691--711,},
	note         = {Citation Key: ouchani2015a tex.citation-number: 25}
}
@inproceedings{Pamula_Jajodia_Ammann_Swarup_2006,
	title        = {A weakest-adversary security metric for network configuration security analysis},
	author       = {Pamula, Joseph and Jajodia, Sushil and Ammann, Paul and Swarup, Vipin},
	year         = 2006,
	booktitle    = {Proceedings of the 2nd ACM workshop on Quality of protection  - QoP '06},
	publisher    = {ACM Press},
	pages        = 31,
	doi          = {10.1145/1179494.1179502},
	isbn         = {978-1-59593-553-3},
	url          = {http://portal.acm.org/citation.cfm?doid=1179494.1179502},
	note         = {tex.ids: pamula2006a, pamulaWeakestadversarySecurityMetric2006a tex.citation-number: 96},
	place        = {Alexandria, Virginia, USA},
	abstractnote = {A security metric measures or assesses the extent to which a system meets its security objectives. Since meaningful quantitative security metrics are largely unavailable, the security community primarily uses qualitative metrics for security. In this paper, we present a novel quantitative metric for the security of computer networks that is based on an analysis of attack graphs. The metric measures the security strength of a network in terms of the strength of the weakest adversary who can successfully penetrate the network. We present an algorithm that computes the minimal sets of required initial attributes for the weakest adversary to possess in order to successfully compromise a network; given a specific network configuration, set of known exploits, a specific goal state, and an attacker class (represented by a set of all initial attacker attributes). We also demonstrate, by example, that diverse network configurations are not always beneficial for network security in terms of penetrability.}
}
@inproceedings{Paulauskas_Garsva_2008,
	title        = {Attacker skill level distribution es- timation in the system mean time-to-compromise},
	author       = {Paulauskas, N. and Garsva, E.},
	year         = 2008,
	month        = may,
	booktitle    = {Information technology, 2008. IT 2008. 1st international conference on},
	pages        = {1–4},
	note         = {Citation Key: paulauskas2008a tex.citation-number: 77}
}
@inproceedings{Paxson_2004,
	title        = {Strategies for sound internet measurement},
	author       = {Paxson, Vern},
	year         = 2004,
	booktitle    = {Proceedings of the 4th ACM SIGCOMM conference on Internet measurement  - IMC '04},
	publisher    = {ACM Press},
	pages        = 263,
	doi          = {10.1145/1028788.1028824},
	isbn         = {978-1-58113-821-4},
	url          = {http://portal.acm.org/citation.cfm?doid=1028788.1028824},
	note         = {tex.ids: paxsonStrategiesSoundInternet2004a},
	place        = {Taormina, Sicily, Italy},
	abstractnote = {Conducting an Internet measurement study in a sound fashion can be much more difficult than it might first appear. We present a number of strategies drawn from experiences for avoiding or overcoming some of the pitfalls. In particular, we discuss dealing with errors and inaccuracies; the importance of associating meta-data with measurements; the technique of calibrating measurements by examining outliers and testing for consistencies; difficulties that arise with large-scale measurements; the utility of developing a discipline for reliably reproducing analysis results; and issues with making datasets publicly available. We conclude with thoughts on the sorts of tools and community practices that can assist researchers with conducting sound measurement studies.}
}
@book{Payne_2006,
	title        = {A Guide to Security Metrics},
	author       = {Payne, S.C.},
	year         = 2006,
	pages        = 11,
	note         = {Citation Key: payne2006a tex.citation-number: 22},
	institution  = {SANS Institute}
}
@article{Pendleton_Garcia-Lebron_Cho_Xu_2016,
	title        = {A Survey on Systems Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Cho, Jin-Hee and Xu, Shouhuai},
	year         = 2016,
	month        = 12,
	journal      = {ACM Computing Surveys},
	volume       = 49,
	number       = 4,
	pages        = {1–35},
	doi          = {10.1145/3005714},
	issn         = {03600300},
	note         = {tex.ids: pendleton2016a, pendletonSurveySystemsSecurity2016a, pendletonSurveySystemsSecurity2016b, pendletonSurveySystemsSecurity2016c, pendletonSurveySystemsSecurity2016d, pendletonSurveySystemsSecurity2016e, pendletonSurveySystemsSecurity2016f, pendletonSurveySystemsSecurity2016g tex.citation-number: 141}
}
@article{Pendleton_Garcia-Lebron_Xu_2016,
	title        = {A Survey on Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Xu, Shouhuai},
	year         = 2016,
	month        = jan,
	journal      = {arXiv:1601.05792 [cs]},
	url          = {http://arxiv.org/abs/1601.05792},
	note         = {arXiv: 1601.05792},
	abstractnote = {The importance of security metrics can hardly be overstated. Despite the attention that has been paid by the academia, government and industry in the past decades, this important problem stubbornly remains open. In this survey, we present a survey of knowledge on security metrics. The survey is centered on a novel taxonomy, which classifies security metrics into four categories: metrics for measuring the system vulnerabilities, metrics for measuring the defenses, metrics for measuring the threats, and metrics for measuring the situations. The insight underlying the taxonomy is that situations (or outcomes of cyber attack-defense interactions) are caused by certain threats (or attacks) against systems that have certain vulnerabilities (including human factors) and employ certain defenses. In addition to systematically reviewing the security metrics that have been proposed in the literature, we discuss the gaps between the state of the art and the ultimate goals.}
}
@inproceedings{Perl_Dechand_Smith_Arp_Yamaguchi_Rieck_Fahl_Acar_2015,
	title        = {Vccfinder: Finding potential vulnerabilities in open-source projects to assist code audits},
	author       = {Perl, Henning and Dechand, Sergej and Smith, Matthew and Arp, Daniel and Yamaguchi, Fabian and Rieck, Konrad and Fahl, Sascha and Acar, Yasemin},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {426–437}
}
@inproceedings{perozzi2014deepwalk,
	title        = {Deepwalk: Online learning of social representations},
	author       = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
	year         = 2014,
	booktitle    = {Proceedings of KDD},
	pages        = {701--710}
}
@article{Pfleeger_2009,
	title        = {Useful Cybersecurity Metrics},
	author       = {Pfleeger, Shari Lawrence},
	year         = 2009,
	month        = jun,
	journal      = {IT Professional Magazine; Washington},
	volume       = 11,
	number       = 3,
	pages        = {38–45},
	doi          = {http://dx.doi.org/10.1109/MITP.2009.63},
	issn         = 15209202,
	note         = {tex.ids: pfleeger2009a},
	abstractnote = {Measuring cybersecurity is difficult, but other disciplines can offer important lessons and techniques for building a system that can help test hypotheses about system security. [PUBLICATION ABSTRACT]}
}
@article{Pfleeger_Cunningham_2010,
	title        = {Why Measuring Security Is Hard},
	author       = {Pfleeger, Shari and Cunningham, Robert},
	year         = 2010,
	month        = jul,
	journal      = {IEEE Security Privacy},
	volume       = 8,
	number       = 4,
	pages        = {46–54},
	doi          = {10.1109/MSP.2010.60},
	issn         = {1558-4046},
	note         = {tex.ids: pfleeger2010a tex.citation-number: 140},
	abstractnote = {For many years, we've been trying to measure ``security'' so that we can increase accountability, demonstrate compliance, and determine whether and by how much our investments in products and processes are making our systems more secure. This article investigates why security measurement is difficult and what strategies might help address our needs.}
}
@inproceedings{Phillips_Swiler_1998,
	title        = {A graph-based system for network-vulnerability analysis},
	author       = {Phillips, Cynthia and Swiler, Laura Painton},
	year         = 1998,
	booktitle    = {Proceedings of the 1998 workshop on New security paradigms  - NSPW '98},
	publisher    = {ACM Press},
	pages        = {71–79},
	doi          = {10.1145/310889.310919},
	isbn         = {978-1-58113-168-0},
	url          = {http://portal.acm.org/citation.cfm?doid=310889.310919},
	note         = {tex.ids: phillips1998a, phillipsGraphbasedSystemNetworkvulnerability1998a tex.citation-number: 83},
	place        = {Charlottesville, Virginia, United States},
	abstractnote = {This paper presents a graph-based approach to network vulnerability analysis. The method is flexible, allowing analysis of attacks from both outside and inside the network. It can analyze risks to a specific network asset, or examine the universe of possible consequences following a successful attack. The graph-based tool can identify the set of attack paths that have a high probability of success (or a low ``effort'' cost) for the attacker. The system could be used to test the effectiveness of making configuration changes, implementing an intrusion detection system, etc.}
}
@inbook{Piessens_2019,
	title        = {The cyber security body of knowledge},
	author       = {Piessens, Frank},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Software Security}
}
@misc{Plummer,
	title        = {An Ethernet Address Resolution Protocol: Or Converting Network Protocol Addresses to 48.bit Ethernet Address for Transmission on Ethernet Hardware},
	author       = {Plummer, D.},
	url          = {https://tools.ietf.org/html/rfc826}
}
@article{Poolsappasit_Dewri_Ray_2012,
	title        = {Dynamic security risk management using bayesian attack graphs},
	author       = {Poolsappasit, N. and Dewri, R. and Ray, I.},
	year         = 2012,
	month        = jan,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 9,
	number       = 1,
	pages        = {61--74,},
	note         = {Citation Key: poolsappasit2012a tex.citation-number: 107}
}
@inproceedings{Prakash_Wellman_2015,
	title        = {Empirical Game-Theoretic Analysis for Moving Target Defense},
	author       = {Prakash, Achintya and Wellman, Michael P.},
	year         = 2015,
	booktitle    = {Proceedings of the Second ACM Workshop on Moving Target Defense - MTD '15},
	publisher    = {ACM Press},
	pages        = {57–65},
	doi          = {10.1145/2808475.2808483},
	isbn         = {978-1-4503-3823-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2808475.2808483},
	note         = {tex.ids: prakash2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {The effectiveness of a moving target defense depends on how it is deployed through specific system operations over time, and how attackers may respond to this deployment. We define a generic cyber-defense scenario, and examine the interplay between attack and defense strategies using empirical game-theoretic techniques. In this approach, the scenario is defined procedurally by a simulator, and data derived from systematic simulation is used to induce a game model. We explore a space of 72 game instances, defined by differences in agent objectives, attack cost, and ability of the defender to detect attack actions. We observe a range of qualitative strategic behaviors, which vary in clear patterns across environmental conditions. In particular, we find that the efficacy of deterrent defense is critically sensitive to detection capability, and in the absence of perfect detection the defender is often driven to proactive moving-target actions.}
}
@article{Premaratne_Samarabandu_Sidhu_Beresh_Tan_2010,
	title        = {Security Analysis and Auditing of IEC61850-Based Automated Substations},
	author       = {Premaratne, Upeka and Samarabandu, Jagath and Sidhu, Tarlochan and Beresh, Robert and Tan, Jian-Cheng},
	year         = 2010,
	month        = oct,
	journal      = {IEEE Transactions on Power Delivery},
	volume       = 25,
	number       = 4,
	pages        = {2346–2355},
	doi          = {10.1109/TPWRD.2010.2043122},
	issn         = {1937-4208},
	note         = {tex.ids: premaratne2010a tex.citation-number: 4},
	abstractnote = {This paper proposes a scheme for auditing the security of an IEC61850-based network based upon a novel security metric for intelligent electronic devices (IEDs). A detailed security analysis on an IEC61850 automated substation is peformed initially with a focus on the possible goals of the attacker. This is followed by the development of a scheme to audit the security of such a network. Security metrics are considered since they provide a tangible means of quantifying the security of a network. The proposed auditing scheme is tested by using it to audit the security of an IEC61850 network. The results are then compared with two other metric schemes-the mean time to compromise (MTTC) metric and the VEA-bility metric, which are used for auditing conventional computer networks. The input data for both metrics are obtained by using a network security tool to scan the IEDs of the network. The impact of using high-traffic generating network security tools on a time-critical IEC61850 network is also investigated.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM '18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network's normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices' context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks' Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@article{Qu_Bengio_Tang,
	title        = {GMNN: Graph Markov Neural Networks},
	author       = {Qu, Meng and Bengio, Yoshua and Tang, Jian},
	pages        = 10,
	abstractnote = {This paper studies semi-supervised object classification in relational data, which is a fundamental problem in relational data modeling. The problem has been extensively studied in the literature of both statistical relational learning (e.g. relational Markov networks) and graph neural networks (e.g. graph convolutional networks). Statistical relational learning methods can effectively model the dependency of object labels through conditional random fields for collective classification, whereas graph neural networks learn effective object representations for classification through end-to-end training. In this paper, we propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds. A GMNN models the joint distribution of object labels with a conditional random field, which can be effectively trained with the variational EM algorithm. In the E-step, one graph neural network learns effective object representations for approximating the posterior distributions of object labels. In the M-step, another graph neural network is used to model the local label dependency. Experiments on object classification, link classification, and unsupervised node representation learning show that GMNN achieves state-of-the-art results.}
}
@article{qualprotection_2005,
	year         = 2005,
	url          = {http://disi.unitn.it/},
	note         = {Citation Key: unknown2005a tex.citation-number: 64}
}
@inproceedings{Rahman_Williams_2016,
	title        = {Security practices in DevOps},
	author       = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
	year         = 2016,
	booktitle    = {Proceedings of the Symposium and Bootcamp on the Science of Security - HotSos '16},
	publisher    = {ACM Press},
	pages        = {109–111},
	doi          = {10.1145/2898375.2898383},
	isbn         = {978-1-4503-4277-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2898375.2898383},
	place        = {Pittsburgh, Pennsylvania}
}
@inproceedings{Rajab_Monrose_Terzis_2005,
	title        = {On the effectiveness of distributed worm monitoring},
	author       = {Rajab, M. and Monrose, F. and Terzis, A.},
	year         = 2005,
	booktitle    = {Proc. USENIX security symposium. Google scholar},
	note         = {Citation Key: rajab2005a}
}
@inproceedings{Ramos_Aquino_Filho_Rodrigues,
	title        = {Quantifying node security in wireless sensor networks under worm attacks},
	author       = {Ramos, A. and Aquino, B. and Filho, R.Holanda and Rodrigues, J.J.P.C.},
	booktitle    = {Brazilian symposium of computer networks},
	note         = {Citation Key: ramos-b tex.citation-number: 35}
}
@article{Ramos_Filho_2015,
	title        = {Sensor data security level estimation scheme for wireless sensor networks},
	author       = {Ramos, A. and Filho, R.},
	year         = 2015,
	month        = jan,
	journal      = {Sensors},
	volume       = 15,
	number       = 1,
	pages        = {2104--2136,},
	note         = {Citation Key: ramos2015a tex.citation-number: 33}
}
@inproceedings{Ramos_Lazar_Filho_Rodrigues,
	title        = {A security metric for the evaluation of collaborative intrusion de- tection systems in wireless sensor networks},
	author       = {Ramos, A. and Lazar, M. and Filho, R.Holanda and Rodrigues, J.J.P.C.},
	booktitle    = {IEEE international conference on communications},
	note         = {Citation Key: ramos-a tex.citation-number: 34}
}
@article{Ramos_Lazar_Filho_Rodrigues_2017,
	title        = {Model-Based Quantitative Network Security Metrics: A Survey},
	author       = {Ramos, Alex and Lazar, Marcella and Filho, Raimir Holanda and Rodrigues, Joel J. P. C.},
	year         = 2017,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 19,
	number       = 4,
	pages        = {2704–2734},
	doi          = {10.1109/COMST.2017.2745505},
	issn         = {2373-745X},
	abstractnote = {Network security metrics (NSMs) based on models allow to quantitatively evaluate the overall resilience of networked systems against attacks. For that reason, such metrics are of great importance to the security-related decision-making process of organizations. Considering that over the past two decades several model-based quantitative NSMs have been proposed, this paper presents a deep survey of the state-of-the-art of these proposals. First, to distinguish the security metrics described in this survey from other types of security metrics, an overview of security metrics, in general, and their classifications is presented. Then, a detailed review of the main existing model-based quantitative NSMs is provided, along with their advantages and disadvantages. Finally, this survey is concluded with an in-depth discussion on relevant characteristics of the surveyed proposals and open research issues of the topic.}
}
@inproceedings{Rao_1997,
	title        = {XSB: A system for efficiently computing well-founded semantics},
	author       = {Rao, Prasad and Sagonas, Konstantinos and Swift, Terrance and Warren, David S. and Freire, Juliana},
	year         = 1997,
	booktitle    = {Logic Programming And Nonmonotonic Reasoning},
	publisher    = {Springer Berlin Heidelberg},
	pages        = {430–440},
	isbn         = {978-3-540-69249-2},
	place        = {Berlin, Heidelberg},
	abstractnote = {The well-founded model provides a natural and robust semantics for logic programs with negative literals in rule bodies. We implemented the well-founded semantics in the SLG-WAM of XSB [19]. Performance results indicate that the overhead of delay and simplification to Prolog -- or tabled -- evaluations is minimal. To compute the well-founded semantics, the SLG-WAM adds to an efficient tabling engine for definite programs three operations -- negative loop detection, delay and simplification -- which serve to detect, to break and to resolve cycles through negation that might arise in evaluating normal programs. XSB is a full Prolog system that closely approximates the ISO standard; additionally, it supports a tight integration of tabled predicates with nontabled predicates.},
	editor       = {Dix, J\"{u}rgen and Furbach, Ulrich and Nerode, AnilEditors}
}
@article{Rashid_Chivers_Danezis_Lupu_Martin,
	title        = {The Cyber Security Body of Knowledge},
	author       = {Rashid, Awais and Chivers, Howard and Danezis, George and Lupu, Emil and Martin, Andrew},
	pages        = 854,
	note         = {tex.ids: rashidCyberSecurityBodya, rashidCyberSecurityBodyb}
}
@article{Reiter_Stubblebine_1999,
	title        = {Authentication metric analysis and design},
	author       = {Reiter, Michael K. and Stubblebine, Stuart G.},
	year         = 1999,
	month        = may,
	journal      = {ACM Transactions on Information and System Security},
	volume       = 2,
	number       = 2,
	pages        = {138–158},
	doi          = {10.1145/317087.317088},
	issn         = 10949224,
	note         = {tex.ids: reiter1999a, reiterAuthenticationMetricAnalysis1999a}
}
@inproceedings{Rimal_Choi_Lumb_2009,
	title        = {A taxonomy and survey of cloud computing systems},
	author       = {Rimal, B.P. and Choi, E. and Lumb, I.},
	year         = 2009,
	month        = aug,
	booktitle    = {INC, IMS and IDC, 2009. NCM '09. Fifth international joint conference on},
	pages        = {44–51},
	note         = {Citation Key: rimal2009a tex.citation-number: 130}
}
@article{Ring_Wunderlich,
	title        = {Flow-based benchmark data sets for intrusion detection},
	author       = {Ring, Markus and Wunderlich, Sarah and Gr\"{u}dl, Dominik and Landes, Dieter and Hotho, Andreas},
	pages        = 10,
	note         = {tex.ids: ringFlowbasedBenchmarkDataa},
	abstractnote = {Anomaly based intrusion detection systems suffer from a lack of appropriate evaluation data sets. Often, existing data sets may not be published due to privacy concerns or do not reflect actual and current attack scenarios. In order to overcome these problems, we identify characteristics of good data sets and develop an appropriate concept for the generation of labelled flow-based data sets that satisfy these criteria. The concept is implemented based on OpenStack, thus demonstrating the suitability of virtual environments. Virtual environments offer advantages compared to static data sets by easily creating up-to-date data sets with recent trends in user behaviour and new attack scenarios.}
}
@inproceedings{Ritchey_Ammann_2000,
	title        = {Using model checking to analyze network vulnerabilities},
	author       = {Ritchey, R.W. and Ammann, P.},
	year         = 2000,
	booktitle    = {Proceeding 2000 IEEE Symposium on Security and Privacy. S\&P 2000},
	publisher    = {IEEE Comput. Soc},
	pages        = {156–165},
	doi          = {10.1109/SECPRI.2000.848453},
	isbn         = {978-0-7695-0665-4},
	url          = {http://ieeexplore.ieee.org/document/848453/},
	note         = {tex.ids: ritchey2000a, ritcheyUsingModelChecking2000a tex.citation-number: 90 ISSN: 1081-6011},
	place        = {Berkeley, CA, USA},
	abstractnote = {Even well administered networks are vulnerable to attacks due to the security ramifications of offering a variety of combined services. That is, services that are secure when offered in isolation nonetheless provide an attacker with a vulnerability to exploit when offered simultaneously. Many current tools address vulnerabilities in the context of a single host. In this paper we address vulnerabilities due to the configuration of various hosts in a network.}
}
@inproceedings{rndic_Laskov_2014,
	title        = {Practical Evasion of a Learning-Based Classifier: A Case Study},
	author       = {rndic, Nedim and Laskov, Pavel},
	year         = 2014,
	month        = may,
	booktitle    = {2014 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {197–211},
	doi          = {10.1109/SP.2014.20},
	isbn         = {978-1-4799-4686-0},
	url          = {http://ieeexplore.ieee.org/document/6956565/},
	note         = {tex.ids: rndic2014a},
	place        = {San Jose, CA},
	abstractnote = {Learning-based classifiers are increasingly used for detection of various forms of malicious data. However, if they are deployed online, an attacker may attempt to evade them by manipulating the data. Examples of such attacks have been previously studied under the assumption that an attacker has full knowledge about the deployed classifier. In practice, such assumptions rarely hold, especially for systems deployed online. A significant amount of information about a deployed classifier system can be obtained from various sources. In this paper, we experimentally investigate the effectiveness of classifier evasion using a real, deployed system, PDFRATE, as a test case. We develop a taxonomy for practical evasion strategies and adapt known evasion algorithms to implement specific scenarios in our taxonomy. Our experimental results reveal a substantial drop of PDFRATE's classification scores and detection accuracy after it is exposed even to simple attacks. We further study potential defense mechanisms against classifier evasion. Our experiments reveal that the original technique proposed for PDFRATE is only effective if the executed attack exactly matches the anticipated one. In the discussion of the findings of our study, we analyze some potential techniques for increasing robustness of learningbased systems against adversarial manipulation of data.}
}
@book{Roberts_1979,
	title        = {Measurement theory, with applications to decision making, utility and the social sciences},
	author       = {Roberts, F.},
	year         = 1979,
	publisher    = {Addison-Wesley, Boston.Google Scholar},
	note         = {Citation Key: roberts1979a}
}
@article{Rosen_Rekhter_2006,
	title        = {BGP/MPLS IP virtual private networks (VPNs)},
	author       = {Rosen, Eric C. and Rekhter, Yakov},
	year         = 2006
}
@article{Rosenquist,
	title        = {Prioritizing Information Security Risks with Threat Agent Risk Assessment},
	author       = {Rosenquist, Matt},
	pages        = 8
}
@article{Roundy_Miller_2013,
	title        = {Binary-code obfuscations in prevalent packer tools},
	author       = {Roundy, Kevin A. and Miller, Barton P.},
	year         = 2013,
	month        = oct,
	journal      = {ACM Computing Surveys},
	volume       = 46,
	number       = 1,
	pages        = {1–32},
	doi          = {10.1145/2522968.2522972},
	issn         = {03600300},
	note         = {tex.ids: roundy2013a}
}
@inbook{Roussev_2019,
	title        = {The cyber security body of knowledge},
	author       = {Roussev, Vassil},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Forensics}
}
@article{Rudolph_Schwarz_2012,
	title        = {Security indicators–a state of the art survey public report},
	author       = {Rudolph, Manuel and Schwarz, Reinhard},
	year         = 2012,
	month        = aug,
	journal      = {FhG IESE VII (043)},
	booktitle    = {2012 Seventh International Conference on Availability, Reliability and Security},
	pages        = {291–300},
	doi          = {10.1109/ARES.2012.10},
	note         = {tex.ids: rudolph2012a, rudolphCriticalSurveySecurity2012a tex.citation-number: 17 ISSN: null},
	abstractnote = {To better control IT security in software engineering and IT management, we need to assess security qualities in the different phases of a system's lifecycle. To this end, various security indicators, measures, and metrics have been proposed by scientists and practitioners, but few have gained general acceptance. We surveyed the current state of the art in qualita-tive and quantitative security measurement to characterize the available measurement strategies, their maturity, and the conceptual or technical obstacles preventing further progress in this field of research. We classified the proposed security indicators with respect to their characteristic properties and derived a classification tree delineating the different security assessment strategies and their derived security measures. Based on this overview, we analyzed the relative merits and deficiencies of current approaches, and we suggested future steps towards better security metrics. This paper summarizes the main results of our survey.}
}
@inproceedings{Sabottke_Suciu_Dumitras,
	title        = {Vulnerability Disclosure in the Age of Social Media: Exploiting Twitter for Predicting Real-World Exploits},
	author       = {Sabottke, Carl and Suciu, Octavian-Petru and Dumitras, Tudor},
	pages        = 16,
	note         = {tex.ids: sabottke2015a},
	abstractnote = {In recent years, the number of software vulnerabilities discovered has grown significantly. This creates a need for prioritizing the response to new disclosures by assessing which vulnerabilities are likely to be exploited and by quickly ruling out the vulnerabilities that are not actually exploited in the real world. We conduct a quantitative and qualitative exploration of the vulnerability-related information disseminated on Twitter. We then describe the design of a Twitter-based exploit detector, and we introduce a threat model specific to our problem. In addition to response prioritization, our detection techniques have applications in risk modeling for cyber-insurance and they highlight the value of information provided by the victims of attacks.}
}
@article{Sahinoglu_2005,
	title        = {Security meter: A practical decision-tree model to quantify risk},
	author       = {Sahinoglu, M.},
	year         = 2005,
	journal      = {IEEE Security and Privacy},
	volume       = 3,
	number       = 3,
	pages        = {18--24,},
	note         = {Citation Key: sahinoglu2005a tex.citation-number: 122}
}
@article{Sahinoglu_2008,
	title        = {An input-output measurable design for the security meter model to quantify and manage software security risk},
	author       = {Sahinoglu, M.},
	year         = 2008,
	journal      = {IEEE Transactions on Instrumentation and Measurement},
	volume       = 57,
	number       = 6,
	pages        = {1251--1260,},
	note         = {Citation Key: sahinoglu2008a tex.citation-number: 123}
}
@article{Saitta_Larcom_Eddington,
	title        = {Trike v.1 Methodology Document [Draft]},
	author       = {Saitta, Paul and Larcom, Brenda and Eddington, Michael},
	pages        = 17
}
@inproceedings{Sallhammar_2006,
	title        = {Towards a stochastic model for integrated security and depend- ability evaluation},
	author       = {Sallhammar, K.},
	year         = 2006,
	month        = apr,
	booktitle    = {First international conference on availability, reliability and security (ARES'06},
	pages        = 8,
	note         = {Citation Key: sallhammar2006b tex.citation-number: 54}
}
@article{Sallhammar_Helvik_Knapskog_2006,
	title        = {On stochastic mod- eling for integrated security and dependability evaluation},
	author       = {Sallhammar, K. and Helvik, B.E. and Knapskog, S.J.},
	year         = 2006,
	month        = oct,
	journal      = {Journal of Networks},
	volume       = 1,
	number       = 5,
	note         = {Citation Key: sallhammar2006a tex.citation-number: 53}
}
@article{Sanders_2014,
	title        = {Quantitative Security Metrics: Unattainable Holy Grail or a Vital Breakthrough within Our Reach?},
	author       = {Sanders, William H.},
	year         = 2014,
	month        = mar,
	journal      = {IEEE Security Privacy},
	volume       = 12,
	number       = 2,
	pages        = {67–69},
	doi          = {10.1109/MSP.2014.31},
	issn         = {1558-4046},
	note         = {tex.ids: sanders2014a},
	abstractnote = {It's long been well understood that you can calculate useful estimations of systems' reliability against accidental failure. It's also well understood that trying to calculate systems' level of security against possibly intelligent, determined, well-funded, and creative adversaries is a far greater challenge. Nevertheless, even a less-than-perfect predictive capacity, if its limitations are respected, is clearly better than none at all. Without promising perfection, such a capacity would offer crucial support to decision making that impacts system security.}
}
@inbook{Sasse_2019,
	title        = {The cyber security body of knowledge},
	author       = {Sasse, M. Angela},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Human Factors}
}
@inproceedings{Savola_2007,
	title        = {Towards a Security Metrics Taxonomy for the Information and Communication Technology Industry},
	author       = {Savola, Reijo},
	year         = 2007,
	month        = {08},
	booktitle    = {International Conference on Software Engineering Advances (ICSEA 2007)},
	pages        = {60–60},
	doi          = {10.1109/ICSEA.2007.79},
	issn         = {null},
	note         = {tex.ids: savola2007a tex.citation-number: 15 ISSN: null},
	abstractnote = {To obtain evidence of the security of different products or organizations, systematic approaches to measuring security are needed. We introduce a high abstraction level taxonomy to support the development of feasible security metrics, along with a survey of the emerging security metrics from the academic, governmental and industrial perspectives. With our taxonomy, we strive to bridge the gap between information security management and ICT products, and services security engineering. We believe that if common metrics approaches between different security disciplines can be found, this will advance our holistic understanding and capabilities, both in security management and engineering. Our taxonomy is based on comparing earlier taxonomy approaches and analyzing types of security metrics. Based on the survey, a discussion of future research directions is given in order to prompt advances in the field.}
}
@article{Savola_2013,
	title        = {Quality of security metrics and measurements},
	author       = {Savola, Reijo M.},
	year         = 2013,
	month        = {09},
	journal      = {Computers \& Security},
	volume       = 37,
	pages        = {78–90},
	doi          = {10.1016/j.cose.2013.05.002},
	issn         = {0167-4048},
	abstractnote = {Quantification of information security can be used to obtain evidence to support decision-making about the security performance of software systems. Knowledge about the relational importance of the main quality criteria of security metrics can help build security metrology models based on practical needs. This paper presents the results of a quantitative security metrics expert survey of 141 respondents, and an associated interview study, regarding the prioritization of 19 quality criteria of security metrics identified in the literature. The interviews were used to validate the survey results and to obtain further information on the findings. The results identified three foundational quality criteria of security metrics: correctness, measurability, and meaningfulness. These criteria form the basis for credibility and sufficiency for security metrics and associated measurements. Moreover, usability was seen as an important criterion. The paper analyzes the foundational and related quality criteria and proposes a model of them.}
}
@inproceedings{Scarfone_Mell_2008,
	title        = {Vulnerability scoring for security configuration settings},
	author       = {Scarfone, Karen and Mell, Peter},
	year         = 2008,
	booktitle    = {Proceedings of the 4th ACM workshop on Quality of protection},
	pages        = {3–8}
}
@inproceedings{Scarfone_Mell_2009,
	title        = {An analysis of cvss version 2 vulnerability scoring},
	author       = {Scarfone, K. and Mell, P.},
	year         = 2009,
	month        = oct,
	booktitle    = {2009 3rd international symposium on empirical software engineering and measurement},
	pages        = {516–525},
	note         = {Citation Key: scarfone2009a tex.citation-number: 48}
}
@article{Schneider,
	title        = {Blueprint for a Science of Cybersecurity},
	author       = {Schneider, Fred B},
	pages        = 17
}
@article{Schneier_1999,
	title        = {Attack trees},
	author       = {Schneier, Bruce},
	year         = 1999,
	journal      = {Dr. Dobb's journal},
	volume       = 24,
	number       = 12,
	pages        = {21–29},
	note         = {tex.ids: schneierAttackTrees1999a}
}
@article{Schneier_2000,
	title        = {Secrets 8 lies: Digital security in a networked world},
	author       = {Schneier, B.},
	year         = 2000,
	note         = {Citation Key: schneier2000a}
}
@article{Schoenfield,
	title        = {Threat Modeling Demystified},
	author       = {Schoenfield, Brook S E},
	pages        = 98
}
@inproceedings{Schryen_Kadura_2009,
	title        = {Open source vs. closed source software: towards measuring security},
	author       = {Schryen, Guido and Kadura, Rouven},
	year         = 2009,
	booktitle    = {Proceedings of the 2009 ACM symposium on Applied Computing},
	pages        = {2016–2023}
}
@article{Sembiring_Ramadhan_Gondokaryono_Arman_2015,
	title        = {Network Security Risk Analysis using Improved MulVAL Bayesian Attack Graphs},
	author       = {Sembiring, Jaka and Ramadhan, Mufti and Gondokaryono, Yudi and Arman, Arry},
	year         = 2015,
	month        = 12,
	journal      = {International Journal on Electrical Engineering and Informatics},
	volume       = 7,
	pages        = {735–753},
	doi          = {10.15676/ijeei.2015.7.4.15},
	abstractnote = {This paper presents some improvements on the Multihost Multistage Vulnerability Analysis (MulVAL) framework. MulVAL is a framework to generate an attack graph for analysis of a computer network security risk. In MulVAL, it is assumed that the probability of success in exploiting the machine configuration and vulnerability variable is 100, and the vulnerability variables are independent of each other. In reality each machine has its own security configuration issue, and vulnerabilities are not independent of each other. Moreover the research in MulVAL attack graph solely focuses on the probability of vulnerability, whereas the probability of vulnerability in security configuration is not covered. In this paper we introduce three methods to improve the MulVAL framework. In the first method we employ Common Vulnerability Scoring System (CVSS) for calculating the probability of vulnerability variables, and Common Configuration Scoring System (CCSS) for calculating the probability of vulnerability of system security configuration. In the second method we introduce the interdependence of vulnerability variables in Bayesian senses. Finally, in the third method we analyze the impact of the change in system security configuration to the probability of vulnerability in the context of Bayesian probability. We analyze and discuss the proposed methods through a simulation for a simple network configuration. The simulation results of the proposed methods demonstrate that the introduction of CVSS, CCSS, employing dependency of vulnerability variables and system security configuration represent a more realistic model for vulnerability in MulVAL framework. \textcopyright{} 2015, School of Electrical Engineering and Informatics. All rights reserved.}
}
@article{SEv2-c21.pdf,
	url          = {https://www.cl.cam.ac.uk/~rja14/Papers/SEv2-c21.pdf}
}
@inproceedings{Shacham_Page_Pfaff_Goh_Modadugu_Boneh_2004,
	title        = {On the effectiveness of address-space randomization},
	author       = {Shacham, Hovav and Page, Matthew and Pfaff, Ben and Goh, Eu-Jin and Modadugu, Nagendra and Boneh, Dan},
	year         = 2004,
	booktitle    = {Proceedings of the 11th ACM conference on Computer and communications security  - CCS '04},
	publisher    = {ACM Press},
	pages        = 298,
	doi          = {10.1145/1030083.1030124},
	isbn         = {978-1-58113-961-7},
	url          = {http://portal.acm.org/citation.cfm?doid=1030083.1030124},
	note         = {tex.ids: shacham2004a},
	place        = {Washington DC, USA},
	abstractnote = {Address-space randomization is a technique used to fortify systems against buffer overflow attacks. The idea is to introduce artificial diversity by randomizing the memory location of certain system components. This mechanism is available for both Linux (via PaX ASLR) and OpenBSD. We study the effectiveness of address-space randomization and find that its utility on 32-bit architectures is limited by the number of bits available for address randomization. In particular, we demonstrate a derandomization attack that will convert any standard buffer-overflow exploit into an exploit that works against systems protected by address-space randomization. The resulting exploit is as effective as the original, albeit somewhat slower: on average 216 seconds to compromise Apache running on a Linux PaX ASLR system. The attack does not require running code on the stack.}
}
@article{Shandilya_Simmons_Shiva_2014,
	title        = {Use of attack graphs in security systems},
	author       = {Shandilya, V. and Simmons, C.B. and Shiva, S.},
	year         = 2014,
	journal      = {Journal of Computer Networks and Communi- cations},
	volume       = 2014,
	pages        = {1--13,},
	note         = {Citation Key: shandilya2014a tex.citation-number: 93}
}
@article{Sharafaldin_Gharib_Lashkari_Ghorbani_2018,
	title        = {Towards a Reliable Intrusion Detection Benchmark Dataset},
	author       = {Sharafaldin, Iman and Gharib, Amirhossein and Lashkari, Arash Habibi and Ghorbani, Ali A.},
	year         = 2018,
	month        = jan,
	journal      = {Software Networking},
	volume       = 2018,
	number       = 1,
	pages        = {177–200},
	doi          = {10.13052/jsn2445-9739.2017.009},
	issn         = {2445-9739},
	abstractnote = {Towards a Reliable Intrusion Detection Benchmark Dataset}
}
@inproceedings{Sheng_Holbrook_Kumaraguru_Cranor_Downs_2010,
	title        = {Who falls for phish?: a demographic analysis of phishing susceptibility and effectiveness of interventions},
	author       = {Sheng, Steve and Holbrook, Mandy and Kumaraguru, Ponnurangam and Cranor, Lorrie Faith and Downs, Julie},
	year         = 2010,
	booktitle    = {Proceedings of the 28th international conference on Human factors in computing systems - CHI '10},
	publisher    = {ACM Press},
	pages        = 373,
	doi          = {10.1145/1753326.1753383},
	isbn         = {978-1-60558-929-9},
	url          = {http://portal.acm.org/citation.cfm?doid=1753326.1753383},
	note         = {tex.ids: sheng2010a},
	place        = {Atlanta, Georgia, USA},
	abstractnote = {In this paper we present the results of a roleplay survey instrument administered to 1001 online survey respondents to study both the relationship between demographics and phishing susceptibility and the effectiveness of several antiphishing educational materials. Our results suggest that women are more susceptible than men to phishing and participants between the ages of 18 and 25 are more susceptible to phishing than other age groups. We explain these demographic factors through a mediation analysis. Educational materials reduced users' tendency to enter information into phishing webpages by 40\% percent; however, some of the educational materials we tested also slightly decreased participants' tendency to click on legitimate links.}
}
@article{Shevchenko,
	title        = {Threat Modeling: A Summary of Available Methods},
	author       = {Shevchenko, Nataliya and Chick, Timothy A and O'Riordan, Paige and Scanlon, Thomas Patrick and Woody, Carol},
	pages        = 26
}
@inproceedings{Sheyner_Haines_Jha_Lippmann_Wing_2002,
	title        = {Automated generation and analysis of attack graphs},
	author       = {Sheyner, Oleg and Haines, Joshua and Jha, Somesh and Lippmann, Richard and Wing, Jeannette M.},
	year         = 2002,
	booktitle    = {Proceedings 2002 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {273–284},
	issn         = {1081-6011},
	url          = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1004377},
	note         = {tex.ids: sheyner2002a, sheynerAutomatedGenerationAnalysis2002a}
}
@article{Shiravi_Shiravi_Ghorbani_2012,
	title        = {A survey of visualization systems for network security},
	author       = {Shiravi, H. and Shiravi, A. and Ghorbani, A.A.},
	year         = 2012,
	month        = aug,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 18,
	number       = 8,
	pages        = {1313--1329,},
	note         = {Citation Key: shiravi2012a tex.citation-number: 65}
}
@article{Shostack,
	title        = {Experiences Threat Modeling at Microsoft},
	author       = {Shostack, Adam},
	pages        = 11,
	abstractnote = {Describes a decade of experience threat modeling products and services at Microsoft. Describes the current threat modeling methodology used in the Security Development Lifecycle. The methodology is a practical approach, usable by non-experts, centered on data flow diagrams and a threat enumeration technique of `STRIDE per element.' The paper covers some lessons learned which are likely applicable to other security analysis techniques. The paper closes with some possible questions for academic research.}
}
@article{Singhal_Ou,
	title        = {Security Risk Analysis of Enterprise Networks Using Probabilistic Attack Graphs},
	author       = {Singhal, Anoop and Ou, Ximming},
	pages        = 24,
	note         = {tex.ids: singhal2011a, singhalSecurityRiskAnalysis2017 tex.publisher: National Institute of Standards and Technology}
}
@inbook{Smart_2019,
	title        = {The cyber security body of knowledge},
	author       = {Smart, Nigel},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Cryptography}
}
@article{Smith_1988,
	title        = {Characterizing computer performance with a single number},
	author       = {Smith, James E.},
	year         = 1988,
	journal      = {Communications of the ACM},
	volume       = 31,
	number       = 10,
	pages        = {1202–1206}
}
@article{Snoek_Larochelle_Adams_2012,
	title        = {Practical Bayesian Optimization of Machine Learning Algorithms},
	author       = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	year         = 2012,
	month        = {06},
	journal      = {arXiv:1206.2944 [cs, stat]},
	url          = {http://arxiv.org/abs/1206.2944},
	note         = {arXiv: 1206.2944},
	abstractnote = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a ``black art'' that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.}
}
@article{Snoek_Rippel_Swersky_Kiros_Satish_Sundaram_Patwary_Prabhat_Adams_2015,
	title        = {Scalable Bayesian Optimization Using Deep Neural Networks},
	author       = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
	year         = 2015,
	month        = {02},
	journal      = {arXiv:1502.05700 [stat]},
	url          = {http://arxiv.org/abs/1502.05700},
	note         = {arXiv: 1502.05700},
	abstractnote = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}
@inproceedings{Snow_Monrose_Davi_Dmitrienko_Liebchen_Sadeghi_2013,
	title        = {Just-In-Time Code Reuse: On the Effectiveness of Fine-Grained Address Space Layout Randomization},
	author       = {Snow, Kevin Z. and Monrose, Fabian and Davi, Lucas and Dmitrienko, Alexandra and Liebchen, Christopher and Sadeghi, Ahmad-Reza},
	year         = 2013,
	month        = may,
	booktitle    = {2013 IEEE Symposium on Security and Privacy},
	pages        = {574–588},
	doi          = {10.1109/SP.2013.45},
	issn         = {1081-6011},
	note         = {tex.ids: snow2013a},
	abstractnote = {Fine-grained address space layout randomization (ASLR) has recently been proposed as a method of efficiently mitigating runtime attacks. In this paper, we introduce the design and implementation of a framework based on a novel attack strategy, dubbed just-in-time code reuse, that undermines the benefits of fine-grained ASLR. Specifically, we derail the assumptions embodied in fine-grained ASLR by exploiting the ability to repeatedly abuse a memory disclosure to map an application's memory layout on-the-fly, dynamically discover API functions and gadgets, and JIT-compile a target program using those gadgets – all within a script environment at the time an exploit is launched. We demonstrate the power of our framework by using it in conjunction with a real-world exploit against Internet Explorer, and also provide extensive evaluations that demonstrate the practicality of just-in-time code reuse attacks. Our findings suggest that fine-grained ASLR may not be as promising as first thought.}
}
@article{Solic_Ocevcic_Golub_2015,
	title        = {The information systems' security level assessment model based on an ontology and evidential reasoning approach},
	author       = {Solic, K. and Ocevcic, H. and Golub, M.},
	year         = 2015,
	month        = nov,
	journal      = {Computers \& Security},
	volume       = 55,
	pages        = {100--112,},
	note         = {Citation Key: solic2015a tex.citation-number: 43}
}
@article{Sonmez_2019,
	title        = {A Conceptual Model for a Metric Based Framework for the Monitoring of Information Security Tasks' Efficiency},
	author       = {S\"{o}nmez, Ferda \"{O}zdemir},
	year         = 2019,
	journal      = {Procedia Computer Science},
	volume       = 160,
	pages        = {181–188},
	doi          = {10.1016/j.procs.2019.09.459},
	issn         = 18770509,
	abstractnote = {Abstract Information Security Governance Systems are not adequate to measure the effectiveness and efficiency of security tIansfkosrmfoartitohne SenecteurrpitryiseGso. vAelrtnhaonucgehSsyosmteemosf athre nsyostteamdesqoufafteertwo amyseafsourrme tehaesuerfefmecetnivt,entheesys satnildl nefefeidciethnecydeoffinsieticounriotyf mtasekasufroermtheentenotbejrepcrtiisveess. Aanltdhomugehtriscosm. Tehoifs thsteusdyystpermops oosfefserawcaoynscfeoprtumaelafsruarmemewenotr,kthmeyodsetillwnheiecdh thaesdhefuimniatinonanodf tmooeal/spurroecmesesntreolabtjedctimvestriacns.d Tmhiestrsicyss.teTmhiaslssotuadlylowprsopthoesecsolaleccotinocnepotfuaelvifdreanmceewdoartka mfoor dseecwurhitiych-rehlastedhutmasakns and twoaoyl/sprtocmesostirvealatetetdhemseetcriucrsi.tyTshtiasffsytostepmrovaildsoe allmoworse tphreodcuolclteivcteioennvoifroenvmideenntc.eTdhaistasyfosrtesmecmuraityyb-reelaptepdlietadsktos aannyd swizaeysoftoenmteortpivriaste itnhdeespeecnudreitnyt sotfaiftfstboupsrinoevsidsedoammaoinreoprrfoudnucctitoivnes eansvliornognmasentht.eTahimis issytsoteimmpmroavyebteheapepfflieecdtivtoenaensys asinzde eofffiecnietenrcpyriosfe siencduerpiteyn-drenlatteodf ittasskbsu.siness domain or functions as long as the aim is to improve the effectiveness and efficiency of security-related tasks.}
}
@misc{soss_v9,
	title        = {STATE OF SOFTWARE SECURITY},
	url          = {https://www.veracode.com/sites/default/files/pdf/resources/ipapers/state-of-software-security-volume-9/}
}
@inproceedings{Spring_Moore_Pym_2017,
	title        = {Practicing a Science of Security: A Philosophy of Science Perspective},
	author       = {Spring, Jonathan M. and Moore, Tyler and Pym, David},
	year         = 2017,
	booktitle    = {Proceedings of the 2017 New Security Paradigms Workshop on ZZZ - NSPW 2017},
	publisher    = {ACM Press},
	pages        = {1–18},
	doi          = {10.1145/3171533.3171540},
	isbn         = {978-1-4503-6384-6},
	url          = {http://dl.acm.org/citation.cfm?doid=3171533.3171540},
	place        = {Santa Cruz, CA, USA},
	abstractnote = {Our goal is to refocus the question about cybersecurity research from `is this process scienti c' to `why is this scienti c process producing unsatisfactory results'. We focus on ve common complaints that claim cybersecurity is not or cannot be scienti c. Many of these complaints presume views associated with the philosophical school known as Logical Empiricism that more recent scholarship has largely modi ed or rejected. Modern philosophy of science, supported by mathematical modeling methods, provides constructive resources to mitigate all purported challenges to a science of security. Therefore, we argue the community currently practices a science of cybersecurity. A philosophy of science perspective suggests the following form of practice: structured observation to seek intelligible explanations of phenomena, evaluating explanations in many ways, with specialized elds (including engineering and forensics) constraining explanations within their own expertise, intertranslating where necessary. A natural question to pursue in future work is how collecting, evaluating, and analyzing evidence for such explanations is di erent in security than other sciences.}
}
@inbook{Srivatanakul_Clark_Polack_2004,
	title        = {Effective Security Requirements Analysis: HAZOP and Use Cases},
	author       = {Srivatanakul, Thitima and Clark, John A. and Polack, Fiona},
	year         = 2004,
	booktitle    = {Information Security},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 3225,
	pages        = {416–427},
	doi          = {10.1007/978-3-540-30144-8\_35},
	isbn         = {978-3-540-23208-7},
	url          = {http://link.springer.com/10.1007/978-3-540-30144-8\_35},
	place        = {Berlin, Heidelberg},
	abstractnote = {Use cases are widely used for functional requirements elicitation. However, security non-functional requirements are often neglected in this requirements analysis process. As systems become increasingly complex current means of analysis will probably prove ineffective. In the safety domain a variety of effective analysis techniques have emerged over many years. Since the safety and security domains share many similarities, various authors have suggested that safety techniques might usefully find application in security. This paper takes one such technique, HAZOP, and applies it to one widely used functional requirement elicitation component, UML use cases, in order to provide systematic analysis of potential security issues at the start of system development.},
	editor       = {Zhang, Kan and Zheng, YuliangEditors}
}
@misc{SSI,
	title        = {Single Metric for HPC (NERSC)},
	url          = {https://www.nersc.gov/research-and-development/benchmarking-and-workload-characterization/ssi/}
}
@article{Stakhanova_Strasburg_Basu_Wong_2012,
	title        = {Towards cost-sensitive assessment of intrusion response selection},
	author       = {Stakhanova, Natalia and Strasburg, Chris and Basu, Samik and Wong, Johnny S.},
	year         = 2012,
	month        = jun,
	journal      = {Journal of Computer Security},
	volume       = 20,
	number       = {2–3},
	pages        = {169–198},
	doi          = {10.3233/JCS-2011-0436},
	issn         = {18758924, 0926227X},
	note         = {tex.ids: stakhanova2012a},
	abstractnote = {In recent years, cost-sensitive intrusion response has gained significant interest mainly due to its emphasis on the balance between potential damage incurred by the intrusion and cost of the response. However, one of the challenges in applying this approach is defining consistent and adaptable measurements of these cost factors on the basis of requirements and policy of the system being protected against intrusions.}
}
@article{Stan_Bitton_Ezrets_Dadon_Inokuchi_Ohta_Yamada_Yagyu_Elovici_Shabtai_2019,
	title        = {Extending Attack Graphs to Represent Cyber-Attacks in Communication Protocols and Modern IT Networks},
	author       = {Stan, Orly and Bitton, Ron and Ezrets, Michal and Dadon, Moran and Inokuchi, Masaki and Ohta, Yoshinobu and Yamada, Yoshiyuki and Yagyu, Tomohiko and Elovici, Yuval and Shabtai, Asaf},
	year         = 2019,
	month        = 6,
	journal      = {arXiv:1906.09786 [cs]},
	url          = {http://arxiv.org/abs/1906.09786},
	note         = {arXiv: 1906.09786},
	abstractnote = {An attack graph is a method used to enumerate the possible paths that an attacker can execute in the organization network. MulVAL is a known open-source framework used to automatically generate attack graphs. MulVAL's default modeling has two main shortcomings. First, it lacks the representation of network protocol vulnerabilities, and thus it cannot be used to model common network attacks such as ARP poisoning, DNS spoofing, and SYN flooding. Second, it does not support advanced types of communication such as wireless and bus communication, and thus it cannot be used to model cyber-attacks on networks that include IoT devices or industrial components. In this paper, we present an extended network security model for MulVAL that: (1) considers the physical network topology, (2) supports short-range communication protocols (e.g., Bluetooth), (3) models vulnerabilities in the design of network protocols, and (4) models specific industrial communication architectures. Using the proposed extensions, we were able to model multiple attack techniques including: spoofing, man-in-the-middle, and denial of service, as well as attacks on advanced types of communication. We demonstrate the proposed model on a testbed implementing a simplified network architecture comprised of both IT and industrial components.}
}
@article{Stevens_1946,
	title        = {On the Theory of Scales of Measurement},
	author       = {Stevens, S. S.},
	year         = 1946,
	journal      = {Science, New Series},
	volume       = 103,
	number       = 2684,
	pages        = {677–680},
	note         = {tex.ids: stevens1946a}
}
@article{Stolfo_Bellovin_Evans_2011,
	title        = {Measuring security},
	author       = {Stolfo, S. and Bellovin, S.M. and Evans, D.},
	year         = 2011,
	month        = may,
	journal      = {IEEE Security and Privacy},
	volume       = 9,
	number       = 3,
	pages        = {60--65,},
	note         = {Citation Key: stolfo2011a tex.citation-number: 12}
}
@inproceedings{stolfo2000a,
	title        = {Cost-based modeling for fraud and intrusion detection: results from the JAM project},
	author       = {Stolfo, S.J. and Wei Fan and Wenke Lee and Prodromidis, A. and Chan, P.K.},
	year         = 1999,
	booktitle    = {Proceedings DARPA Information Survivability Conference and Exposition. DISCEX'00},
	publisher    = {IEEE Comput. Soc},
	volume       = 2,
	pages        = {130–144},
	doi          = {10.1109/DISCEX.2000.821515},
	isbn         = {978-0-7695-0490-2},
	url          = {http://ieeexplore.ieee.org/document/821515/},
	note         = {tex.ids: stolfo2000a},
	place        = {Hilton Head, SC, USA}
}
@inproceedings{Stone-Gross_Kruegel_Almeroth_Moser_Kirda_2009,
	title        = {FIRE: FInding Rogue nEtworks},
	author       = {Stone-Gross, Brett and Kruegel, Christopher and Almeroth, Kevin and Moser, Andreas and Kirda, Engin},
	year         = 2009,
	month        = dec,
	booktitle    = {2009 Annual Computer Security Applications Conference},
	publisher    = {IEEE},
	pages        = {231–240},
	doi          = {10.1109/ACSAC.2009.29},
	isbn         = {978-1-4244-5327-6},
	url          = {http://ieeexplore.ieee.org/document/5380682/},
	note         = {tex.ids: stone-gross2009a},
	place        = {Honolulu, Hawaii, USA},
	abstractnote = {For many years, online criminals have been able to conduct their illicit activities by masquerading behind disreputable Internet Service Providers (ISPs). For example, organizations such as the Russian Business Network (RBN), Atrivo (a.k.a., Intercage), McColo, and most recently, the Triple Fiber Network (3FN) operated with impunity, providing a safe haven for Internet criminals for their own financial gain. What primarily sets these ISPs apart from others is the significant longevity of the malicious activities on their networks and the apparent lack of action taken in response to abuse reports. Interestingly, even though the Internet provides a certain degree of anonymity, such ISPs fear public attention. Once exposed, rogue networks often cease their malicious activities quickly, or are de-peered (disconnected) by their upstream providers. As a result, the Internet criminals are forced to relocate their operations.}
}
@inproceedings{Strasburg_Stakhanova_Basu_Wong_2009,
	title        = {A Framework for Cost Sensitive Assessment of Intrusion Response Selection},
	author       = {Strasburg, Chris and Stakhanova, Natalia and Basu, Samik and Wong, Johnny S.},
	year         = 2009,
	booktitle    = {2009 33rd Annual IEEE International Computer Software and Applications Conference},
	publisher    = {IEEE},
	pages        = {355–360},
	doi          = {10.1109/COMPSAC.2009.54},
	isbn         = {978-0-7695-3726-9},
	url          = {http://ieeexplore.ieee.org/document/5254241/},
	note         = {tex.ids: strasburg2009a},
	place        = {Seattle, Washington, USA},
	abstractnote = {In recent years, cost-sensitive intrusion response has gained significant interest, mainly due to its emphasis on the balance between potential damage incurred by the intrusion and cost of the response. However, one of the challenges in applying this approach is defining a consistent and adaptable measurement of these cost factors on the basis of system requirements and policy. In this paper, we present a host-based framework for the cost-sensitive assessment and selection of intrusion response. Specifically, we introduce a set of measurements that characterize the potential costs associated with the intrusion handling process, and propose an intrusion response evaluation method with respect to the risk of potential intrusion damage, the effectiveness of the response action and the response cost for a system. We provide an implementation of the proposed solution as an IDS-independent plugin tool and demonstrate its advantages on the several attack examples.}
}
@inbook{Stringhini_2019,
	title        = {The cyber security body of knowledge},
	author       = {Stringhini, Gianluca},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Adversarial Behaviours}
}
@article{Sullivan,
	title        = {Chapter 9: Dataflow Diagrams},
	author       = {Sullivan, Louis Henri},
	pages        = 50
}
@inbook{Suri_2019,
	title        = {The cyber security body of knowledge},
	author       = {Suri, Neeraj},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Distributed Systems Security}
}
@book{Sutton_Barto_2018,
	title        = {Reinforcement learning: an introduction},
	author       = {Sutton, Richard S. and Barto, Andrew G.},
	year         = 2018,
	publisher    = {The MIT Press},
	series       = {Adaptive computation and machine learning series},
	isbn         = {978-0-262-03924-6},
	place        = {Cambridge, Massachusetts},
	edition      = {Second edition},
	abstractnote = {``Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms.''--},
	collection   = {Adaptive computation and machine learning series}
}
@book{Swanson_Bartol_Sabato_Hash_Graffo_2003,
	title        = {Security metrics guide for information technology systems},
	author       = {Swanson, M and Bartol, N and Sabato, J and Hash, J and Graffo, L},
	year         = 2003,
	number       = {NIST SP 800-55},
	pages        = {NIST SP 800--55},
	doi          = {10.6028/NIST.SP.800-55},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-55.pdf},
	place        = {Gaithersburg, MD},
	institution  = {National Institute of Standards and Technology}
}
@inproceedings{Tang_Mhamdi_McLernon_Zaidi_Ghogho_2016,
	title        = {Deep learning approach for Network Intrusion Detection in Software Defined Networking},
	author       = {Tang, Tuan A and Mhamdi, Lotfi and McLernon, Des and Zaidi, Syed Ali Raza and Ghogho, Mounir},
	year         = 2016,
	month        = oct,
	booktitle    = {2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)},
	publisher    = {IEEE},
	pages        = {258–263},
	doi          = {10.1109/WINCOM.2016.7777224},
	isbn         = {978-1-5090-3837-4},
	url          = {http://ieeexplore.ieee.org/document/7777224/},
	place        = {Fez, Morocco},
	abstractnote = {Software Defined Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for flow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSLKDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the fortyone features of NSL-KDD Dataset. Through experiments, we confirm that the deep learning approach shows strong potential to be used for flow-based anomaly detection in SDN environments.}
}
@inproceedings{Tang_Sethumadhavan_Stolfo_2015,
	title        = {Heisenbyte: Thwarting Memory Disclosure Attacks using Destructive Code Reads},
	author       = {Tang, Adrian and Sethumadhavan, Simha and Stolfo, Salvatore},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {256–267},
	doi          = {10.1145/2810103.2813685},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813685},
	note         = {tex.ids: tang2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Vulnerabilities that disclose executable memory pages enable a new class of powerful code reuse attacks that build the attack payload at runtime. In this work, we present Heisenbyte, a system to protect against memory disclosure attacks. Central to Heisenbyte is the concept of destructive code reads – code is garbled right after it is read. Garbling the code after reading it takes away from the attacker her ability to leverage memory disclosure bugs in both static code and dynamically generated just-in-time code. By leveraging existing virtualization support, Heisenbyte's novel use of destructive code reads sidesteps the problem of incomplete binary disassembly in binaries, and extends protection to close-sourced COTS binaries, which are two major limitations of prior solutions against memory disclosure vulnerabilities. Our experiments demonstrate that Heisenbyte can tolerate some degree of imperfect static analysis in disassembled binaries, while effectively thwarting dynamic code reuse exploits in both static and JIT code, at a modest 1.8\% average runtime overhead due to virtualization and 16.5\% average overhead due to the destructive code reads.}
}
@inproceedings{tang2015line,
	title        = {Line: Large-scale information network embedding},
	author       = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
	year         = 2015,
	booktitle    = {Proceedings of WWW},
	pages        = {1067--1077}
}
@article{Tariq_2012,
	title        = {Towards information security metrics framework for cloud computing},
	author       = {Tariq, Muhammad Imran},
	year         = 2012,
	journal      = {International Journal of Cloud Computing and Services Science},
	volume       = 1,
	number       = 4,
	pages        = 209
}
@article{Tavallaee_Stakhanova_Ghorbani_2010,
	title        = {Toward Credible Evaluation of Anomaly-Based Intrusion-Detection Methods},
	author       = {Tavallaee, Mahbod and Stakhanova, Natalia and Ghorbani, Ali Akbar},
	year         = 2010,
	month        = {09},
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume       = 40,
	number       = 5,
	pages        = {516–524},
	doi          = {10.1109/TSMCC.2010.2048428},
	issn         = {1094-6977, 1558-2442},
	note         = {tex.ids: tavallaee2010a},
	abstractnote = {Since the first introduction of anomaly-based intrusion detection to the research community in 1987, the field has grown tremendously. A variety of methods and techniques introducing new capabilities in detecting novel attacks were developed. Most of these techniques report a high detection rate of 98\% at the low false alarm rate of 1\%. In spite of the anomaly-based approach's appeal, the industry generally favors signature-based detection for mainstream implementation of intrusion-detection systems. While a variety of anomaly-detection techniques have been proposed, adequate comparison of these methods' strengths and limitations that can lead to potential commercial application is difficult. Since the validity of experimental research in academic computer science, in general, is questionable, it is plausible to assume that research in anomaly detection shares the above problem. The concerns about the validity of these methods may partially explain why anomaly-based intrusion-detection methods are not adopted by industry. To investigate this issue, we review the current state of the experimental practice in the area of anomaly-based intrusion detection and survey 276 studies in this area published during the period of 2000–2008. We summarize our observations and identify the common pitfalls among surveyed works.}
}
@article{Thakore,
	title        = {A QUANTITATIVE METHODOLOGY FOR EVALUATING AND DEPLOYING SECURITY MONITORS},
	author       = {Thakore, Uttam},
	pages        = 87,
	note         = {tex.ids: thakore2015a, thakoreQUANTITATIVEMETHODOLOGYEVALUATINGa}
}
@article{Trcek_2010,
	title        = {Security metrics foundations for computer security},
	author       = {Tr\v{c}ek, Denis},
	year         = 2010,
	journal      = {The Computer Journal},
	publisher    = {Oxford University Press},
	volume       = 53,
	number       = 7,
	pages        = {1106–1112}
}
@inbook{Troncoso_2019,
	title        = {The cyber security body of knowledge},
	author       = {Troncoso, Carmela},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Privacy \& Online Rights}
}
@article{tu2017network,
	title        = {Network representation learning: an overview},
	author       = {TU, Cunchao and YANG, Cheng and LIU, Zhiyuan and SUN, Maosong},
	year         = 2017,
	journal      = {SCIENTIA SINICA Informationis},
	volume       = 47,
	number       = 8,
	pages        = {980--996}
}
@inproceedings{Tupper_Zincir-Heywood_2008,
	title        = {VEA-bility Security Metric: A Network Security Analysis Tool},
	author       = {Tupper, Melanie and Zincir-Heywood, A. Nur},
	year         = 2008,
	month        = mar,
	booktitle    = {2008 Third International Conference on Availability, Reliability and Security},
	publisher    = {IEEE},
	pages        = {950–957},
	doi          = {10.1109/ARES.2008.138},
	isbn         = {978-0-7695-3102-1},
	url          = {http://ieeexplore.ieee.org/document/4529446/},
	note         = {tex.ids: tupper2008a, tupperVEAbilitySecurityMetric2008a tex.citation-number: 31},
	abstractnote = {In this work, we propose a novel quantitative security metric, VEA-bility, which measures the desirability of different network configurations. An administrator can then use the VEA-bility scores of different configurations to configure a secure network. Based on our findings, we conclude that the VEAbility can be used to accurately estimate the comparative desirability of a specific network configuration. This information can then be used to explore alternate possible configurations and allows an administrator to select one among the given options. These tools are important to network administrators as they strive to provide secure, yet functional, network configurations.}
}
@inproceedings{Ugarte-Pedrero_Balzarotti_Santos_Bringas_2015,
	title        = {SoK: Deep Packer Inspection: A Longitudinal Study of the Complexity of Run-Time Packers},
	author       = {Ugarte-Pedrero, Xabier and Balzarotti, Davide and Santos, Igor and Bringas, Pablo G.},
	year         = 2015,
	month        = may,
	booktitle    = {2015 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {659–673},
	doi          = {10.1109/SP.2015.46},
	isbn         = {978-1-4673-6949-7},
	issn         = {2375-1207},
	url          = {https://ieeexplore.ieee.org/document/7163053/},
	note         = {tex.ids: ugarte-pedrero2015a, ugarte-pedreroSoKDeepPacker2015a, ugarte-pedreroSoKDeepPacker2015b},
	place        = {San Jose, CA},
	abstractnote = {Run-time packers are often used by malware-writers to obfuscate their code and hinder static analysis. The packer problem has been widely studied, and several solutions have been proposed in order to generically unpack protected binaries. Nevertheless, these solutions commonly rely on a number of assumptions that may not necessarily reflect the reality of the packers used in the wild. Moreover, previous solutions fail to provide useful information about the structure of the packer or its complexity. In this paper, we describe a framework for packer analysis and we propose a taxonomy to measure the runtime complexity of packers.}
}
@article{unknown2011a,
	year         = 2011,
	journal      = {National Science and Technology Council},
	url          = {https://www.nitrd.gov/SUBCOMMITTEE/csia/Fed\_Cybersecurity\_RD\_Strategic\_Plan\_2011.pdf.},
	note         = {Citation Key: unknown2011a}
}
@article{Ur_Segreti_Bauer_Christin_Cranor_Komanduri_Kurilova_Mazurek_Melicher_Shay,
	title        = {Measuring Real-World Accuracies and Biases in Modeling Password Guessability},
	author       = {Ur, Blase and Segreti, Sean M and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Komanduri, Saranga and Kurilova, Darya and Mazurek, Michelle L and Melicher, William and Shay, Richard},
	pages        = 19,
	note         = {tex.ids: ur2015a, urMeasuringRealWorldAccuraciesa},
	abstractnote = {Parameterized password guessability--how many guesses a particular cracking algorithm with particular training data would take to guess a password--has become a common metric of password security. Unlike statistical metrics, it aims to model real-world attackers and to provide per-password strength estimates. We investigate how cracking approaches often used by researchers compare to real-world cracking by professionals, as well as how the choice of approach biases research conclusions.}
}
@article{ur2012a,
	title        = {How Does Your Password Measure Up? The Effect of Strength Meters on Password Creation},
	author       = {Ur, Blase and Kelley, Patrick Gage and Komanduri, Saranga and Lee, Joel and Maass, Michael and Mazurek, Michelle L and Passaro, Timothy and Shay, Richard and Vidas, Timothy and Bauer, Lujo and et al.},
	pages        = 16,
	note         = {tex.ids: ur2012a},
	abstractnote = {To help users create stronger text-based passwords, many web sites have deployed password meters that provide visual feedback on password strength. Although these meters are in wide use, their effects on the security and usability of passwords have not been well studied.}
}
@inproceedings{Vaughn_Henning_Siraj_2003,
	title        = {Information assurance measures and metrics - state of practice and proposed taxonomy},
	author       = {Vaughn, R.B. and Henning, R. and Siraj, A.},
	year         = 2003,
	booktitle    = {36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the},
	publisher    = {IEEE},
	pages        = {10 pp.},
	doi          = {10.1109/HICSS.2003.1174904},
	isbn         = {978-0-7695-1874-9},
	url          = {http://ieeexplore.ieee.org/document/1174904/},
	note         = {tex.ids: vaughn2003a tex.citation-number: 14},
	place        = {Big Island, HI, USA},
	abstractnote = {The term `` assurance'' has been used for decades in trusted system development as an expression of confidence that one has in the strength of mechanisms or countermeasures. One of the unsolved problems of security engineering is the adoption of measures or metrics that can reliably depict the assurance associated with a specific hardware and software system. This paper reports on a recent attempt to focus requirements in this area by examining those currently in use. It then suggests a categorization of Information Assurance (IA) metrics that may be tailored to an organization's needs1. We believe that the provision of security mechanisms in systems is a subset of the systems engineering discipline having a large software-engineering correlation. There is general agreement that no single system metric or any ``one-prefect'' set of IA metrics applies across all systems or audiences. The set most useful for an organization largely depends on their IA goals, their technical, organizational and operational needs, and the financial, personnel, and technical resources that are available.}
}
@article{Vellaithurai_Srivastava_Zonouz_Berthier_2015,
	title        = {Cpin- dex: Cyber-physical vulnerability assessment for power-grid infrastruc- tures},
	author       = {Vellaithurai, C. and Srivastava, A. and Zonouz, S. and Berthier, R.},
	year         = 2015,
	month        = mar,
	journal      = {IEEE Transactions on Smart Grid},
	volume       = 6,
	number       = 2,
	pages        = {566--575,},
	note         = {Citation Key: vellaithurai2015a tex.citation-number: 119}
}
@article{Velleman_Wilkinson,
	title        = {Nominal, Ordinal, Interval, and Ratio Typologies are Misleading},
	author       = {Velleman, Paul and Wilkinson, Leland},
	pages        = 19,
	note         = {tex.ids: velleman1993a}
}
@inbook{Verbauwhede_2019,
	title        = {The cyber security body of knowledge},
	author       = {Verbauwhede, Ingrid},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Hardware Security}
}
@inproceedings{Verendel_2009,
	title        = {Quantified security is a weak hypothesis: a critical survey of results and assumptions},
	author       = {Verendel, Vilhelm},
	year         = 2009,
	booktitle    = {Proceedings of the 2009 workshop on New security paradigms workshop - NSPW '09},
	publisher    = {ACM Press},
	pages        = 37,
	doi          = {10.1145/1719030.1719036},
	isbn         = {978-1-60558-845-2},
	url          = {http://portal.acm.org/citation.cfm?doid=1719030.1719036},
	note         = {tex.ids: verendel2009a, verendelQuantifiedSecurityWeak2009a, verendelQuantifiedSecurityWeak2009b tex.citation-number: 16},
	place        = {Oxford, United Kingdom},
	abstractnote = {This paper critically surveys previous work on quantitative representation and analysis of security. Such quantified security has been presented as a general approach to precisely assess and control security. We classify a significant part of the work between 1981 and 2008 with respect to security perspective, target of quantification, underlying assumptions and type of validation. The result shows how the validity of most methods is still strikingly unclear. Despite applying a number of techniques from fields such as computer science, economics and reliability theory to the problem it is unclear what valid results exist with respect to operational security. Quantified security is thus a weak hypothesis because a lack of validation and comparison between such methods against empirical data. Furthermore, many assumptions in formal treatments are not empirically well-supported in operational security and have been adopted from other fields. A number of risks are present with depending on quantitative methods with limited or no validation.}
}
@article{Vigna_Kemmerer_1999,
	title        = {Netstat: A network-based intrusion detection system},
	author       = {Vigna, G. and Kemmerer, R.A.},
	year         = 1999,
	month        = jan,
	journal      = {J. Comput. Secur},
	volume       = 7,
	number       = 1,
	pages        = {37--71,},
	note         = {Citation Key: vigna1999a tex.citation-number: 86}
}
@article{Villarrubia_Fernandez-Medina_Piattini_2006,
	title        = {Metrics of Password Management Policy},
	author       = {Villarrubia, Carlos and Fern\'{a}ndez-Medina, Eduardo and Piattini, Mario},
	year         = 2006,
	journal      = {Computational Science and Its Applications-ICCSA 2006},
	publisher    = {Springer},
	pages        = {1013–1023}
}
@inproceedings{villarrubia_mario_2004,
	title        = {Towards a classification of security metrics},
	author       = {C. Villarrubia, E. Fern\'{a}ndez-Medina and Mario, P.},
	year         = 2004,
	booktitle    = {Proceedings of the 2nd international workshop on security in information systems (WOSIS 2004). In con- junction with ICEIS},
	pages        = {342–350},
	note         = {Citation Key: c2004a tex.citation-number: 18},
	place        = {Porto, Portugal}
}
@inbook{Villarrubia_Medina_Piattini_2004,
	title        = {Towards a classification of security metrics},
	author       = {Villarrubia, Carlos and Medina, Eduardo F. and Piattini, Mario},
	year         = 2004,
	booktitle    = {WOSIS},
	pages        = {342--350,},
	note         = {Citation Key: villarrubia2004a}
}
@book{Wagner_Eckhoff_2015,
	title        = {Technical privacy metrics: A systematic survey},
	author       = {Wagner, I. and Eckhoff, D.},
	year         = 2015,
	month        = {06},
	journal      = {ACM Computing Surveys},
	volume       = 51,
	number       = 3,
	pages        = {1–38},
	doi          = {10.1145/3168389},
	issn         = {03600300},
	note         = {Citation Key: wagner2015a tex.arxiv: 1512.00327}
}
@article{Wald_1980,
	title        = {A method of estimating plane vulnerability based on damage of survivors, CRC 432, July 1980},
	author       = {Wald, A.},
	year         = 1980,
	journal      = {Center for Naval Analyses}
}
@inproceedings{Wang_Islam_Long_Singhal_Jajodia_2008,
	title        = {An attack graph-based probabilistic security metric},
	author       = {Wang, Lingyu and Islam, Tania and Long, Tao and Singhal, Anoop and Jajodia, Sushil},
	year         = 2008,
	booktitle    = {IFIP Annual Conference on Data and Applications Security and Privacy},
	publisher    = {Springer},
	pages        = {283–296},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-70567-3\_22},
	note         = {tex.ids: wang2008a, wangAttackGraphbasedProbabilistic2008a tex.citation-number: 88}
}
@book{Wang_Jajodia_Singhal_2017,
	title        = {Network Security Metrics},
	author       = {Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop},
	year         = 2017,
	publisher    = {Springer International Publishing},
	doi          = {10.1007/978-3-319-66505-4},
	isbn         = {978-3-319-66504-7},
	url          = {http://link.springer.com/10.1007/978-3-319-66505-4},
	place        = {Cham}
}
@article{Wang_Jajodia_Singhal_Cheng_Noel_2014,
	title        = {k-Zero Day Safety: A Network Security Metric for Measuring the Risk of Unknown Vulnerabilities},
	author       = {Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop and Cheng, Pengsu and Noel, Steven},
	year         = 2014,
	month        = jan,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 11,
	number       = 1,
	pages        = {30–44},
	doi          = {10.1109/TDSC.2013.24},
	issn         = {1545-5971},
	note         = {tex.ids: wang2014a, wangKzeroDaySafety2013 tex.citation-number: 113 publisher: IEEE},
	abstractnote = {By enabling a direct comparison of different security solutions with respect to their relative effectiveness, a network security metric may provide quantiſable evidences to assist security practitioners in securing computer networks. However, research on security metrics has been hindered by difſculties in handling zero day attacks exploiting unknown vulnerabilities. In fact, the security risk of unknown vulnerabilities has been considered as something unmeasurable due to the less predictable nature of software ƀaws. This causes a major difſculty to security metrics, because a more secure conſguration would be of little value if it were equally susceptible to zero day attacks. In this paper, we propose a novel security metric, k-zero day safety, to address this issue. Instead of attempting to rank unknown vulnerabilities, our metric counts how many such vulnerabilities would be required for compromising network assets; a larger count implies more security since the likelihood of having more unknown vulnerabilities available, applicable, and exploitable all at the same time will be signiſcantly lower. We formally deſne the metric, analyze the complexity of computing the metric, devise heuristic algorithms for intractable cases, and ſnally demonstrate through case studies that applying the metric to existing network security practices may generate actionable knowledge.}
}
@inbook{Wang_Jajodia_Singhal_Noel_2010,
	title        = {k-Zero Day Safety: Measuring the Security Risk of Networks against Unknown Attacks},
	author       = {Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop and Noel, Steven},
	year         = 2010,
	booktitle    = {Computer Security – ESORICS 2010},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 6345,
	pages        = {573–587},
	doi          = {10.1007/978-3-642-15497-3\_35},
	isbn         = {978-3-642-15496-6},
	url          = {http://link.springer.com/10.1007/978-3-642-15497-3\_35},
	note         = {tex.ids: wang2010a},
	place        = {Berlin, Heidelberg},
	abstractnote = {The security risk of a network against unknown zero day attacks has been considered as something unmeasurable since software flaws are less predictable than hardware faults and the process of finding such flaws and developing exploits seems to be chaotic [24]. In this paper, we propose a novel security metric, k-zero day safety, based on the number of unknown zero day vulnerabilities. That is, the metric counts at least how many unknown vulnerabilities are required for compromising a network asset, regardless of what vulnerabilities those are. We formally define the metric based on a model of relevant network components. We then devise algorithms for computing the metric. Finally, we discuss how to apply the metric for hardening a network.},
	editor       = {Gritzalis, Dimitris and Preneel, Bart and Theoharidou, Marianthi}
}
@inbook{Wang_Jou_Gong_Sargor_Goseva-Popstojanova_Trivedi_2003,
	title        = {Sitar: a scalable intrusion-tolerant architecture for dis- tributed services},
	author       = {Wang, F. and Jou, F. and Gong, F. and Sargor, C. and Goseva-Popstojanova, K. and Trivedi, K.},
	year         = 2003,
	booktitle    = {Foundations of intrusion tolerant systems, 2003 [Organically assured and survivable information systems},
	pages        = {359–367},
	note         = {Citation Key: wang2003a tex.citation-number: 133}
}
@inproceedings{Wang_Singhal_Jajodia_2007a,
	title        = {Measuring the overall security of network configurations using attack graphs},
	author       = {Wang, Lingyu and Singhal, Anoop and Jajodia, Sushil},
	year         = 2007,
	booktitle    = {IFIP Annual Conference on Data and Applications Security and Privacy},
	publisher    = {Springer},
	pages        = {98–112},
	note         = {tex.ids: wang2007a tex.citation-number: 100}
}
@inproceedings{Wang_Singhal_Jajodia_2007b,
	title        = {Toward Measuring Network Security Using Attack Graphs},
	author       = {Wang, Lingyu and Singhal, Anoop and Jajodia, Sushil},
	year         = 2007,
	note         = {tex.ids: wang2007a, wang2007b tex.citation-number: 101}
}
@inproceedings{Wang_Zhang_Jajodia_Singhal_Albanese_2014,
	title        = {Mod- eling network diversity for evaluating the robustness of networks against zero-day attacks},
	author       = {Wang, L. and Zhang, M. and Jajodia, S. and Singhal, A. and Albanese, M.},
	year         = 2014,
	booktitle    = {Proceedings of the 19th european symposium on research in computer security},
	publisher    = {Springer International Publishing},
	pages        = {494–511},
	note         = {Citation Key: wang2014b tex.citation-number: 116},
	place        = {Wroclaw, Poland}
}
@inproceedings{wang2016structural,
	title        = {Structural deep network embedding},
	author       = {Wang, Daixin and Cui, Peng and Zhu, Wenwu},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages        = {1225--1234},
	organization = {ACM}
}
@inproceedings{Wei_Frinke_Carter_Ritter_2001,
	title        = {Cost-benefit analysis for network intrusion detection systems},
	author       = {Wei, H. and Frinke, D. and Carter, O. and Ritter, C.},
	year         = 2001,
	booktitle    = {Proceedings of the 28th annual computer security conference},
	publisher    = {D.C.Google Scholar},
	note         = {Citation Key: wei2001a},
	place        = {Washington}
}
@inproceedings{Weir_Aggarwal_Collins_Stern_2010,
	title        = {Testing metrics for password creation policies by attacking large sets of revealed passwords},
	author       = {Weir, Matt and Aggarwal, Sudhir and Collins, Michael and Stern, Henry},
	year         = 2010,
	booktitle    = {Proceedings of the 17th ACM conference on Computer and communications security - CCS '10},
	publisher    = {ACM Press},
	pages        = 162,
	doi          = {10.1145/1866307.1866327},
	isbn         = {978-1-4503-0245-6},
	url          = {http://portal.acm.org/citation.cfm?doid=1866307.1866327},
	note         = {tex.ids: weir2010a, weirTestingMetricsPassword2010a},
	place        = {Chicago, Illinois, USA},
	abstractnote = {In this paper we attempt to determine the effectiveness of using entropy, as defined in NIST SP800-63, as a measurement of the security provided by various password creation policies. This is accomplished by modeling the success rate of current password cracking techniques against real user passwords. These data sets were collected from several different websites, the largest one containing over 32 million passwords. This focus on actual attack methodologies and real user passwords quite possibly makes this one of the largest studies on password security to date. In addition we examine what these results mean for standard password creation policies, such as minimum password length, and character set requirements.}
}
@inproceedings{Weiss_1991,
	title        = {A system security engineering process},
	author       = {Weiss, Jonathan D.},
	year         = 1991,
	booktitle    = {Proceedings of the 14th National Computer Security Conference},
	volume       = 249,
	pages        = {572–581}
}
@inproceedings{Whaiduzzaman_Gani_2014,
	title        = {Measuring security for cloud service provider: A third party approach},
	author       = {Whaiduzzaman, M. and Gani, A.},
	year         = 2014,
	month        = feb,
	booktitle    = {Electrical information and communication technology (EICT), 2013 international conference on},
	pages        = {1–6},
	note         = {Citation Key: whaiduzzaman2014a tex.citation-number: 36}
}
@inbook{Williams_2019,
	title        = {The cyber security body of knowledge},
	author       = {Williams, Laurie},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Secure Software Lifecycle}
}
@book{Woodard_Veitch_Thomas_Duggan_2007,
	title        = {Categorizing threat: building and using a generic threat matrix.},
	author       = {Woodard, Laura and Veitch, Cynthia K. and Thomas, Sherry Reede and Duggan, David Patrick},
	year         = 2007,
	month        = {09},
	number       = {SAND2007-5791, 921121},
	pages        = {SAND2007--5791, 921121},
	doi          = {10.2172/921121},
	url          = {http://www.osti.gov/servlets/purl/921121-o2fi48/}
}
@article{Wynn_Whitmore_Upton_Spriggs_McKinnon_McInnes_Graubart_Clausen,
	title        = {Methodology Description Version 1.0},
	author       = {Wynn, Jackson and Whitmore, Joseph and Upton, Geoff and Spriggs, Lindsay and McKinnon, Dan and McInnes, Richard and Graubart, Richard and Clausen, Lauren},
	pages        = 60
}
@inproceedings{Xie_Li_Ou_Liu_Levy_2010,
	title        = {Using bayesian networks for cyber security analysis},
	author       = {Xie, P. and Li, J.H. and Ou, X. and Liu, P. and Levy, R.},
	year         = 2010,
	month        = jun,
	booktitle    = {Dependable systems and networks (DSN), 2010 IEEE/IFIP international conference on},
	pages        = {211–220},
	note         = {Citation Key: xie2010a tex.citation-number: 108}
}
@inproceedings{Xie_Wen_Zhang_Hu_Chen_2009,
	title        = {Applying attack graphs to network security metric},
	author       = {Xie, A. and Wen, W. and Zhang, L. and Hu, J. and Chen, Z.},
	year         = 2009,
	booktitle    = {2009 international conference on multimedia information networking and security},
	publisher    = {IEEE},
	volume       = 1,
	pages        = {427–431},
	note         = {Citation Key: xie2009a tex.citation-number: 41}
}
@article{Xin_Kong_Liu_Chen_Li_Zhu_Gao_Hou_Wang_2018,
	title        = {Machine Learning and Deep Learning Methods for Cybersecurity},
	author       = {Xin, Yang and Kong, Lingshuang and Liu, Zhi and Chen, Yuling and Li, Yanmiao and Zhu, Hongliang and Gao, Mingcheng and Hou, Haixia and Wang, Chunhua},
	year         = 2018,
	journal      = {IEEE Access},
	volume       = 6,
	pages        = {35365–35381},
	doi          = {10.1109/ACCESS.2018.2836950},
	issn         = {2169-3536},
	note         = {tex.ids: xinMachineLearningDeep2018a},
	abstractnote = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.}
}
@article{Xu_2014a,
	title        = {Cybersecurity dynamics},
	author       = {Xu, Shouhuai},
	year         = 2014,
	journal      = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security - HotSoS '14},
	pages        = {1–2},
	doi          = {10.1145/2600176.2600190},
	note         = {tex.ids: xu2014a, xuCybersecurityDynamics2014a tex.source: Google Scholar},
	abstractnote = {We explore the emerging field of Cybersecurity Dynamics, a candidate foundation for the Science of Cybersecurity.}
}
@inproceedings{Xu_2014b,
	title        = {Emergent behavior in cybersecurity},
	author       = {Xu, Shouhuai},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security - HotSoS '14},
	publisher    = {ACM Press},
	pages        = {1–2},
	doi          = {10.1145/2600176.2600189},
	isbn         = {978-1-4503-2907-1},
	url          = {http://dl.acm.org/citation.cfm?doid=2600176.2600189},
	note         = {tex.ids: xu2014c, xuEmergentBehaviorCybersecurity2014a tex.source: Google Scholar},
	place        = {Raleigh, North Carolina},
	abstractnote = {We argue that emergent behavior is inherent to cybersecurity.}
}
@article{Xu_Da_Xu,
	title        = {Cyber Epidemic Models with Dependences},
	author       = {Xu, Maochao and Da, Gaofeng and Xu, Shouhuai},
	journal      = {Internet Mathematics},
	pages        = 37,
	note         = {tex.ids: xu2015b, xuCyberEpidemicModelsa},
	abstractnote = {Studying models of cyber epidemics over arbitrary complex networks can deepen our understanding of cyber security from a whole-system perspective. In this work, we initiate the investigation of cyber epidemic models that accommodate the dependences between the cyber attack events. Due to the notorious difficulty in dealing with such dependences, essentially all existing cyber epidemic models have disregarded them. Specifically, we introduce the idea of copulas into cyber epidemic models for accommodating the dependences between the cyber attack events. We investigate the epidemic equilibrium thresholds as well as the bounds for both equilibrium and nonequilibrium infection probabilities. We further characterize the side effects of disregarding the due dependences between the cyber attack events by showing that the results thereof are unnecessarily restrictive or even incorrect.}
}
@article{Xu_Lu_Li,
	title        = {A Stochastic Model of Active Cyber Defense Dynamics},
	author       = {Xu, Shouhuai and Lu, Wenlian and Li, Hualun},
	journal      = {Internet Mathematics},
	pages        = 48,
	note         = {tex.ids: xu2015a, xuStochasticModelActivea},
	abstractnote = {The concept of active cyber defense has appeared in the literature in recent years. However, there are no mathematical models for characterizing the effectiveness of active cyber defense. In this paper, we fill the void by proposing a novel Markov process model that is native to the interaction between cyber attack and active cyber defense. Unfortunately, the native Markov process model cannot be tackled by techniques of which we are aware. We therefore simplify, via mean-field approximation, the Markov process model as a dynamical system model that is amenable to analysis. This allows us to derive a set of valuable analytic results that characterize the effectiveness of four types of active cyber defense dynamics. Simulations show that the analytic results are intrinsic to the native Markov process model, and therefore justify the validity of the dynamical system model. We also discuss side effects of the mean-field approximation and their implications.}
}
@article{Xu_Lu_Xu_2012,
	title        = {Push- and pull-based epidemic spreading in arbitrary networks: Thresholds and deeper insights},
	author       = {Xu, S. and Lu, W. and Xu, L.},
	year         = 2012,
	journal      = {ACM TAAS},
	volume       = {7, 3},
	number       = 1,
	note         = {Citation Key: xu2012b tex.address: Google Scholar}
}
@article{Xu_Lu_Xu_Zhan_2014,
	title        = {Adaptive Epidemic Dynamics in Networks: Thresholds and Control},
	author       = {Xu, Shouhuai and Lu, Wenlian and Xu, Li and Zhan, Zhenxin},
	year         = 2014,
	month        = jan,
	journal      = {ACM Transactions on Autonomous and Adaptive Systems},
	volume       = 8,
	number       = 4,
	pages        = {1–19},
	doi          = {10.1145/2555613},
	issn         = 15564665,
	note         = {tex.ids: xu2014d, xuAdaptiveEpidemicDynamics2014a}
}
@article{Xu_Lu_Zhan_2012,
	title        = {A stochastic model of multivirus dynamics},
	author       = {Xu, S. and Lu, W. and Zhan, Z.},
	year         = 2012,
	journal      = {IEEE Trans. Depend. Secure Comput},
	volume       = {9, 1},
	pages        = {30–45},
	note         = {Citation Key: xu2012a}
}
@article{Xu_Xu_2012,
	title        = {An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems},
	author       = {Xu, Maochao and Xu, Shouhuai},
	year         = 2012,
	month        = aug,
	journal      = {Internet Mathematics},
	volume       = 8,
	number       = 3,
	pages        = {288–320},
	doi          = {10.1080/15427951.2012.654480},
	issn         = {1542-7951, 1944-9488},
	note         = {tex.ids: mxu2012a, xuExtendedStochasticModel2012a, xuExtendedStochasticModel2012b},
	abstractnote = {Quantitative security analysis of networked computer systems has been an open problem in computer security for decades. Recently, a promising approach was proposed in [Li et al. 11], which, however, made some strong assumptions including the exponential distribution of, and the independence among, the relevant random variables. In this paper, we substantially weaken these assumptions while offering, in addition to the same types of analytical results as in [Li et al. 11], methods for obtaining the desired security quantities in practice. Moreover, we investigate the problem from a higher-level abstraction, which also leads to both analytical results and practical methods for obtaining the desired security quantities. These should represent a significant step toward ultimately solving the problem of quantitative security analysis of networked computer systems.}
}
@article{Xu_Zhan_Xu_Ye_2014,
	title        = {An Evasion and Counter-Evasion Study in Malicious Websites Detection},
	author       = {Xu, Li and Zhan, Zhenxin and Xu, Shouhuai and Ye, Keyin},
	year         = 2014,
	month        = aug,
	journal      = {arXiv:1408.1993 [cs]},
	issn         = {null},
	url          = {http://arxiv.org/abs/1408.1993},
	note         = {tex.ids: xu2014b, xuEvasionCounterevasionStudy2014 arXiv: 1408.1993},
	abstractnote = {Malicious websites are a major cyber attack vector, and effective detection of them is an important cyber defense task. The main defense paradigm in this regard is that the defender uses some kind of machine learning algorithms to train a detection model, which is then used to classify websites in question. Unlike other settings, the following issue is inherent to the problem of malicious websites detection: the attacker essentially has access to the same data that the defender uses to train his/her detection models. This `symmetry' can be exploited by the attacker, at least in principle, to evade the defender's detection models. In this paper, we present a framework for characterizing the evasion and counter-evasion interactions between the attacker and the defender, where the attacker attempts to evade the defender's detection models by taking advantage of this symmetry. Within this framework, we show that an adaptive attacker can make malicious websites evade powerful detection models, but proactive training can be an effective counter-evasion defense mechanism. The framework is geared toward the popular detection model of decision tree, but can be adapted to accommodate other classifiers.}
}
@article{Yamin_Katt_Gkioulos_2020,
	title        = {Cyber ranges and security testbeds: Scenarios, functions, tools and architecture},
	author       = {Yamin, Muhammad Mudassar and Katt, Basel and Gkioulos, Vasileios},
	year         = 2020,
	month        = jan,
	journal      = {Computers \& Security},
	volume       = 88,
	pages        = 101636,
	doi          = {10.1016/j.cose.2019.101636},
	issn         = {0167-4048},
	abstractnote = {The first line of defense against cyber threats and cyber crimes is to be aware and get ready, e.g., through cyber security training. Training can have two forms, the first is directed towards security professionals and aims at improving understanding of the latest threats and increasing skill levels in defending and mitigating against them. The second form of training, which used to attract less attention, aims at increasing cyber security awareness among non-security professionals and the general public. Conducting such training programs requires dedicated testbeds and infrastructures that help realizing and executing the training scenarios and provide a playground for the trainees. A cyber range is an environment that aims at providing such testbeds. The purpose of this paper is to study the concept of a cyber range, and provide a systematic literature review that covers unclassified cyber ranges and security testbeds. In this study we develop a taxonomy for cyber range systems and evaluate the current literature focusing on architecture and scenarios, but including also capabilities, roles, tools and evaluation criteria. The results of this study can be used as a baseline for future initiatives towards the development and evaluation of cyber ranges in accordance with existing best practices and lessons learned from contemporary research and developments.}
}
@inproceedings{yang2015network,
	title        = {Network representation learning with rich text information},
	author       = {Yang, Cheng and Liu, Zhiyuan and Zhao, Deli and Sun, Maosong and Chang, Edward},
	year         = 2015,
	booktitle    = {Proceedings of IJCAI}
}
@article{Yardon_2014,
	title        = {Symantec develops new attack on cyberhacking},
	author       = {Yardon, D.},
	year         = 2014,
	month        = may,
	url          = {http://www.wsj.},
	note         = {Citation Key: yardon2014a}
}
@inproceedings{Yen_Heorhiadi_Oprea_Reiter_Juels_2014,
	title        = {An Epidemiological Study of Malware Encounters in a Large Enterprise},
	author       = {Yen, Ting-Fang and Heorhiadi, Victor and Oprea, Alina and Reiter, Michael K. and Juels, Ari},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security - CCS '14},
	publisher    = {ACM Press},
	pages        = {1117–1130},
	doi          = {10.1145/2660267.2660330},
	isbn         = {978-1-4503-2957-6},
	url          = {http://dl.acm.org/citation.cfm?doid=2660267.2660330},
	note         = {tex.ids: yen2014a, yenEpidemiologicalStudyMalware2014a},
	place        = {Scottsdale, Arizona, USA},
	abstractnote = {We present an epidemiological study of malware encounters in a large, multi-national enterprise. Our data sets allow us to observe or infer not only malware presence on enterprise computers, but also malware entry points, network locations of the computers (i.e., inside the enterprise network or outside) when the malware were encountered, and for some web-based malware encounters, web activities that gave rise to them. By coupling this data with demographic information for each host's primary user, such as his or her job title and level in the management hierarchy, we are able to paint a reasonably comprehensive picture of malware encounters for this enterprise. We use this analysis to build a logistic regression model for inferring the risk of hosts encountering malware; those ranked highly by our model have a > 3\texttimes{} higher rate of encountering malware than the base rate. We also discuss where our study confirms or refutes other studies and guidance that our results suggest.}
}
@inproceedings{Yilek_Rescorla_Shacham_Enright_Savage_2009,
	title        = {When private keys are public: results from the 2008 Debian OpenSSL vulnerability},
	author       = {Yilek, Scott and Rescorla, Eric and Shacham, Hovav and Enright, Brandon and Savage, Stefan},
	year         = 2009,
	booktitle    = {Proceedings of the 9th ACM SIGCOMM conference on Internet measurement conference - IMC '09},
	publisher    = {ACM Press},
	pages        = 15,
	doi          = {10.1145/1644893.1644896},
	isbn         = {978-1-60558-771-4},
	url          = {http://portal.acm.org/citation.cfm?doid=1644893.1644896},
	note         = {tex.ids: yilek2009a, yilekWhenPrivateKeys2009a},
	place        = {Chicago, Illinois, USA},
	abstractnote = {We report on the aftermath of the discovery of a severe vulnerability in the Debian Linux version of OpenSSL. Systems affected by the bug generated predictable random numbers, most importantly public/private keypairs. To study user response to this vulnerability, we collected a novel dataset of daily remote scans of over 50,000 SSL/TLS-enabled Web servers, of which 751 displayed vulnerable certificates. We report three primary results. First, as expected from previous work, we find an extremely slow rate of fixing, with 30\% of the hosts vulnerable when we began our survey on day 4 after disclosure still vulnerable almost six months later. However, unlike conventional vulnerabilities, which typically show a short, fast fixing phase, we observe a much flatter curve with fixing extending six months after the announcement. Second, we identify some predictive factors for the rate of upgrading. Third, we find that certificate authorities continued to issue certificates to servers with weak keys long after the vulnerability was disclosed.}
}
@inproceedings{Yin_Yurcik_Li_Lakkaraju_Abad_2004,
	title        = {Visflowconnect: providing security situational awareness by visualizing network traffic flows},
	author       = {Yin, X. and Yurcik, W. and Li, Y. and Lakkaraju, K. and Abad, C.},
	year         = 2004,
	booktitle    = {Performance, computing, and communications, 2004 IEEE international conference on},
	pages        = {601–607},
	note         = {Citation Key: yin2004a tex.citation-number: 66}
}
@report{zaber_pkb,
	title        = {Measuring Cloud Network Performance with PerfKit Benchmarker},
	author       = {Derek Phanekham and Matthew Zaber and Suku Nair}
}
@inproceedings{Zaffarano_Taylor_Hamilton_2015,
	title        = {A Quantitative Framework for Moving Target Defense Effectiveness Evaluation},
	author       = {Zaffarano, Kara and Taylor, Joshua and Hamilton, Samuel},
	year         = 2015,
	booktitle    = {Proceedings of the Second ACM Workshop on Moving Target Defense - MTD '15},
	publisher    = {ACM Press},
	pages        = {3–10},
	doi          = {10.1145/2808475.2808476},
	isbn         = {978-1-4503-3823-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2808475.2808476},
	note         = {tex.ids: zaffarano2015a, zaffaranoQuantitativeFrameworkMoving2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Static defense has proven to be a brittle mechanism for defending against cyber attack. Despite this, proactive defensive measures have not been widely deployed. This is because flexible proactive defensive measures such as Moving Target Defense (MTD) have as much potential to interfere with a network's ability to support the mission as they do to defend the network. In this paper we introduce an approach to defining and measuring MTD effects applied in a network environment to help guide MTD deployment decisions that successfully balance the potential security benefits of MTD deployment against the potential productivity costs.}
}
@inproceedings{Zhan_Xu_Xu_2015,
	title        = {A Characterization of Cybersecurity Posture from Network Telescope Data},
	author       = {Zhan, Zhenxin and Xu, Maochao and Xu, Shouhuai},
	year         = 2015,
	booktitle    = {Trusted Systems},
	publisher    = {Springer International Publishing},
	volume       = 9473,
	pages        = {105–126},
	doi          = {10.1007/978-3-319-27998-5\_7},
	isbn         = {978-3-319-27997-8},
	url          = {http://link.springer.com/10.1007/978-3-319-27998-5\_7},
	note         = {tex.ids: zhan2014a, zhanCharacterizationCybersecurityPosture2015a},
	place        = {Cham},
	abstractnote = {Data-driven understanding of cybersecurity posture is an important problem that has not been adequately explored. In this paper, we analyze some real data collected by CAIDA's network telescope during the month of March 2013. We propose to formalize the concept of cybersecurity posture from the perspectives of three kinds of time series: the number of victims (i.e., telescope IP addresses that are attacked), the number of attackers that are observed by the telescope, and the number of attacks that are observed by the telescope. Characterizing cybersecurity posture therefore becomes investigating the phenomena and statistical properties exhibited by these time series, and explaining their cybersecurity meanings. For example, we propose the concept of sweep-time, and show that sweep-time should be modeled by stochastic process, rather than random variable. We report that the number of attackers (and attacks) from a certain country dominates the total number of attackers (and attacks) that are observed by the telescope. We also show that substantially smaller network telescopes might not be as useful as a large telescope.},
	editor       = {Yung, Moti and Zhu, Liehuang and Yang, Yanjiang}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the field of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE--a fast, scalable, and effective model, whose single-thread version is 10–400\texttimes{} faster than efficient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE first initializes network embeddings efficiently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and significant efficiency superiority when compared to the aforementioned baselines. In addition, ProNE's embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
@inproceedings{Zhang_Durumeric_Bailey_Liu_Karir_2014,
	title        = {On the Mismanagement and Maliciousness of Networks},
	author       = {Zhang, Jing and Durumeric, Zakir and Bailey, Michael and Liu, Mingyan and Karir, Manish},
	year         = 2014,
	booktitle    = {Proceedings 2014 Network and Distributed System Security Symposium},
	publisher    = {Internet Society},
	doi          = {10.14722/ndss.2014.23057},
	isbn         = {978-1-891562-35-8},
	url          = {https://www.ndss-symposium.org/ndss2014/programme/mismanagement-and-maliciousness-networks/},
	note         = {tex.ids: zhang2014a, zhangMismanagementMaliciousnessNetworks2014a},
	place        = {San Diego, CA},
	abstractnote = {In this paper, we systematically explore the widely held, anecdotal belief that mismanaged networks are responsible for a wide range of security incidents. Utilizing Internet-scale measurements of DNS resolvers, BGP routers, and SMTP, HTTP, and DNS-name servers, we find there are thousands of networks where a large fraction of network services are misconfigured. Combining global feeds of malicious activities including spam, phishing, malware, and scanning, we find a statistically significant correlation between networks that are mismanaged and networks that are responsible for maliciousness.}
}
@article{Zhang_Patras_Haddadi_2019,
	title        = {Deep Learning in Mobile and Wireless Networking: A Survey},
	author       = {Zhang, Chaoyun and Patras, Paul and Haddadi, Hamed},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1803.04311 [cs]},
	url          = {http://arxiv.org/abs/1803.04311},
	note         = {arXiv: 1803.04311},
	abstractnote = {The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space.}
}
@article{Zhang_Wang_Jajodia_Singhal_Albanese_2016,
	title        = {Network Diversity: A Security Metric for Evaluating the Resilience of Networks Against Zero-Day Attacks},
	author       = {Zhang, Mengyuan and Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop and Albanese, Massimiliano},
	year         = 2016,
	month        = may,
	journal      = {IEEE Transactions on Information Forensics and Security},
	volume       = 11,
	number       = 5,
	pages        = {1071–1086},
	doi          = {10.1109/TIFS.2016.2516916},
	issn         = {1556-6013, 1556-6021},
	note         = {tex.ids: zhang2016a, zhangNetworkDiversitySecurity2016a, zhangNetworkDiversitySecurity2016b tex.citation-number: 115 publisher: IEEE},
	abstractnote = {Diversity has long been regarded as a security mechanism for improving the resilience of software and networks against various attacks. More recently, diversity has found new applications in cloud computing security, Moving Target Defense (MTD), and improving the robustness of network routing. However, most existing efforts rely on intuitive and imprecise notions of diversity, and the few existing models of diversity are mostly designed for a single system running diverse software replicas or variants. At a higher abstraction level, as a global property of the entire network, diversity and its effect on security have received limited attention. In this paper, we take the first step towards formally modeling network diversity as a security metric by designing and evaluating a series of diversity metrics. Specifically, we first devise a biodiversity-inspired metric based on the effective number of distinct resources. We then propose two complementary diversity metrics, based on the least and the average attacking efforts, respectively. We provide guidelines for instantiating the proposed metrics and present a case study on estimating software diversity. Finally, we evaluate the proposed metrics through simulation.}
}
@inproceedings{Zhang_Zhang_Ou_2014,
	title        = {After we knew it: empirical study and modeling of cost-effectiveness of exploiting prevalent known vulnerabilities across IaaS cloud},
	author       = {Zhang, Su and Zhang, Xinwen and Ou, Xinming},
	year         = 2014,
	booktitle    = {Proceedings of the 9th ACM symposium on Information, computer and communications security - ASIA CCS '14},
	publisher    = {ACM Press},
	pages        = {317–328},
	doi          = {10.1145/2590296.2590300},
	isbn         = {978-1-4503-2800-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2590296.2590300},
	note         = {tex.ids: zhang2014b, zhangWeKnewIt2014a},
	place        = {Kyoto, Japan},
	abstractnote = {Infrastructure as a Service (IaaS) cloud has been attracting more and more customers as it provides the highest level of flexibility by offering configurable virtual machines (VMs) and computing infrastructures. Public VM images are usually available for customers to customize and launch. However, the 1 to N mapping between VM images and running instances in IaaS makes vulnerabilities propagate rapidly across the entire public cloud. Besides, IaaS cloud naturally comes with a larger and more stable attack surface and more concentrated target resources than traditional surroundings. In this paper, we first identify the threat of exploiting prevalent vulnerabilities 1 over public IaaS cloud with an empirical study in Amazon EC2. We find that attackers can compromise a considerable number of VMs with trivial cost. We then do a qualitative cost-effectiveness analysis of this threat. Our main result is a two-fold observation: in IaaS cloud, exploiting prevalent vulnerabilities is much more cost-effective than traditional in-house computing environment, therefore attackers have stronger incentive; Fortunately, on the other hand, cloud defenders (cloud providers and customers) also have much lower cost-loss ratio than in traditional environment, therefore they can be more effective for defending attacks. We then build a game-theoretic model and conduct a risk-gain analysis to compare exploiting and patching strategies under cloud and traditional computing environments. Our modeling indicates that under cloud environment, both attack and defense become less cost-effective as time goes by, and the earlier actioner can be more rewarding. We propose countermeasures against such threat in order to bridge the gap between current security situation and defending mechanisms. To our best knowledge, we are the first to analyze and model the threat with prevalent knownvulnerabilities in public cloud.}
}
@inproceedings{Zheng_Lu_Xu_2015,
	title        = {Active cyber defense dynamics exhibiting rich phenomena},
	author       = {Zheng, Ren and Lu, Wenlian and Xu, Shouhuai},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 Symposium and Bootcamp on the Science of Security - HotSoS '15},
	publisher    = {ACM Press},
	pages        = {1–12},
	doi          = {10.1145/2746194.2746196},
	isbn         = {978-1-4503-3376-4},
	url          = {http://dl.acm.org/citation.cfm?doid=2746194.2746196},
	note         = {tex.ids: zheng2015a, zhengActiveCyberDefense2015a, zhengActiveCyberDefense2015b, zhengActiveCyberDefense2015c},
	place        = {Urbana, Illinois},
	abstractnote = {The Internet is a man-made complex system under constant attacks (e.g., Advanced Persistent Threats and malwares). It is therefore important to understand the phenomena that can be induced by the interaction between cyber attacks and cyber defenses. In this paper, we explore the rich phenomena that can be exhibited when the defender employs active defense to combat cyber attacks. To the best of our knowledge, this is the first study that shows that active cyber defense dynamics (or more generally, cybersecurity dynamics) can exhibit the bifurcation and chaos phenomena. This has profound implications for cyber security measurement and prediction: (i) it is infeasible (or even impossible) to accurately measure and predict cyber security under certain circumstances; (ii) the defender must manipulate the dynamics to avoid such unmanageable situations in real-life defense operations.}
}
@article{Zhu_Liu_He_Ota_2015,
	title        = {Quality of experience and quality of protection provisions in emerging mobile networks [guest editorial},
	author       = {Zhu, H. and Liu, K.H. and He, W. and Ota, K.},
	year         = 2015,
	month        = aug,
	journal      = {IEEE Wireless Communications},
	volume       = 22,
	number       = 4,
	pages        = {8--9,},
	note         = {Citation Key: zhu2015a tex.citation-number: 59}
}
@article{Zhu_Rass_2018,
	title        = {Game Theory Meets Network Security: A Tutorial at ACM CCS},
	author       = {Zhu, Quanyan and Rass, Stefan},
	year         = 2018,
	month        = {01},
	journal      = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {2163–2165},
	doi          = {10.1145/3243734.3264421},
	note         = {arXiv: 1808.08066},
	abstractnote = {The increasingly pervasive connectivity of today's information systems brings up new challenges to security. Traditional security has accomplished a long way toward protecting well-defined goals such as confidentiality, integrity, availability, and authenticity. However, with the growing sophistication of the attacks and the complexity of the system, the protection using traditional methods could be costprohibitive. A new perspective and a new theoretical foundation are needed to understand security from a strategic and decision-making perspective. Game theory provides a natural framework to capture the adversarial and defensive interactions between an attacker and a defender. It provides a quantitative assessment of security, prediction of security outcomes, and a mechanism design tool that can enable security-by-design and reverse the attacker's advantage. This tutorial provides an overview of diverse methodologies from game theory that includes games of incomplete information, dynamic games, mechanism design theory to offer a modern theoretic underpinning of a science of cybersecurity. The tutorial will also discuss open problems and research challenges that the CCS community can address and contribute with an objective to build a multidisciplinary bridge between cybersecurity, economics, game and decision theory.}
}
@article{Zimmermann_1980,
	title        = {OSI reference model-the ISO model of architecture for open systems interconnection},
	author       = {Zimmermann, Hubert},
	year         = 1980,
	journal      = {IEEE Transactions on communications},
	volume       = 28,
	number       = 4,
	pages        = {425–432}
}
@article{Zonouz_Berthier_Khurana_Sanders_Yardley_2015,
	title        = {Seclius: An information flow-based, consequence-centric security metric},
	author       = {Zonouz, S.A. and Berthier, R. and Khurana, H. and Sanders, W.H. and Yardley, T.},
	year         = 2015,
	month        = feb,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 26,
	number       = 2,
	pages        = {562--573,},
	note         = {Citation Key: zonouz2015a tex.citation-number: 118}
}
@article{Zonouz_Haghani_2013,
	title        = {Cyber-physical security metric inference in smart grid critical infrastructures based on system administrators' responsive behavior},
	author       = {Zonouz, S. and Haghani, P.},
	year         = 2013,
	month        = nov,
	journal      = {Computers \& Security},
	volume       = 39,
	number       = {PART B},
	pages        = {190--200,},
	note         = {Citation Key: zonouz2013a tex.citation-number: 3}
}
