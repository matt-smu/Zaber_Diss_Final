@article{Rashid_Chivers_Danezis_Lupu_Martin,
	title        = {The Cyber Security Body of Knowledge},
	author       = {Rashid, Awais and Chivers, Howard and Danezis, George and Lupu, Emil and Martin, Andrew},
	pages        = 854
}
@article{Chew_Swanson_Stine_Bartol_Brown_Robinson_2008,
	title        = {Performance Measurement Guide for Information Security},
	author       = {Chew, Elizabeth and Swanson, Marianne M. and Stine, Kevin M. and Bartol, N. and Brown, Anthony and Robinson, W.},
	year         = 2008,
	month        = {07},
	url          = {https://www.nist.gov/publications/performance-measurement-guide-information-security},
	abstractnote = {This document provides guidance on how an organization, through the use of metrics, identifies the adequacy of in-place security controls, policies, and procedu}
}
@article{iso_27004,
	title        = {ISO/IEC 27004:2016},
	author       = {14:00-17:00},
	journal      = {ISO},
	url          = {http://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/06/41/64120.html},
	abstractnote = {Information technology — Security techniques — Information security management — Monitoring, measurement, analysis and evaluation}
}
@article{cis_cic,
	title        = {CIS Controls V7 Measures \& Metrics},
	journal      = {CIS},
	url          = {https://www.cisecurity.org/white-papers/cis-controls-v7-measures-metrics/},
	abstractnote = {CIS Controls are updated \& reviewed in collaboration with international cybersecurity experts and IT professionals in various industries.}
}
@inbook{Debar_2019,
	title        = {The cyber security body of knowledge},
	author       = {Debar, Hervé},
	year         = 2019,
	publisher    = {University of Bristol},
	url          = {https://www.cybok.org/},
	note         = {tex.chapter: Security Operations \& Inicident Management}
}
@misc{soss_v9,
	title        = {STATE OF SOFTWARE SECURITY},
	url          = {https://www.veracode.com/sites/default/files/pdf/resources/ipapers/state-of-software-security-volume-9/}
}
@article{Alhazmi_Malaiya_2008,
	title        = {Application of vulnerability discovery models to major operating systems},
	author       = {Alhazmi, Omar H. and Malaiya, Yashwant K.},
	year         = 2008,
	journal      = {IEEE Transactions on Reliability},
	volume       = 57,
	number       = 1,
	pages        = {14–22},
	note         = {tex.ids: alhazmiApplicationVulnerabilityDiscovery2008a, alhazmiApplicationVulnerabilityDiscovery2008b}
}
@inproceedings{Anderson_2001,
	title        = {Why information security is hard-an economic perspective},
	author       = {Anderson, Ross},
	year         = 2001,
	booktitle    = {Seventeenth Annual Computer Security Applications Conference},
	publisher    = {IEEE},
	pages        = {358–365},
	issn         = {null},
	note         = {tex.ids: andersonWhyInformationSecurity2001a, andersonWhyInformationSecurity2001b}
}
@inproceedings{Anderson_Moore_2007,
	title        = {The economics of information security: A survey and open questions},
	author       = {Anderson, Ross and Moore, Tyler},
	year         = 2007,
	booktitle    = {Fourth bi-annual Conference on the Economics of the Software and Internet Industries},
	pages        = {19–20}
}
@article{Bellovin_2006,
	title        = {On the Brittleness of Software and the Infeasibility of Security Metrics},
	author       = {Bellovin, S.M.},
	year         = 2006,
	month        = {07},
	journal      = {IEEE Security \& Privacy Magazine},
	volume       = 4,
	number       = 4,
	pages        = {96–96},
	doi          = {10.1109/MSP.2006.101},
	issn         = {1540-7993},
	note         = {tex.ids: bellovinBrittlenessSoftwareInfeasibility2006a}
}
@article{Bohme_Moore,
	title        = {Security Metrics and Security Investment},
	author       = {Bohme, Rainer and Moore, Tyler},
	year         = 2013,
	pages        = 36
}
@article{Gordon_Loeb,
	title        = {The economics of information security investment},
	author       = {Gordon, Lawrence A and Loeb, Martin P},
	journal      = {ACM Transactions on Information and System Security},
	volume       = 5,
	number       = 4,
	pages        = 20
}
@article{Anderson_Mooreb,
	title        = {Information Security Economics -- and Beyond},
	author       = {Anderson, Ross and Moore, Tyler},
	pages        = 24,
	abstractnote = {The economics of information security has recently become a thriving and fast-moving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, incentives are becoming as important to dependability as technical design. The new ﬁeld provides valuable insights not just into ‘security’ topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of eﬀort by programmers and testers), and policy (particularly digital rights management). This research program has been starting to spill over into more general security questions (such as law-enforcement strategy), and into the interface between security and sociology. Most recently it has started to interact with psychology, both through the psychology-and-economics tradition and in response to phishing. The promise of this research program is a novel framework for analyzing information security problems – one that is both principled and eﬀective.}
}
@article{Anderson_Moore,
	title        = {The Economics of Information Security: A Survey and Open Questions},
	author       = {Anderson, Ross and Moore, Tyler},
	pages        = 27,
	abstractnote = {The economics of information security has recently become a thriving and fastmoving discipline. As distributed systems are assembled from machines belonging to principals with divergent interests, we ﬁnd incentives becoming as important to dependability as technical design is. The new ﬁeld provides valuable insights not just into ‘security’ topics such as privacy, bugs, spam, and phishing, but into more general areas such as system dependability (the design of peer-to-peer systems and the optimal balance of eﬀort by programmers and testers), policy (particularly digital rights management) and more general security questions (such as law-enforcement strategy).}
}
@book{Bell_LaPadula_1973,
	title        = {Secure computer systems: Mathematical foundations (volume 1)},
	author       = {Bell, D. and LaPadula, L.},
	year         = 1973,
	institution  = {Technical Report ESD-TR-73-278, Mitre Corporation}
}
@article{Dhillon_2011,
	title        = {Developer-Driven Threat Modeling: Lessons Learned in the Trenches},
	author       = {Dhillon, Danny},
	year         = 2011,
	month        = {07},
	journal      = {IEEE Security \& Privacy},
	volume       = 9,
	number       = 4,
	pages        = {41–47},
	doi          = {10.1109/MSP.2011.47},
	issn         = {1540-7993}
}
@article{Duggan_Michalski,
	title        = {Threat Analysis Framework},
	author       = {Duggan, David P and Michalski, John T},
	pages        = 31,
	abstractnote = {The need to protect national critical infrastructure has led to the development of a threat analysis framework. The threat analysis framework can be used to identify the elements required to quantify threats against critical infrastructure assets and provide a means of distributing actionable threat information to critical infrastructure entities for the protection of infrastructure assets. This document identifies and describes five key elements needed to perform a comprehensive analysis of threat: the identification of an adversary, the development of generic threat profiles, the identification of generic attack paths, the discovery of adversary intent, and the identification of mitigation strategies.}
}
@article{Ellison,
	title        = {Ceremony Design and Analysis},
	author       = {Ellison, Carl},
	pages        = 17,
	abstractnote = {The concept of ceremony is introduced as an extension of the concept of network protocol, with human nodes alongside computer nodes and with communication links that include UI, human-to-human communication and transfers of physical objects that carry data. What is out-of-band to a protocol is in-band to a ceremony, and therefore subject to design and analysis using variants of the same mature techniques used for the design and analysis of protocols. Ceremonies include all protocols, as well as all applications with a user interface, all workflow and all provisioning scenarios. A secure ceremony is secure against both normal attacks and social engineering. However, some secure protocols imply ceremonies that cannot be made secure.}
}
@article{Hutchins_Cloppert_Amin,
	title        = {Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains},
	author       = {Hutchins, Eric M and Cloppert, Michael J and Amin, Rohan M},
	pages        = 14,
	abstractnote = {Conventional network defense tools such as intrusion detection systems and anti-virus focus on the vulnerability component of risk, and traditional incident response methodology presupposes a successful intrusion. An evolution in the goals and sophistication of computer network intrusions has rendered these approaches insuﬃcient for certain actors. A new class of threats, appropriately dubbed the “Advanced Persistent Threat” (APT), represents well-resourced and trained adversaries that conduct multi-year intrusion campaigns targeting highly sensitive economic, proprietary, or national security information. These adversaries accomplish their goals using advanced tools and techniques designed to defeat most conventional computer network defense mechanisms. Network defense techniques which leverage knowledge about these adversaries can create an intelligence feedback loop, enabling defenders to establish a state of information superiority which decreases the adversary’s likelihood of success with each subsequent intrusion attempt. Using a kill chain model to describe phases of intrusions, mapping adversary kill chain indicators to defender courses of action, identifying patterns that link individual intrusions into broader campaigns, and understanding the iterative nature of intelligence gathering form the basis of intelligence-driven computer network defense (CND). Institutionalization of this approach reduces the likelihood of adversary success, informs network defense investment and resource prioritization, and yields relevant metrics of performance and eﬀectiveness. The evolution of advanced persistent threats necessitates an intelligence-based model because in this model the defenders mitigate not just vulnerability, but the threat component of risk, too.}
}
@book{Morana_2015,
	title        = {Risk centric threat modeling: process for attack simulation and threat analysis},
	author       = {Morana, Marco M. and Uceda Vélez, Tony},
	year         = 2015,
	publisher    = {Wiley},
	isbn         = {978-1-118-98835-0},
	place        = {Hoboken, New Jersey},
	abstractnote = {“This book describes how to apply application threat modeling as an advanced preventive form of security”--}
}
@article{Musman_Turner_2018,
	title        = {A game theoretic approach to cyber security risk management},
	author       = {Musman, Scott and Turner, Andrew},
	year         = 2018,
	month        = {04},
	journal      = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	volume       = 15,
	number       = 2,
	pages        = {127–146},
	doi          = {10.1177/1548512917699724},
	issn         = {1548-5129, 1557-380X},
	abstractnote = {This paper describes the Cyber Security Game (CSG). Cyber Security Game is a method that has been implemented in software that quantitatively identifies cyber security risks and uses this metric to determine the optimal employment of security methods for any given investment level. Cyber Security Game maximizes a system’s ability to operate in today’s contested cyber environment by minimizing its mission risk. The risk score is calculated by using a mission impact model to compute the consequences of cyber incidents and combining that with the likelihood that attacks will succeed. The likelihood of attacks succeeding is computed by applying a threat model to a system topology model and defender model. Cyber Security Game takes into account the widespread interconnectedness of cyber systems, where defenders must defend all multi-step attack paths and an attacker only needs one to succeed. It employs a game theoretic solution using a game formulation that identifies defense strategies to minimize the maximum cyber risk (MiniMax). This paper discusses the methods and models that compose Cyber Security Game . A limited example of a Point of Sale system is used to provide specific demonstrations of Cyber Security Game models and analyses.}
}
@article{Rosenquist,
	title        = {Prioritizing Information Security Risks with Threat Agent Risk Assessment},
	author       = {Rosenquist, Matt},
	pages        = 8
}
@article{Saitta_Larcom_Eddington,
	title        = {Trike v.1 Methodology Document [Draft]},
	author       = {Saitta, Paul and Larcom, Brenda and Eddington, Michael},
	pages        = 17
}
@article{Schneier_1999,
	title        = {Attack trees},
	author       = {Schneier, Bruce},
	year         = 1999,
	journal      = {Dr. Dobb’s journal},
	volume       = 24,
	number       = 12,
	pages        = {21–29},
	note         = {tex.ids: schneierAttackTrees1999a}
}
@article{Schoenfield,
	title        = {Threat Modeling Demystified},
	author       = {Schoenfield, Brook S E},
	pages        = 98
}
@article{Shevchenko,
	title        = {Threat Modeling: A Summary of Available Methods},
	author       = {Shevchenko, Nataliya and Chick, Timothy A and O’Riordan, Paige and Scanlon, Thomas Patrick and Woody, Carol},
	pages        = 26
}
@article{Shostack,
	title        = {Experiences Threat Modeling at Microsoft},
	author       = {Shostack, Adam},
	pages        = 11,
	abstractnote = {Describes a decade of experience threat modeling products and services at Microsoft. Describes the current threat modeling methodology used in the Security Development Lifecycle. The methodology is a practical approach, usable by non-experts, centered on data ﬂow diagrams and a threat enumeration technique of ‘STRIDE per element.’ The paper covers some lessons learned which are likely applicable to other security analysis techniques. The paper closes with some possible questions for academic research.}
}
@inbook{Srivatanakul_Clark_Polack_2004,
	title        = {Effective Security Requirements Analysis: HAZOP and Use Cases},
	author       = {Srivatanakul, Thitima and Clark, John A. and Polack, Fiona},
	year         = 2004,
	booktitle    = {Information Security},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 3225,
	pages        = {416–427},
	doi          = {10.1007/978-3-540-30144-8_35},
	isbn         = {978-3-540-23208-7},
	url          = {http://link.springer.com/10.1007/978-3-540-30144-8_35},
	place        = {Berlin, Heidelberg},
	abstractnote = {Use cases are widely used for functional requirements elicitation. However, security non-functional requirements are often neglected in this requirements analysis process. As systems become increasingly complex current means of analysis will probably prove ineﬀective. In the safety domain a variety of eﬀective analysis techniques have emerged over many years. Since the safety and security domains share many similarities, various authors have suggested that safety techniques might usefully ﬁnd application in security. This paper takes one such technique, HAZOP, and applies it to one widely used functional requirement elicitation component, UML use cases, in order to provide systematic analysis of potential security issues at the start of system development.},
	editor       = {Zhang, Kan and Zheng, YuliangEditors}
}
@article{Sullivan,
	title        = {Chapter 9: Dataflow Diagrams},
	author       = {Sullivan, Louis Henri},
	pages        = 50
}
@book{Woodard_Veitch_Thomas_Duggan_2007,
	title        = {Categorizing threat: building and using a generic threat matrix.},
	author       = {Woodard, Laura and Veitch, Cynthia K. and Thomas, Sherry Reede and Duggan, David Patrick},
	year         = 2007,
	month        = {09},
	number       = {SAND2007-5791, 921121},
	pages        = {SAND2007--5791, 921121},
	doi          = {10.2172/921121},
	url          = {http://www.osti.gov/servlets/purl/921121-o2fi48/}
}
@article{Wynn_Whitmore_Upton_Spriggs_McKinnon_McInnes_Graubart_Clausen,
	title        = {Methodology Description Version 1.0},
	author       = {Wynn, Jackson and Whitmore, Joseph and Upton, Geoff and Spriggs, Lindsay and McKinnon, Dan and McInnes, Richard and Graubart, Richard and Clausen, Lauren},
	pages        = 60
}
@article{Zhu_Rass_2018,
	title        = {Game Theory Meets Network Security: A Tutorial at ACM CCS},
	author       = {Zhu, Quanyan and Rass, Stefan},
	year         = 2018,
	month        = {01},
	journal      = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {2163–2165},
	doi          = {10.1145/3243734.3264421},
	note         = {arXiv: 1808.08066},
	abstractnote = {The increasingly pervasive connectivity of today’s information systems brings up new challenges to security. Traditional security has accomplished a long way toward protecting well-defined goals such as confidentiality, integrity, availability, and authenticity. However, with the growing sophistication of the attacks and the complexity of the system, the protection using traditional methods could be costprohibitive. A new perspective and a new theoretical foundation are needed to understand security from a strategic and decision-making perspective. Game theory provides a natural framework to capture the adversarial and defensive interactions between an attacker and a defender. It provides a quantitative assessment of security, prediction of security outcomes, and a mechanism design tool that can enable security-by-design and reverse the attacker’s advantage. This tutorial provides an overview of diverse methodologies from game theory that includes games of incomplete information, dynamic games, mechanism design theory to offer a modern theoretic underpinning of a science of cybersecurity. The tutorial will also discuss open problems and research challenges that the CCS community can address and contribute with an objective to build a multidisciplinary bridge between cybersecurity, economics, game and decision theory.}
}
@article{Corporation,
	title        = {Structured Threat Information eXpression (STIX™)},
	author       = {Corporation, The MITRE},
	pages        = 18
}
@inproceedings{Beck_2013,
	title        = {Manifesto for Agile Software Development},
	author       = {Beck, Kent M. and Beedle, Mike and Bennekum, Arie van and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andy and Jeffries, Ron and et al.},
	year         = 2013
}
@inproceedings{Johnson_2013,
	title        = {Why don’t software developers use static analysis tools to find bugs?},
	author       = {Johnson, Brittany and Song, Yoonki and Murphy-Hill, Emerson and Bowdidge, Robert},
	year         = 2013,
	month        = {05},
	booktitle    = {2013 35th International Conference on Software Engineering (ICSE)},
	publisher    = {IEEE},
	pages        = {672–681},
	doi          = {10.1109/ICSE.2013.6606613},
	isbn         = {978-1-4673-3076-3},
	url          = {http://ieeexplore.ieee.org/document/6606613/},
	place        = {San Francisco, CA, USA}
}
@inproceedings{Michael_Williams_2007,
	title        = {Toward the Use of Automated Static Analysis Alerts for Early Identification of Vulnerability- and Attack-prone Components},
	author       = {Michael and Williams, Laurie},
	year         = 2007,
	month        = {07},
	booktitle    = {Second International Conference on Internet Monitoring and Protection (ICIMP 2007)},
	publisher    = {IEEE},
	pages        = {18–18},
	doi          = {10.1109/ICIMP.2007.46},
	url          = {https://ieeexplore.ieee.org/document/4271764/},
	place        = {San Jose, CA},
	abstractnote = {Extensive research has shown that software metrics can be used to identify fault- and failure-prone components. These metrics can also give early indications of overall software quality. We seek to parallel the identification and prediction of fault- and failure-prone components in the reliability context with vulnerability- and attack-prone components in the security context. Our research will correlate the quantity and severity of alerts generated by source code static analyzers to vulnerabilities discovered by manual analyses and testing. A strong correlation may indicate that automated static analyzers (ASA), a potentially early technique for vulnerability identification in the development phase, can identify high risk areas in the software system. Based on the alerts, we may be able to predict the presence of more complex and abstract vulnerabilities involved with the design and operation of the software system. An early knowledge of vulnerability can allow software engineers to make informed risk management decisions and prioritize redesign, inspection, and testing efforts. This paper presents our research objective and methodology.}
}
@article{Basili_Briand_Melo_1996,
	title        = {A validation of object-oriented design metrics as quality indicators},
	author       = {Basili, V.R. and Briand, L.C. and Melo, W.L.},
	year         = 1996,
	month        = 10,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 22,
	number       = 10,
	pages        = {751–761},
	doi          = {10.1109/32.544352},
	issn         = {00985589},
	abstractnote = {This paper presents the results of a study conducted at the University of Maryland in which we experimentally investigated the suite of Object-Oriented (OO) design metrics introduced by [Chidamber&Kemerer, 1994]. In order to do this, we assessed these metrics as predictors of fault-prone classes. This study is complementary to [Li&Henry, 1993] where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on experimental results, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber&Kemerer’s OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. We also showed that they are, on our data set, better predictors than “traditional” code metrics, which can only be collected at a later phase of the software development processes.}
}
@inproceedings{Rahman_Williams_2016,
	title        = {Security practices in DevOps},
	author       = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
	year         = 2016,
	booktitle    = {Proceedings of the Symposium and Bootcamp on the Science of Security - HotSos ’16},
	publisher    = {ACM Press},
	pages        = {109–111},
	doi          = {10.1145/2898375.2898383},
	isbn         = {978-1-4503-4277-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2898375.2898383},
	place        = {Pittsburgh, Pennsylvania}
}
@article{Chandramouli_Samarati_Ray_Ray_2018,
	title        = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	author       = {Chandramouli, Ramaswamy and Samarati, Pierangela and Ray, Indrakshi and Ray, Indrajit},
	year         = 2018,
	journal      = {Comprehensive Security Assurance Measures for Virtualized Server Environments},
	pages        = {55–77},
	doi          = {https://doi.org/10.1007/978-3-030-04834-1_3},
	abstractnote = {Virtualization is the dominant technology employed in enterprise data centers and those used for offering cloud computing services. This technology has resulted in what is called a virtualized infrastructure.}
}
@inproceedings{Cheng_Deng_Li_DeLoach_Singhal_Ou_2014,
	title        = {Metrics of Security},
	author       = {Cheng, Yi and Deng, Julia and Li, Jason H. and DeLoach, Scott A. and Singhal, Anoop and Ou, Xinming},
	year         = 2014,
	booktitle    = {Cyber Defense and Situational Awareness},
	doi          = {10.1007/978-3-319-11391-3_13},
	abstractnote = {Discussion of challenges and ways of improving Cyber Situational Awareness dominated our previous chapters. However, we have not yet touched on how to quantify any improvement we might achieve. Indeed, to get an accurate assessment of network security and provide sufficient Cyber Situational Awareness (CSA), simple but meaningful metrics—the focus of the Metrics of Security chapter—are necessary. The adage, “what can’t be measured can’t be effectively managed,” applies here. Without good metrics and the corresponding evaluation methods, security analysts and network operators cannot accurately evaluate and measure the security status of their networks and the success of their operations. In particular, this chapter explores two distinct issues: (i) how to define and use metrics as quantitative characteristics to represent the security state of a network, and (ii) how to define and use metrics to measure CSA from a defender’s point of view.}
}
@inproceedings{Cho_Hurley_Xu_2016,
	title        = {Metrics and measurement of trustworthy systems},
	author       = {Cho, Jin-Hee and Hurley, Patrick M. and Xu, Shouhuai},
	year         = 2016,
	month        = nov,
	booktitle    = {MILCOM 2016 - 2016 IEEE Military Communications Conference},
	publisher    = {IEEE},
	pages        = {1237–1242},
	doi          = {10.1109/MILCOM.2016.7795500},
	isbn         = {978-1-5090-3781-0},
	url          = {http://ieeexplore.ieee.org/document/7795500/},
	place        = {Baltimore, MD, USA},
	abstractnote = {Accurate measurement of the quality of systems is crucial to building trustworthy systems. Such a measurement indicates whether a system is working properly and meeting its requirements. Although security and dependability metrics are regarded as key metrics for measuring the quality of systems, they are not sufﬁcient for measuring the quality of systems that are placed in a multi-domain environment including hardware, software, network, human factors, and physical environments. In order to embrace multidimensional aspects of the quality of a system, we introduce a trustworthiness metric framework that supports three key submetrics of trust, resilience, and agility, and propose an ontology-based framework with three corresponding sub-ontologies. We also discuss how the key metrics are related to the severity of threats and the quality of assessment tools. This work is part of the cyber defense effort conducted by the Trustworthy Systems Working Group (TSWG) under the Cyber Strategic Challenge Group (CSCG) of The Technical Cooperation Program (TTCP), which is an international cooperation organization for enhancing defense science and technology.}
}
@inproceedings{DaSilva_Ferreira_deGeus_2012,
	title        = {A methodology for management of cloud computing using security criteria},
	author       = {Da Silva, Carlos Alberto and Ferreira, Anderson Soares and de Geus, Paulo Licio},
	year         = 2012,
	booktitle    = {2012 IEEE Latin America Conference on Cloud Computing and Communications (LatinCloud)},
	publisher    = {IEEE},
	pages        = {49–54}
}
@inbook{deFranco_Rosa_Jino_2017,
	title        = {A Survey of Security Assessment Ontologies},
	author       = {de Franco Rosa, Ferrucio and Jino, Mario},
	year         = 2017,
	booktitle    = {Recent Advances in Information Systems and Technologies},
	publisher    = {Springer International Publishing},
	volume       = 569,
	pages        = {166–173},
	doi          = {10.1007/978-3-319-56535-4_17},
	isbn         = {978-3-319-56534-7},
	url          = {http://link.springer.com/10.1007/978-3-319-56535-4_17},
	place        = {Cham},
	abstractnote = {A literature survey on ontologies concerning the Security Assessment domain has been carried out to uncover initiatives that aim at formalizing concepts from the “Security Assessment” field of research. A preliminary analysis and a discussion on the selected works are presented. Our main contribution is an updated literature review, describing key characteristics, results, research issues, and application domains of the papers. We have also detected gaps in the Security Assessment literature that could be the subject of further studies in the field. This work is meant to be useful for security researchers who wish to adopt a formal approach in their methods.},
	editor       = {Rocha, Álvaro and Correia, Ana Maria and Adeli, Hojjat and Reis, Luís Paulo and Costanzo, SandraEditors}
}
@article{Grubesic_Matisziw_Murray_Snediker_2008a,
	title        = {Comparative approaches for assessing network vulnerability},
	author       = {Grubesic, Tony H. and Matisziw, Timothy C. and Murray, Alan T. and Snediker, Diane},
	year         = 2008,
	journal      = {International Regional Science Review},
	volume       = 31,
	number       = 1,
	pages        = {88–112}
}
@article{Grubesic_Matisziw_Murray_Snediker_2008b,
	title        = {Comparative Approaches for Assessing Network Vulnerability},
	author       = {Grubesic, Tony and Matisziw, Timothy and Murray, Alan and Snediker, Diane},
	year         = 2008,
	month        = jan,
	journal      = {International Regional Science Review - INT REG SCI REV},
	volume       = 31,
	doi          = {10.1177/0160017607308679},
	abstractnote = {A common theme in analysis and evaluation of network-based critical infrastructure is the assessment of system vulnerability. Graph theoretic, simulation, and optimization-based tech-niques have played a significant role in examining potential network vulnerabilities given the insights they can provide for mitigating facility loss and prioritizing fortification efforts. Cen-tral to these approaches is the concept of facility (arc–node) importance or criticality to sys-tem survivability. Assessments of network vulnerability can dramatically differ based on how facility importance is characterized. In this review, various approaches for assessing facility importance and network vulnerability are examined. The key differences in these approaches are the ways in which a facility’s role in maintaining network operability is evaluated given arc–node disruption. Comparative results suggest significant differences exist among mea-sures of facility importance and network performance. Furthermore, the subsequent incon-gruities in these measures and their implications need to be clearly understood to support interdiction risk and vulnerability assessment for critical infrastructures.}
}
@inbook{Kotenko_Doynikova_2014a,
	title        = {Security Assessment of Computer Networks Based on Attack Graphs and Security Events},
	author       = {Kotenko, Igor and Doynikova, Elena},
	year         = 2014,
	booktitle    = {Information and Communication Technology},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 8407,
	pages        = {462–471},
	doi          = {10.1007/978-3-642-55032-4_47},
	isbn         = {978-3-642-55031-7},
	url          = {http://link.springer.com/10.1007/978-3-642-55032-4_47},
	place        = {Berlin, Heidelberg},
	abstractnote = {Security assessment is an important task for operation of modern computer networks. The paper suggests the security assessment technique based on attack graphs which can be implemented in contemporary SIEM systems. It is based on the security metrics taxonomy and different techniques for calculation of security metrics according to the data about current events. Proposed metrics form the basis for security awareness and reflect current security situation, including development of attacks, attacks sources and targets, attackers’ characteristics. The technique suggested is demonstrated on a case study.},
	editor       = {Linawati and Mahendra, Made Sudiana and Neuhold, Erich J. and Tjoa, A Min and You, IlsunEditors}
}
@inbook{Kotenko_Doynikova_2014b,
	title        = {Security Assessment of Computer Networks Based on Attack Graphs and Security Events},
	author       = {Kotenko, Igor and Doynikova, Elena},
	year         = 2014,
	booktitle    = {Information and Communication Technology},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 8407,
	pages        = {462–471},
	doi          = {10.1007/978-3-642-55032-4_47},
	isbn         = {978-3-642-55031-7},
	url          = {http://link.springer.com/10.1007/978-3-642-55032-4_47},
	place        = {Berlin, Heidelberg},
	abstractnote = {Security assessment is an important task for operation of modern computer networks. The paper suggests the security assessment technique based on attack graphs which can be implemented in contemporary SIEM systems. It is based on the security metrics taxonomy and different techniques for calculation of security metrics according to the data about current events. Proposed metrics form the basis for security awareness and reflect current security situation, including development of attacks, attacks sources and targets, attackers’ characteristics. The technique suggested is demonstrated on a case study.},
	editor       = {Linawati and Mahendra, Made Sudiana and Neuhold, Erich J. and Tjoa, A Min and You, IlsunEditors}
}
@inproceedings{Kotenko_Polubelova_Saenko_Doynikova_2013,
	title        = {The Ontology of Metrics for Security Evaluation and Decision Support in SIEM Systems},
	author       = {Kotenko, Igor and Polubelova, Olga and Saenko, Igor and Doynikova, Elena},
	year         = 2013,
	month        = sep,
	pages        = {638–645},
	doi          = {10.1109/ARES.2013.84},
	abstractnote = {Analysis of computer network security is a serious challenge. Many security metrics has been proposed for this purpose, but their effective use for rapid and reliable security evaluation and generation of countermeasures in SIEM systems remains an important problem. The use of ontologies for security information representation in SIEM systems contributes largely to the success of this task. However, most of works on ontological security data representation does not take into account the ontologies of security metrics. This paper proposes a new approach on using security metrics which is based on their ontological representation and serves for comprehensive security evaluation and subsequent countermeasure generation. The novelty of the proposed approach is that ontology of security metrics is viewed as a core component of a countermeasure decision support system. The proposed solutions are tested on a specific example.}
}
@article{Latora_Marchiori_2005,
	title        = {Vulnerability and Protection of Critical Infrastructures},
	author       = {Latora, Vito and Marchiori, Massimo},
	year         = 2005,
	month        = jan,
	journal      = {Physical Review E},
	volume       = 71,
	number       = 1,
	pages        = {015103},
	doi          = {10.1103/PhysRevE.71.015103},
	issn         = {1539-3755, 1550-2376},
	note         = {arXiv: cond-mat/0407491},
	abstractnote = {Critical infrastructure networks are a key ingredient of modern society. We discuss a general method to spot the critical components of a critical infrastructure network, i.e. the nodes and the links fundamental to the perfect functioning of the network. Such nodes, and not the most connected ones, are the targets to protect from terrorist attacks. The method, used as an improvement analysis, can also help to better shape a planned expansion of the network.}
}
@book{Mahalingam_Abdollah_Sahib_2014,
	title        = {Learner Centric in M-Learning: Integration of Security, Dependability and Trust.},
	author       = {Mahalingam, Sheila and Abdollah, Faizal Mohd and Sahib, Shahrin},
	year         = 2014,
	publisher    = {ERIC}
}
@article{Mir_2013,
	title        = {Modeling of Security Measurement Metrics in an Information System},
	author       = {Mir, Irshad Ahmad},
	year         = 2013
}
@article{Azuwa_Ahmad_Sahib_2012,
	title        = {Technical security metrics model in compliance with ISO/IEC 27001 standard},
	author       = {MP Azuwa, Azuwa and Ahmad, Rabiah and Sahib, Sharin},
	year         = 2012,
	journal      = {International Journal of Cyber-Security and Digital Forensics},
	volume       = 1,
	pages        = {280–288}
}
@article{Oltramari_Henshel_Cains_Hoffman,
	title        = {Towards a Human Factors Ontology for Cyber Security},
	author       = {Oltramari, Alessandro and Henshel, Diane and Cains, Mariana and Hoffman, Blaine},
	pages        = 8,
	abstractnote = {Traditional cybersecurity risk assessment is reactive and based on business risk assessment approach. The 2014 NIST Cybersecurity Framework provides businesses with an organizational tool to catalog cybersecurity efforts and areas that need additional support. As part of an on-going effort to develop a holistic, predictive cyber security risk assessment model, the characterization of human factors, which includes human behavior, is needed to understand how the actions of users, defenders (IT personnel), and attackers affect cybersecurity risk. Trust has been found to be a crucial element affecting an individual’s role within a cyber system. The use of trust as a human factor in holistic cybersecurity risk assessment relies on an understanding how differing mental models, risk postures, and social biases impact the level trust given to an individual and the biases affecting the ability to give said trust. The Human Factors Ontology illustrates the individual characteristics, situational characteristics, and relationships that influence the trust given to an individual. Furthering the incorporation of ontologies into the science of cybersecurity will help decision-makers build the foundation needed for predictive and quantitative risk assessments.}
}
@article{Payne_2007,
	title        = {A Guide to Security Metrics},
	author       = {Payne, Shirley},
	year         = 2007,
	pages        = 11
}
@article{Pendleton_Garcia-Lebron_Cho_Xu_2016,
	title        = {A Survey on Systems Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Cho, Jin-Hee and Xu, Shouhuai},
	year         = 2016,
	month        = 12,
	journal      = {ACM Computing Surveys},
	volume       = 49,
	number       = 4,
	pages        = {1–35},
	doi          = {10.1145/3005714},
	issn         = {03600300}
}
@article{Pendleton_Garcia-Lebron_Xu_2016,
	title        = {A Survey on Security Metrics},
	author       = {Pendleton, Marcus and Garcia-Lebron, Richard and Xu, Shouhuai},
	year         = 2016,
	month        = jan,
	journal      = {arXiv:1601.05792 [cs]},
	url          = {http://arxiv.org/abs/1601.05792},
	note         = {arXiv: 1601.05792},
	abstractnote = {The importance of security metrics can hardly be overstated. Despite the attention that has been paid by the academia, government and industry in the past decades, this important problem stubbornly remains open. In this survey, we present a survey of knowledge on security metrics. The survey is centered on a novel taxonomy, which classifies security metrics into four categories: metrics for measuring the system vulnerabilities, metrics for measuring the defenses, metrics for measuring the threats, and metrics for measuring the situations. The insight underlying the taxonomy is that situations (or outcomes of cyber attack-defense interactions) are caused by certain threats (or attacks) against systems that have certain vulnerabilities (including human factors) and employ certain defenses. In addition to systematically reviewing the security metrics that have been proposed in the literature, we discuss the gaps between the state of the art and the ultimate goals.}
}
@article{Ramos_Lazar_Filho_Rodrigues_2017,
	title        = {Model-Based Quantitative Network Security Metrics: A Survey},
	author       = {Ramos, Alex and Lazar, Marcella and Filho, Raimir Holanda and Rodrigues, Joel J. P. C.},
	year         = 2017,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 19,
	number       = 4,
	pages        = {2704–2734},
	doi          = {10.1109/COMST.2017.2745505},
	issn         = {2373-745X},
	abstractnote = {Network security metrics (NSMs) based on models allow to quantitatively evaluate the overall resilience of networked systems against attacks. For that reason, such metrics are of great importance to the security-related decision-making process of organizations. Considering that over the past two decades several model-based quantitative NSMs have been proposed, this paper presents a deep survey of the state-of-the-art of these proposals. First, to distinguish the security metrics described in this survey from other types of security metrics, an overview of security metrics, in general, and their classifications is presented. Then, a detailed review of the main existing model-based quantitative NSMs is provided, along with their advantages and disadvantages. Finally, this survey is concluded with an in-depth discussion on relevant characteristics of the surveyed proposals and open research issues of the topic.}
}
@book{Swanson_Bartol_Sabato_Hash_Graffo_2003,
	title        = {Security metrics guide for information technology systems},
	author       = {Swanson, M and Bartol, N and Sabato, J and Hash, J and Graffo, L},
	year         = 2003,
	number       = {NIST SP 800-55},
	pages        = {NIST SP 800--55},
	doi          = {10.6028/NIST.SP.800-55},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-55.pdf},
	place        = {Gaithersburg, MD},
	institution  = {National Institute of Standards and Technology}
}
@article{Tariq_2012,
	title        = {Towards information security metrics framework for cloud computing},
	author       = {Tariq, Muhammad Imran},
	year         = 2012,
	journal      = {International Journal of Cloud Computing and Services Science},
	volume       = 1,
	number       = 4,
	pages        = 209
}
@inproceedings{Verendel_2009,
	title        = {Quantified security is a weak hypothesis: a critical survey of results and assumptions},
	author       = {Verendel, Vilhelm},
	year         = 2009,
	booktitle    = {Proceedings of the 2009 workshop on New security paradigms workshop - NSPW ’09},
	publisher    = {ACM Press},
	pages        = 37,
	doi          = {10.1145/1719030.1719036},
	isbn         = {978-1-60558-845-2},
	url          = {http://portal.acm.org/citation.cfm?doid=1719030.1719036},
	place        = {Oxford, United Kingdom},
	abstractnote = {This paper critically surveys previous work on quantitative representation and analysis of security. Such quantiﬁed security has been presented as a general approach to precisely assess and control security. We classify a signiﬁcant part of the work between 1981 and 2008 with respect to security perspective, target of quantiﬁcation, underlying assumptions and type of validation. The result shows how the validity of most methods is still strikingly unclear. Despite applying a number of techniques from ﬁelds such as computer science, economics and reliability theory to the problem it is unclear what valid results exist with respect to operational security. Quantiﬁed security is thus a weak hypothesis because a lack of validation and comparison between such methods against empirical data. Furthermore, many assumptions in formal treatments are not empirically well-supported in operational security and have been adopted from other ﬁelds. A number of risks are present with depending on quantitative methods with limited or no validation.}
}
@article{attacktrees.pdf,
	url          = {http://tnlandforms.us/cs594-cns96/attacktrees.pdf}
}
@article{SEv2-c21.pdf,
	url          = {https://www.cl.cam.ac.uk/~rja14/Papers/SEv2-c21.pdf}
}
@book{Mell_Scarfone_Romanosky_2007,
	title        = {The common vulnerability scoring system (CVSS) and its applicability to federal agency systems},
	author       = {Mell, Peter and Scarfone, Karen and Romanosky, Sasha},
	year         = 2007,
	number       = {NIST IR 7435},
	pages        = {NIST IR 7435},
	doi          = {10.6028/NIST.IR.7435},
	url          = {https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nistir7435.pdf},
	place        = {Gaithersburg, MD},
	abstractnote = {The Common Vulnerability Scoring System (CVSS) provides an open framework for communicating the characteristics and impacts of IT vulnerabilities. The National Vulnerability Database (NVD) provides specific CVSS scores for publicly known vulnerabilities. Federal agencies can use the Federal Information Processing Standards (FIPS) 199 security categories with the NVD CVSS scores to obtain impact scores that are tailored to each agency’s environment. CVSS consists of three groups: Base, Temporal and Environmental. Each group produces a numeric score ranging from 0.0 to 10.0, and a vector, a compressed textual representation that reflects the values used to derive the score. The Base group represents the intrinsic qualities of a vulnerability. The Temporal group reflects the characteristics of a vulnerability that change over time. The Environmental group represents the characteristics of a vulnerability that are unique to any user’s environment. CVSS enables IT managers, vulnerability bulletin providers, security vendors, application vendors and researchers to all benefit by adopting this common language of scoring IT vulnerabilities.},
	institution  = {National Institute of Standards and Technology}
}
@article{Almasizadeh_Azgomi_2013,
	title        = {A stochastic model of attack process for the evaluation of security metrics},
	author       = {Almasizadeh, Jaafar and Azgomi, Mohammad Abdollahi},
	year         = 2013,
	month        = jul,
	journal      = {Computer Networks},
	series       = {Towards a Science of Cyber Security},
	volume       = 57,
	number       = 10,
	pages        = {2159–2180},
	doi          = {10.1016/j.comnet.2013.03.011},
	issn         = {1389-1286},
	abstractnote = {To trust a computer system that is supposed to be secure, it is necessary to predict the degree to which the system’s security level can be achieved when operating in a specific environment under cyber attacks. In this paper, we propose a state-based stochastic model for obtaining quantitative security metrics representing the level of a system’s security. The main focus of the study is on how to model the progression of an attack process over time. The basic assumption of our model is that the time parameter plays the essential role in capturing the nature of an attack process. In practice, the attack process will terminate successfully, possibly after a number of unsuccessful attempts. What is important is, indeed, the estimation of how long it takes to be conducted. The proposed stochastic model is parameterized based on a suitable definition of time distributions describing attacker’s actions and system’s reactions over time. For this purpose, probability distribution functions are defined and assigned to transitions of the model for characterizing the temporal aspects of the attacker and system behavior. With the definition of the distributions, the stochastic model will be recognized to be a semi-Markov chain. This mathematical model will be analytically solved to calculate the desirable quantitative security metrics, such as mean time to security failure and steady-state security. The proposed method shows a systematic development of the stochastic modeling techniques and concepts, used frequently in the area of dependability evaluation, for attack process modeling. Like any other modeling method, the proposed model is also constructed based on some underlying assumptions, which are specific to the context of security analysis.},
	collection   = {Towards a Science of Cyber Security}
}
@inbook{McQueen_Boyer_Flynn_Beitel_2006,
	title        = {Time-to-compromise model for cyber risk reduction estimation},
	author       = {McQueen, Miles A. and Boyer, Wayne F. and Flynn, Mark A. and Beitel, George A.},
	year         = 2006,
	booktitle    = {Quality of Protection},
	publisher    = {Springer},
	pages        = {49–64}
}
@article{Jha_Sheyner_Wing,
	title        = {Minimization and Reliability Analyses of Attack Graphs},
	author       = {Jha, Somesh and Sheyner, Oleg and Wing, Jeannette M},
	pages        = 31
}
@inproceedings{Kanoun_Cuppens_Boulahia_Cuppens_Dubus_Martin_2009,
	title        = {Success Likelihood of Ongoing Attacks for Intrusion Detection and Response Systems},
	author       = {Kanoun, Wael and Cuppens-Boulahia, Nora and Cuppens, Frédéric and Dubus, Samuel and Martin, Antony},
	year         = 2009,
	month        = aug,
	booktitle    = {2009 International Conference on Computational Science and Engineering},
	volume       = 3,
	pages        = {83–91},
	doi          = {10.1109/CSE.2009.233},
	issn         = {null},
	abstractnote = {Intrusion Detection and Response Systems have become a core component in modern security architectures. Current researches are combining intrusion detection and response systems with risk analysis or cost-sensitive approaches to enhance the detection and the response procedure, by assessing the risk of detected attacks and candidate countermeasures. The Risk has two primary dimensions: (i) the likelihood of success of the attack(s), and (ii) the impact of the attack(s) and the countermeasure(s).In this paper, we present a model to assess the success likelihood of attack objectives. This model can be used by intrusion detection and response systems to identify candidate ongoing scenarios, calculate dynamically the likelihood of success for each of them considering the progress of the attack and the state of the target system, and finally prioritize candidate intrusion objectives and associated countermeasures.}
}
@article{Li_Parker_Xu_2011,
	title        = {A Stochastic Model for Quantitative Security Analyses of Networked Systems},
	author       = {Li, Xiaohu and Parker, Paul and Xu, Shouhuai},
	year         = 2011,
	month        = mar,
	journal      = {IEEE Transactions on Dependable and Secure Computing; Washington},
	volume       = 8,
	number       = 1,
	pages        = {28–43},
	doi          = {http://dx.doi.org/10.1109/TDSC.2008.75},
	issn         = 15455971,
	abstractnote = {Traditional security analyses are often geared toward cryptographic primitives or protocols. Although such analyses are necessary, they cannot address a defender’s need for insight into which aspects of a networked system having a significant impact on its security, and how to tune its configurations or parameters so as to improve security. This question is known to be notoriously difficult to answer, and the state of the art is that we know little about it. Toward ultimately addressing this question, this paper presents a stochastic model for quantifying security of networked systems. The resulting model captures two aspects of a networked system: 1. the strength of deployed security mechanisms such as intrusion detection systems and 2. the underlying vulnerability graph, which reflects how attacks may proceed. The resulting model brings the following insights: 1. How should a defender tune system configurations (e.g., network topology) so as to improve security? 2).How should a defender “tune” system parameters (e.g., by upgrading which security mechanisms) so as to improve security? 3. Under what conditions is the steady-state number of compromised entities of interest below a given threshold with a high probability? Simulation studies are conducted to confirm the analytic results, and to show the tightness of the bounds of certain important metric that cannot be resolved analytically.}
}
@inproceedings{Anderson_Moore_2007,
	title        = {The economics of information security: A survey and open questions},
	author       = {Anderson, Ross and Moore, Tyler},
	year         = 2007,
	booktitle    = {Fourth bi-annual Conference on the Economics of the Software and Internet Industries},
	pages        = {19–20}
}
@book{Morris_2001,
	title        = {Measurement and instrumentation principles},
	author       = {Morris, Alan S.},
	year         = 2001,
	publisher    = {Butterworth-Heinemann},
	isbn         = {978-0-7506-5081-6},
	place        = {Oxford [England] ; Boston}
}
@article{Debievre_2009,
	title        = {The 2007 International Vocabulary of Metrology (VIM), JCGM 200:2008 [ISO/IEC Guide 99]: Meeting the need for intercontinentally understood concepts and their associated intercontinentally agreed terms},
	author       = {De Bièvre, Paul},
	year         = 2009,
	month        = mar,
	journal      = {Clinical Biochemistry},
	series       = {Highlight Section: Quality \& Accreditation in Laboratory Medicine},
	volume       = 42,
	number       = 4,
	pages        = {246–248},
	doi          = {10.1016/j.clinbiochem.2008.09.007},
	issn         = {0009-9120},
	abstractnote = {Unambiguous and consistent concepts and terms such as measurand, metrological traceability, measurement uncertainty, comparability of measurement results, target measurement uncertainty, etc., must govern the description of measurements in order to enable a valid comparison of measurement results. That is not yet the case as numerous workshops over the last decade have shown worldwide and as chemical literature continuously displays. For international trade in food and feed to be fair, for border-crossing implementation of environmental regulations to be the same for all parties concerned, for interchangeability of results of clinical measurements to become a reality, for any border-crossing interpretation of measurement results in chemistry to become possible, well understood and mutually accepted, common and well defined concepts and terms are essential. Similarly, their translations from one language – English – to 30–40 other languages, must be realized and fixed unequivocally. Countries using English as common language have not yet fully realized that they are at a considerable advantage over countries where such translated terms describing concepts may not yet be available, let alone understood and accepted. A number of ambiguities in the definitions and terms are described which illustrate the importance of the revision (1997–2007) of the International Vocabulary of Metrology (VIM), henceforth conveniently called “VIM3”, especially since chemical measurement is covered in this VIM for the first time in history:‘measurand’‘metrological comparability of measurement results’‘metrology’‘metrological compatibility of measurement results’‘measurement result’‘metrological traceability’ (incl ‘to the SI’)‘measurement uncertainty’‘target measurement uncertainty’‘calibration hierarchy’‘quantity’and many others. It is concluded that the revised VIM is of primordial importance for good understanding within and between the measurement communities worldwide.},
	collection   = {Highlight Section: Quality & Accreditation in Laboratory Medicine}
}
@article{Schneider,
	title        = {Blueprint for a Science of Cybersecurity},
	author       = {Schneider, Fred B},
	pages        = 17
}
@inbook{Kott_2014,
	title        = {Towards fundamental science of cyber security},
	author       = {Kott, Alexander},
	year         = 2014,
	booktitle    = {Network science and cybersecurity},
	publisher    = {Springer},
	pages        = {1–13}
}
@inproceedings{Spring_Moore_Pym_2017,
	title        = {Practicing a Science of Security: A Philosophy of Science Perspective},
	author       = {Spring, Jonathan M. and Moore, Tyler and Pym, David},
	year         = 2017,
	booktitle    = {Proceedings of the 2017 New Security Paradigms Workshop on ZZZ - NSPW 2017},
	publisher    = {ACM Press},
	pages        = {1–18},
	doi          = {10.1145/3171533.3171540},
	isbn         = {978-1-4503-6384-6},
	url          = {http://dl.acm.org/citation.cfm?doid=3171533.3171540},
	place        = {Santa Cruz, CA, USA},
	abstractnote = {Our goal is to refocus the question about cybersecurity research from ‘is this process scienti c’ to ‘why is this scienti c process producing unsatisfactory results’. We focus on ve common complaints that claim cybersecurity is not or cannot be scienti c. Many of these complaints presume views associated with the philosophical school known as Logical Empiricism that more recent scholarship has largely modi ed or rejected. Modern philosophy of science, supported by mathematical modeling methods, provides constructive resources to mitigate all purported challenges to a science of security. Therefore, we argue the community currently practices a science of cybersecurity. A philosophy of science perspective suggests the following form of practice: structured observation to seek intelligible explanations of phenomena, evaluating explanations in many ways, with specialized elds (including engineering and forensics) constraining explanations within their own expertise, intertranslating where necessary. A natural question to pursue in future work is how collecting, evaluating, and analyzing evidence for such explanations is di erent in security than other sciences.}
}
@article{Evans_2008,
	title        = {NSF/IARPA/NSA Workshop on the Science of Security},
	author       = {Evans, D.},
	year         = 2008,
	journal      = {Also see http://sos. cs. virginia. edu/., University of Virginia}
}
@article{Yamin_Katt_Gkioulos_2020,
	title        = {Cyber ranges and security testbeds: Scenarios, functions, tools and architecture},
	author       = {Yamin, Muhammad Mudassar and Katt, Basel and Gkioulos, Vasileios},
	year         = 2020,
	month        = jan,
	journal      = {Computers \& Security},
	volume       = 88,
	pages        = 101636,
	doi          = {10.1016/j.cose.2019.101636},
	issn         = {0167-4048},
	abstractnote = {The first line of defense against cyber threats and cyber crimes is to be aware and get ready, e.g., through cyber security training. Training can have two forms, the first is directed towards security professionals and aims at improving understanding of the latest threats and increasing skill levels in defending and mitigating against them. The second form of training, which used to attract less attention, aims at increasing cyber security awareness among non-security professionals and the general public. Conducting such training programs requires dedicated testbeds and infrastructures that help realizing and executing the training scenarios and provide a playground for the trainees. A cyber range is an environment that aims at providing such testbeds. The purpose of this paper is to study the concept of a cyber range, and provide a systematic literature review that covers unclassified cyber ranges and security testbeds. In this study we develop a taxonomy for cyber range systems and evaluate the current literature focusing on architecture and scenarios, but including also capabilities, roles, tools and evaluation criteria. The results of this study can be used as a baseline for future initiatives towards the development and evaluation of cyber ranges in accordance with existing best practices and lessons learned from contemporary research and developments.}
}
@article{Sonmez_2019,
	title        = {A Conceptual Model for a Metric Based Framework for the Monitoring of Information Security Tasks’ Efficiency},
	author       = {Sönmez, Ferda Özdemir},
	year         = 2019,
	journal      = {Procedia Computer Science},
	volume       = 160,
	pages        = {181–188},
	doi          = {10.1016/j.procs.2019.09.459},
	issn         = 18770509,
	abstractnote = {Abstract Information Security Governance Systems are not adequate to measure the effectiveness and efficiency of security tIansfkosrmfoartitohne SenecteurrpitryiseGso. vAelrtnhaonucgehSsyosmteemosf athre nsyostteamdesqoufafteertwo amyseafsourrme tehaesuerfefmecetnivt,entheesys satnildl nefefeidciethnecydeoffinsieticounriotyf mtasekasufroermtheentenotbejrepcrtiisveess. Aanltdhomugehtriscosm. Tehoifs thsteusdyystpermops oosfefserawcaoynscfeoprtumaelafsruarmemewenotr,kthmeyodsetillwnheiecdh thaesdhefuimniatinonanodf tmooeal/spurroecmesesntreolabtjedctimvestriacns.d Tmhiestrsicyss.teTmhiaslssotuadlylowprsopthoesecsolaleccotinocnepotfuaelvifdreanmceewdoartka mfoor dseecwurhitiych-rehlastedhutmasakns and twoaoyl/sprtocmesostirvealatetetdhemseetcriucrsi.tyTshtiasffsytostepmrovaildsoe allmoworse tphreodcuolclteivcteioennvoifroenvmideenntc.eTdhaistasyfosrtesmecmuraityyb-reelaptepdlietadsktos aannyd swizaeysoftoenmteortpivriaste itnhdeespeecnudreitnyt sotfaiftfstboupsrinoevsidsedoammaoinreoprrfoudnucctitoivnes eansvliornognmasentht.eTahimis issytsoteimmpmroavyebteheapepfflieecdtivtoenaensys asinzde eofffiecnietenrcpyriosfe siencduerpiteyn-drenlatteodf ittasskbsu.siness domain or functions as long as the aim is to improve the effectiveness and efficiency of security-related tasks.}
}
@article{Hutchins_Cloppert_Amin,
	title        = {Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains},
	author       = {Hutchins, Eric M and Cloppert, Michael J and Amin, Rohan M},
	pages        = 14,
	abstractnote = {Conventional network defense tools such as intrusion detection systems and anti-virus focus on the vulnerability component of risk, and traditional incident response methodology presupposes a successful intrusion. An evolution in the goals and sophistication of computer network intrusions has rendered these approaches insuﬃcient for certain actors. A new class of threats, appropriately dubbed the “Advanced Persistent Threat” (APT), represents well-resourced and trained adversaries that conduct multi-year intrusion campaigns targeting highly sensitive economic, proprietary, or national security information. These adversaries accomplish their goals using advanced tools and techniques designed to defeat most conventional computer network defense mechanisms. Network defense techniques which leverage knowledge about these adversaries can create an intelligence feedback loop, enabling defenders to establish a state of information superiority which decreases the adversary’s likelihood of success with each subsequent intrusion attempt. Using a kill chain model to describe phases of intrusions, mapping adversary kill chain indicators to defender courses of action, identifying patterns that link individual intrusions into broader campaigns, and understanding the iterative nature of intelligence gathering form the basis of intelligence-driven computer network defense (CND). Institutionalization of this approach reduces the likelihood of adversary success, informs network defense investment and resource prioritization, and yields relevant metrics of performance and eﬀectiveness. The evolution of advanced persistent threats necessitates an intelligence-based model because in this model the defenders mitigate not just vulnerability, but the threat component of risk, too.}
}
@inproceedings{Haque_Keffeler_Atkison_2017,
	title        = {An Evolutionary Approach of Attack Graphs and Attack Trees: A Survey of Attack Modeling},
	author       = {Haque, S. and Keffeler, M. and Atkison, T.},
	year         = 2017,
	booktitle    = {Proceedings of the International Conference on Security and Management (SAM); Athens},
	publisher    = {The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp)},
	pages        = {224–229},
	url          = {https://search.proquest.com/docview/2139471619/abstract/7169E9EF244F4076PQ/1},
	place        = {Athens, United States, Athens},
	abstractnote = {The advancement of modern day computing has led to an increase of threats and intrusions. As a result, advanced security measures and threat analysis models are necessary to detect these threats and identify protective measures needed to secure a system. The most popular forms of attack modeling today are attack graphs and attack trees. This literature summarizes the different approaches through an extensive survey of the relevant papers and identifies the current challenges, requirements and limitations of efficient attack modeling.}
}
@inproceedings{Kundu_Ghosh_Chokshi_Ghosh_2012,
	title        = {Analysis of attack graph-based metrics for quantification of network security},
	author       = {Kundu, A. and Ghosh, N. and Chokshi, I. and Ghosh, S. K.},
	year         = 2012,
	month        = dec,
	booktitle    = {2012 Annual IEEE India Conference (INDICON)},
	pages        = {530–535},
	doi          = {10.1109/INDCON.2012.6420675},
	abstractnote = {Computer network has grown both in size and complexity with the advent of Internet. It facilitates easy access to vast store of reference materials, collaborative computing, and information sharing. However, this requires a secure interconnected world of computing where confidentiality, integrity, and availability of information and resources are restored. Traditionally, security mechanism is enforced by access control and authentication. However, these security best practices do not take operating system, or network service-based or application vulnerabilities (programming flaws) into account. With the evolution of sophisticated hacking tools, attackers exploit these vulnerabilities and can gain legitimate access to network resources, bypassing the access control and authentication policies. One tool that presents a succinct representation of different attack scenarios specific to a network is attack graph. Attack graph models service or application-based attacks and depicts all possible multihost multi-step attack scenarios that an attacker can launch to penetrate into an enterprise network. The severity associated with each attack scenario can be evaluated following some attack graph-based security metrics. A good number of security metrics are prevalent in the literature, however, there exists no reported work which determines their efficacy and applicability. In this paper, a survey on attack graph-based metrics has been done and comparative analysis of the existing metrics has been presented to facilitate understanding of a given network’s level of security strength. A case study has been perceived for the purpose of analysis.}
}
@inbook{Bohme_Nowey_2008,
	title        = {Economic Security Metrics},
	author       = {Böhme, Rainer and Nowey, Thomas},
	year         = 2008,
	booktitle    = {Dependability Metrics},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 4909,
	pages        = {176–187},
	doi          = {10.1007/978-3-540-68947-8_15},
	isbn         = {978-3-540-68946-1},
	url          = {http://link.springer.com/10.1007/978-3-540-68947-8_15},
	place        = {Berlin, Heidelberg},
	abstractnote = {This chapter surveys economic approaches for security metrics, among which we could identify two main areas of research. One has its roots in investment and decision theory and is mainly pursued in the ﬁeld of information technology-oriented business administration. It has yielded a number of quantitative metrics that can be applied as guidelines in investment decisions as well as for the evaluation of existing security measures. The second area of research has ancestors in micro-economics. It deals with market concepts to gather security-relevant information and extract quantitative indicators on information security properties.},
	editor       = {Eusgeld, Irene and Freiling, Felix C. and Reussner, RalfEditors}
}
@inproceedings{Hecker_2008,
	title        = {On System Security Metrics and the Definition Approaches},
	author       = {Hecker, Artur},
	year         = 2008,
	month        = aug,
	booktitle    = {2008 Second International Conference on Emerging Security Information, Systems and Technologies},
	pages        = {412–419},
	doi          = {10.1109/SECURWARE.2008.37},
	issn         = {2162-2116},
	abstractnote = {In this survey paper, we assess existing approaches to security metric definition. We classify proposed definitions and discuss their advantages and problems. We argue that without a more restrictive definition, the apparently common term degenerates to a mere buzzword, which can be dangerous in terms of suggested comparability. We conclude with some guidelines on IS metric definition and sketch an alternative concept for the operational IS security evaluation.}
}
@article{Savola_2013,
	title        = {Quality of security metrics and measurements},
	author       = {Savola, Reijo M.},
	year         = 2013,
	month        = {09},
	journal      = {Computers \& Security},
	volume       = 37,
	pages        = {78–90},
	doi          = {10.1016/j.cose.2013.05.002},
	issn         = {0167-4048},
	abstractnote = {Quantification of information security can be used to obtain evidence to support decision-making about the security performance of software systems. Knowledge about the relational importance of the main quality criteria of security metrics can help build security metrology models based on practical needs. This paper presents the results of a quantitative security metrics expert survey of 141 respondents, and an associated interview study, regarding the prioritization of 19 quality criteria of security metrics identified in the literature. The interviews were used to validate the survey results and to obtain further information on the findings. The results identified three foundational quality criteria of security metrics: correctness, measurability, and meaningfulness. These criteria form the basis for credibility and sufficiency for security metrics and associated measurements. Moreover, usability was seen as an important criterion. The paper analyzes the foundational and related quality criteria and proposes a model of them.}
}
@article{Rudolph_Schwarz_2012,
	title        = {Security indicators–a state of the art survey public report},
	author       = {Rudolph, Manuel and Schwarz, Reinhard},
	year         = 2012,
	journal      = {FhG IESE VII (043)}
}
@inproceedings{survey_2013,
	year         = 2013,
	booktitle    = {Proceedings of the 10th International Conference on Security and Cryptography},
	publisher    = {SCITEPRESS - Science and and Technology Publications},
	pages        = {543–548},
	doi          = {10.5220/0004530905430548},
	isbn         = {978-989-8565-73-0},
	url          = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0004530905430548},
	place        = {Reykjavík, Iceland}
}
@article{Wagner_Eckhoff_2018,
	title        = {Technical Privacy Metrics: A Systematic Survey},
	author       = {Wagner, Isabel and Eckhoff, David},
	year         = 2018,
	month        = {06},
	journal      = {ACM Computing Surveys},
	volume       = 51,
	number       = 3,
	pages        = {1–38},
	doi          = {10.1145/3168389},
	issn         = {03600300}
}
@article{Tavallaee_Stakhanova_Ghorbani_2010,
	title        = {Toward Credible Evaluation of Anomaly-Based Intrusion-Detection Methods},
	author       = {Tavallaee, Mahbod and Stakhanova, Natalia and Ghorbani, Ali Akbar},
	year         = 2010,
	month        = {09},
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume       = 40,
	number       = 5,
	pages        = {516–524},
	doi          = {10.1109/TSMCC.2010.2048428},
	issn         = {1094-6977, 1558-2442},
	abstractnote = {Since the ﬁrst introduction of anomaly-based intrusion detection to the research community in 1987, the ﬁeld has grown tremendously. A variety of methods and techniques introducing new capabilities in detecting novel attacks were developed. Most of these techniques report a high detection rate of 98\% at the low false alarm rate of 1\%. In spite of the anomaly-based approach’s appeal, the industry generally favors signature-based detection for mainstream implementation of intrusion-detection systems. While a variety of anomaly-detection techniques have been proposed, adequate comparison of these methods’ strengths and limitations that can lead to potential commercial application is difﬁcult. Since the validity of experimental research in academic computer science, in general, is questionable, it is plausible to assume that research in anomaly detection shares the above problem. The concerns about the validity of these methods may partially explain why anomaly-based intrusion-detection methods are not adopted by industry. To investigate this issue, we review the current state of the experimental practice in the area of anomaly-based intrusion detection and survey 276 studies in this area published during the period of 2000–2008. We summarize our observations and identify the common pitfalls among surveyed works.}
}
@inproceedings{Savola_2007,
	title        = {Towards a Security Metrics Taxonomy for the Information and Communication Technology Industry},
	author       = {Savola, Reijo},
	year         = 2007,
	month        = {08},
	booktitle    = {International Conference on Software Engineering Advances (ICSEA 2007)},
	pages        = {60–60},
	doi          = {10.1109/ICSEA.2007.79},
	issn         = {null},
	abstractnote = {To obtain evidence of the security of different products or organizations, systematic approaches to measuring security are needed. We introduce a high abstraction level taxonomy to support the development of feasible security metrics, along with a survey of the emerging security metrics from the academic, governmental and industrial perspectives. With our taxonomy, we strive to bridge the gap between information security management and ICT products, and services security engineering. We believe that if common metrics approaches between different security disciplines can be found, this will advance our holistic understanding and capabilities, both in security management and engineering. Our taxonomy is based on comparing earlier taxonomy approaches and analyzing types of security metrics. Based on the survey, a discussion of future research directions is given in order to prompt advances in the field.}
}

 @inproceedings{Vaughn_Henning_Siraj_2003, place={Big Island, HI, USA}, title={Information assurance measures and metrics - state of practice and proposed taxonomy}, ISBN={978-0-7695-1874-9}, url={http://ieeexplore.ieee.org/document/1174904/}, DOI={10.1109/HICSS.2003.1174904}, abstractNote={The term “ assurance” has been used for decades in trusted system development as an expression of confidence that one has in the strength of mechanisms or countermeasures. One of the unsolved problems of security engineering is the adoption of measures or metrics that can reliably depict the assurance associated with a specific hardware and software system. This paper reports on a recent attempt to focus requirements in this area by examining those currently in use. It then suggests a categorization of Information Assurance (IA) metrics that may be tailored to an organization’s needs1. We believe that the provision of security mechanisms in systems is a subset of the systems engineering discipline having a large software-engineering correlation. There is general agreement that no single system metric or any “one-prefect” set of IA metrics applies across all systems or audiences. The set most useful for an organization largely depends on their IA goals, their technical, organizational and operational needs, and the financial, personnel, and technical resources that are available.}, note={tex.ids: vaughn2003a
tex.citation-number: 14}, booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, publisher={IEEE}, author={Vaughn, R.B. and Henning, R. and Siraj, A.}, year={2003}, pages={10 pp.} }

@inproceedings{Rostami_2013,
	title        = {Hardware security: Threat models and metrics},
	author       = {Rostami, M. and Koushanfar, F. and Rajendran, J. and Karri, R.},
	year         = 2013,
	booktitle    = {Proc. Int. Conf},
	publisher    = {Computer Aided Design},
	pages        = {819–823},
	note         = {Citation Key: rostami2013a tex.citation-number: 13}
}

@article{Rostami_Koushanfar_Karri_2014,
	title        = {A Primer on Hardware Security: Models, Methods, and Metrics},
	author       = {Rostami, Masoud and Koushanfar, Farinaz and Karri, Ramesh},
	year         = 2014,
	month        = aug,
	journal      = {Proceedings of the IEEE},
	volume       = 102,
	number       = 8,
	pages        = {1283–1295},
	doi          = {10.1109/JPROC.2014.2335155},
	issn         = {1558-2256},
	note         = {tex.ids: rostamiPrimerHardwareSecurity2014a},
	abstractnote = {The multinational, distributed, and multistep nature of integrated circuit (IC) production supply chain has introduced hardware-based vulnerabilities. Existing literature in hardware security assumes ad hoc threat models, defenses, and metrics for evaluation, making it difficult to analyze and compare alternate solutions. This paper systematizes the current knowledge in this emerging field, including a classification of threat models, state-of-the-art defenses, and evaluation metrics for important hardware-based attacks.}