@inbook{Ahmed_Al-Shaer_Khan_2008,
	title        = {A novel quantitative approach for measuring network security},
	author       = {Ahmed, M. and Al-Shaer, E. and Khan, L.},
	year         = 2008,
	booktitle    = {IEEE INFOCOM'2008.Google scholar},
	note         = {Citation Key: ahmed2008a}
}
@article{Al-Shaer_Khan_Ahmed_2008,
	title        = {A comprehensive objective network security metric framework for proactive security configuration},
	author       = {Al-Shaer, E. and Khan, L. and Ahmed, M.},
	year         = 2008,
	journal      = {Proc. CSIIRW'08},
	volume       = 42,
	number       = 1,
	note         = {Citation Key: al-shaer2008a tex.address: Google Scholar}
}
@inproceedings{Albanese_Jajodia_Noel_2012,
	title        = {Time-efficient and cost-effective network hardening using attack graphs},
	author       = {Albanese, M. and Jajodia, S. and Noel, S.},
	year         = 2012,
	booktitle    = {Proc. IEEE},
	volume       = {DSN'12},
	pages        = {1–12},
	note         = {Citation Key: albanese2012a}
}
@article{Albert_Barabasi_2002,
	title        = {Statistical mechanics of complex networks},
	author       = {Albert, R. and Barabasi, A.},
	year         = 2002,
	journal      = {Rev. Mod. Phys},
	volume       = 74,
	note         = {Citation Key: albert2002a}
}
@inproceedings{Ammann_Wijesekera_Kaushik_2002,
	title        = {Scalable, graph-based network vulnerability analysis},
	author       = {Ammann, P. and Wijesekera, D. and Kaushik, S.},
	year         = 2002,
	booktitle    = {Proc. ACM},
	volume       = {CCS'02},
	pages        = {217–224},
	note         = {Citation Key: ammann2002a tex.citation-number: 91}
}
@inproceedings{Axelsson_2009,
	title        = {The base-rate fallacy and its implications for the difficulty of intrusion detection},
	author       = {Axelsson, S.},
	year         = 2009,
	booktitle    = {Proc. ACM CCS'09},
	pages        = {1–7},
	note         = {Citation Key: axelsson2009a}
}
@inproceedings{Backes_Nurnberger_2014,
	title        = {Oxymoron: Making fine-grained memory randomization practical by allowing code sharing},
	author       = {Backes, M. and N\"{u}rnberger, S.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {433–447},
	note         = {Citation Key: backes2014a}
}
@article{Berinato_2002,
	title        = {Finally, a real return on security spending},
	author       = {Berinato, S.},
	year         = 2002,
	url          = {http://www.cio.com/article/2440999/metrics/finally--a-real-return-on-security-spending.html.},
	note         = {Citation Key: berinato2002a}
}
@article{Biggio_Fumera_Roli_2014,
	title        = {Security evaluation of patternclassifiers under attack},
	author       = {Biggio, B. and Fumera, G. and Roli, F.},
	year         = 2014,
	journal      = {IEEE Trans. Knowl. Data Eng},
	volume       = {26, 4},
	pages        = {984–996},
	note         = {Citation Key: biggio2014a}
}
@inproceedings{Bilge_Dumitras_2012,
	title        = {Before we knew it: An empirical study of zero-day attacks in the real world},
	author       = {Bilge, L. and Dumitras, T.},
	year         = 2012,
	booktitle    = {Proc. ACM CCS'12},
	pages        = {833–844},
	note         = {Citation Key: bilge2012a tex.citation-number: 135}
}
@inproceedings{Boggs_Du_Stolfo_2014,
	title        = {Measuring drive-by download defense in depth},
	author       = {Boggs, N. and Du, S. and Stolfo, S.},
	year         = 2014,
	booktitle    = {Proc. RAID'14. 172–191.Google scholar},
	note         = {Citation Key: boggs2014a}
}
@inproceedings{Boggs_Stolfo_2011,
	title        = {ALDR: A new metric for measuring effective layering of defenses},
	author       = {Boggs, N. and Stolfo, S.},
	year         = 2011,
	booktitle    = {Proc. Layered assurance workshop (LAW'11},
	note         = {Citation Key: boggs2011a}
}
@article{Bohme_Freiling_2008,
	author       = {B\"{o}hme, R. and Freiling, F.},
	year         = 2008,
	note         = {Citation Key: boehme2008b}
}
@article{Bohme_Nowey_2008,
	title        = {Dependability metrics. Chapter Economic Security Metrics, 176–187.Google Scholar},
	author       = {B\"{o}hme, R. and Nowey, T.},
	year         = 2008,
	note         = {Citation Key: boehme2008a}
}
@inproceedings{Bonneau_2012a,
	title        = {Statistical metrics for individual password strength},
	author       = {Bonneau, J.},
	year         = 2012,
	booktitle    = {Proc. International conference on security protocols},
	pages        = {76–86},
	note         = {Citation Key: bonneau2012a}
}
@inproceedings{Bonneau_2012b,
	title        = {The science of guessing: Analyzing an anonymized corpus of 70 million passwords},
	author       = {Bonneau, J.},
	year         = 2012,
	booktitle    = {Proc. IEEE symposium on security and privacy},
	pages        = {538–552},
	note         = {Citation Key: bonneau2012b}
}
@article{Burow_Carr_Brunthaler_Payer_Nash_Larsen_Franz_2016,
	title        = {Control-flow integrity: Precision, security, and performance},
	author       = {Burow, N. and Carr, S. and Brunthaler, S. and Payer, M. and Nash, J. and Larsen, P. and Franz, M.},
	year         = 2016,
	note         = {Citation Key: burow2016a}
}
@article{Burr_Dodson_Polk_2006,
	title        = {Electronic authentication guideline},
	author       = {Burr, W. and Dodson, D. and Polk, W.},
	year         = 2006,
	url          = {http://csrc.nist.gov/publications/nistpubs/800-63/SP800-63V1\_0\_2.pdf.Google},
	note         = {Citation Key: burr2006a tex.type: NIST publication 800-63 version 1.0.2.}
}
@article{C.I.S._2010,
	title        = {The CIS security metrics},
	author       = {C.I.S.},
	year         = 2010,
	url          = {http://benchmarks.cisecurity.org/downloads/metrics/.},
	note         = {Citation Key: c2010a}
}
@inproceedings{Cardenas_Baras_Seamon_2006,
	title        = {A framework for the evaluation of intrusion detection systems},
	author       = {Cardenas, A. and Baras, J. and Seamon, K.},
	year         = 2006,
	booktitle    = {Proc. IEEE 2006 symposium on security and privacy. Google scholar},
	note         = {Citation Key: cardenas2006a}
}
@article{Carin_Cybenko_Hughes_2008,
	title        = {Cybersecurity strategies: The QuERIES methodology},
	author       = {Carin, L. and Cybenko, G. and Hughes, J.},
	year         = 2008,
	journal      = {IEEE Comput},
	volume       = {41, 8},
	pages        = {20–26},
	note         = {Citation Key: carin2008a}
}
@inproceedings{Carlini_Barresi_Payer_Wagner_Gross_2015,
	title        = {Control-flow bending: On the effectiveness of control-flow integrity},
	author       = {Carlini, N. and Barresi, A. and Payer, M. and Wagner, D. and Gross, T.},
	year         = 2015,
	booktitle    = {24th USENIX security symposium},
	pages        = {161–176},
	note         = {Citation Key: carlini2015a}
}
@inproceedings{Carlini_Wagner_2014,
	title        = {ROP is still dangerous: Breaking modern defenses},
	author       = {Carlini, N. and Wagner, D.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {385–399},
	note         = {Citation Key: carlini2014a}
}
@article{Carnavalet_Mannan_2015,
	title        = {A large-scale evaluation of high-impact password strength meters},
	author       = {Carnavalet, X.De Carn\'{e} De and Mannan, M.},
	year         = 2015,
	journal      = {ACM TISSEC},
	volume       = {18, 1},
	number       = 1,
	note         = {Citation Key: carnavalet2015a}
}
@inproceedings{Castelluccia_Durmuth_Perito_2012,
	title        = {Adaptive password-strength meters from markov models},
	author       = {Castelluccia, C. and D\"{u}rmuth, M. and Perito, D.},
	year         = 2012,
	booktitle    = {Proc. NDSS'12.Google scholar},
	note         = {Citation Key: castelluccia2012a}
}
@article{Chandola_Banerjee_Kumar_2009,
	title        = {Anomaly detection: A survey},
	author       = {Chandola, V. and Banerjee, A. and Kumar, V.},
	year         = 2009,
	journal      = {ACM Comput. Surv},
	volume       = {41, 3},
	number       = 1,
	note         = {Citation Key: chandola2009a tex.address: Google Scholar}
}
@inproceedings{Chen_Ji_2007,
	title        = {Measuring network-aware worm spreading ability},
	author       = {Chen, Z. and Ji, C.},
	year         = 2007,
	booktitle    = {Proc. INFOCOM'2007},
	pages        = {116–124},
	note         = {Citation Key: chen2007a}
}
@article{Cheng_Deng_Li_DeLoach_Singhal_Ou_2014,
	title        = {Metrics of Security},
	author       = {Cheng, Yi and Deng, Julia and Li, Jason and DeLoach, Scott A. and Singhal, Anoop and Ou, Xinming},
	year         = 2014,
	journal      = {Cyber Defense and Situational Awareness},
	volume       = 62,
	pages        = {263–295},
	doi          = {10.1007/978-3-319-11391-3\_13},
	note         = {tex.ids: cheng2014a},
	editor       = {Kott, Alexander and Wang, Cliff and Erbacher, Robert F.}
}
@inproceedings{Cheng_Wang_Jajodia_Singhal_2012,
	title        = {Aggregating CVSS Base Scores for Semantics-Rich Network Security Metrics},
	author       = {Cheng, Pengsu and Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop},
	year         = 2012,
	month        = oct,
	booktitle    = {2012 IEEE 31st Symposium on Reliable Distributed Systems},
	publisher    = {IEEE},
	pages        = {31–40},
	doi          = {10.1109/SRDS.2012.4},
	isbn         = {978-1-4673-2397-0},
	url          = {http://ieeexplore.ieee.org/document/6424837/},
	note         = {tex.ids: cheng2012a},
	place        = {Irvine, CA, USA},
	abstractnote = {A network security metric is desirable in evaluating the effectiveness of security solutions in distributed systems. Aggregating CVSS scores of individual vulnerabilities provides a practical approach to network security metric. However, existing approaches to aggregating CVSS scores usually cause useful semantics of individual scores to be lost in the aggregated result. In this paper, we address this issue through two novel approaches. First, instead of taking each base score as an input, our approach drills down to the underlying base metric level where dependency relationships have well-defined semantics. Second, our approach interprets and aggregates the base metrics from three different aspects in order to preserve corresponding semantics of the individual scores. Finally, we confirm the advantages of our approaches through simulation.}
}
@article{Chew_Swanson_Stine_Bartol_Brown_Robinson_2008,
	title        = {NIST special publication 800-55 revision 1: Performance measurement guide for information Security.Google scholar},
	author       = {Chew, E. and Swanson, M. and Stine, K. and Bartol, N. and Brown, A. and Robinson, W.},
	year         = 2008,
	note         = {Citation Key: chew2008a}
}
@inproceedings{Cho_Cam_Oltramari_2016,
	title        = {Effect of personality traits on trust and risk to phishing vulnerability: Modeling and analysis},
	author       = {Cho, J. and Cam, H. and Oltramari, A.},
	year         = 2016,
	booktitle    = {Proc. IEEE CogSIMA'16.Google scholar},
	note         = {Citation Key: cho2016a}
}
@article{Council_2007,
	title        = {Hard problem list},
	author       = {Council, I.N.F.O.S.E.C.Research},
	year         = 2007,
	url          = {http://www.infosec-research.org/},
	note         = {Citation Key: council2007a}
}
@inproceedings{Da_Xu_Xu_2014,
	title        = {A new approach to modeling and analyzing security of networked systems},
	author       = {Da, G. and Xu, M. and Xu, S.},
	year         = 2014,
	booktitle    = {Proc. HotSoS'14. Google scholar},
	note         = {Citation Key: da2014a}
}
@inproceedings{Dacier_Deswarte_Kaaniche_1996,
	title        = {Models and tools for quantitative assessment of operational security},
	author       = {Dacier, Marc and Deswarte, Yves and Ka\^{a}niche, Mohamed},
	year         = 1996,
	booktitle    = {IFIP International Conference on ICT Systems Security and Privacy Protection},
	publisher    = {Springer},
	pages        = {177–186},
	note         = {tex.ids: dacier1996a}
}
@inproceedings{Dagon_Gu_Lee_Lee_2007,
	title        = {A taxonomy of botnet structures},
	author       = {Dagon, D. and Gu, G. and Lee, C. and Lee, W.},
	year         = 2007,
	booktitle    = {Proc. ACSAC'07. 325–339.Google Scholar},
	note         = {Citation Key: dagon2007a}
}
@inproceedings{Dagon_Zou_Lee_2006,
	title        = {Modeling botnet propagation using time zones},
	author       = {Dagon, D. and Zou, C. and Lee, W.},
	year         = 2006,
	booktitle    = {Proc. NDSS'06.Google Scholar},
	note         = {Citation Key: dagon2006a}
}
@inbook{Dalvi_Domingos_Mausam_Verma_2004,
	title        = {Adversarial classification},
	author       = {Dalvi, N. and Domingos, P. and Mausam, S.Sanghai and Verma, D.},
	year         = 2004,
	booktitle    = {Proc},
	volume       = {KDD'04},
	pages        = {99–108},
	note         = {Citation Key: dalvi2004a}
}
@inproceedings{Davi_Sadeghi_Lehmann_Monrose_2014,
	title        = {Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection},
	author       = {Davi, L. and Sadeghi, A. and Lehmann, D. and Monrose, F.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium},
	pages        = {401–416},
	note         = {Citation Key: davi2014a}
}
@inproceedings{DellAmico_Michiardi_Roudier_2010,
	title        = {Password strength: An empirical analysis},
	author       = {DellAmico, M. and Michiardi, P. and Roudier, Y.},
	year         = 2010,
	booktitle    = {Proc. INFOCOM'10},
	pages        = {983–991},
	note         = {Citation Key: dellamico2010a}
}
@inproceedings{Desmedt_Frankel_1989,
	title        = {Threshold cryptosystems},
	author       = {Desmedt, Y. and Frankel, Y.},
	year         = 1989,
	booktitle    = {Proc. Crypto},
	pages        = {307–315},
	note         = {Citation Key: desmedt1989a}
}
@inproceedings{durumeric2014a,
	title        = {The matter of heartbleed},
	author       = {Durumeric, Z. and Kasten, J. and Adrian, D. and Halderman, J. and Bailey, M. and Li, F. and Weaver, N. and Amann, J. and Beekman, J. and Payer, M. and et al.},
	year         = 2014,
	booktitle    = {Proc. ACM IMC'14},
	pages        = {475–488},
	note         = {Citation Key: durumeric2014a},
}
@inbook{Edwards_Hofmeyr_Forrest_2015,
	title        = {Hype and heavy tails: A closer look at data breaches},
	author       = {Edwards, B. and Hofmeyr, S. and Forrest, S.},
	year         = 2015,
	booktitle    = {Proc WEIS'15. 67–78.Google Scholar},
	note         = {Citation Key: edwards2015a}
}
@inproceedings{Eskridge_Carvalho_Stoner_Toggweiler_Granados_2015,
	title        = {VINE: A cyber emulation environment for MTD experimentation},
	author       = {Eskridge, T. and Carvalho, M. and Stoner, E. and Toggweiler, T. and Granados, A.},
	year         = 2015,
	booktitle    = {Proc. ACM MTD'15},
	pages        = {43–47},
	note         = {Citation Key: eskridge2015a}
}
@article{F.I.R.S.T._2015,
	title        = {Forum of incident response and security teams: Common vulnerability scoring system (CVSS) version 3.0},
	author       = {F.I.R.S.T.},
	year         = 2015,
	url          = {https://www.first.org/cvss.},
	note         = {Citation Key: f2015a}
}
@article{Frei_Feb_2010,
	title        = {The security exposure of SOoftware portfolios},
	author       = {Frei, S. and Feb, T.Kristensen},
	year         = 2010,
	url          = {https://secunia.com/gfx/pdf/Secunia\_RSA\_Software\_Portfolio\_Security\_Exposure.pdf.},
	note         = {Citation Key: frei2010a}
}
@inproceedings{Frigault_Wang_2008,
	title        = {Measuring Network Security Using Bayesian Network-Based Attack Graphs},
	author       = {Frigault, Marcel and Wang, Lingyu},
	year         = 2008,
	month        = jan,
	pages        = {698–703},
	doi          = {10.1109/COMPSAC.2008.88},
	isbn         = {978-0-7695-3262-2},
	note         = {tex.ids: frigault2008b, frigaultMeasuringNetworkSecurity2008a},
	abstractnote = {Given the increasing dependence of our societies on information systems, the overall security of these systems should be measured and improved. Existing work generally focuses on measuring individual vulnerabilities instead of measuring their combined effects. Recent research has explored the application of attack graphs and probabilistic security metrics to address this challenge. However, such work usually assumes metrics of individual vulnerabilities to be independently distributed and combines them in an arbitrary manner. They cannot address more realistic cases, such as exploiting one vulnerability makes another vulnerability easier to exploit. In this paper, we propose to model probability metrics based on attack graphs as a special Bayesian Network. This approach provides a sound theoretical foundation to such metrics. It can also provide the capabilities of using conditional probabilities to address the general cases of interdependency between vulnerabilities.}
}
@inproceedings{Frigault_Wang_Singhal_Jajodia_2008,
	title        = {Measuring network security using dynamic bayesian network},
	author       = {Frigault, M. and Wang, L. and Singhal, A. and Jajodia, S.},
	year         = 2008,
	booktitle    = {Proc. QoP'08},
	pages        = {23–30},
	note         = {Citation Key: frigault2008a tex.ids: frigault2008b tex.citation-number: 106}
}
@inproceedings{Gaffney,
	title        = {Evaluation of intrusion detectors: A decision theory approach},
	author       = {Gaffney, Jr, J. and Ulvila, J.},
	year         = 2001,
	booktitle    = {Proc. IEEE symposium on security and privacy},
	pages        = {50–61},
	note         = {Citation Key: gaffney2001a},
	jr_ulvila_2001 = {null}
}
@inproceedings{Goktas_Athanasopoulos_Bos_Portokalidis_2014,
	title        = {Out of control: Overcoming control-flow integrity},
	author       = {G\"{o}ktas, E. and Athanasopoulos, E. and Bos, H. and Portokalidis, G.},
	year         = 2014,
	booktitle    = {Proc. IEEE Security and Privacy},
	pages        = {575–589},
	note         = {Citation Key: goektas2014a}
}
@article{Gordon_Loeb_2006,
	title        = {Budgeting process for information security expenditures},
	author       = {Gordon, L. and Loeb, M.},
	year         = 2006,
	journal      = {Communications of the ACM},
	volume       = {49, 1},
	pages        = {121–125},
	note         = {Citation Key: gordon2006a}
}
@inproceedings{Gu_Cardenas_Lee_2008,
	title        = {Principled reasoning and practical applications of alert fusion in intrusion detection systems},
	author       = {Gu, G. and C\'{a}rdenas, A. and Lee, W.},
	year         = 2008,
	booktitle    = {Proc. ACM ASIACCS'08},
	pages        = {136–147},
	note         = {Citation Key: gu2008a}
}
@inproceedings{Gu_Fogla_Dagon_Lee_Skoric_2006,
	title        = {Measuring intrusion detection capability: An information-theoretic approach},
	author       = {Gu, G. and Fogla, P. and Dagon, D. and Lee, W. and Skori\'{c}, B.},
	year         = 2006,
	booktitle    = {Proc. AsiaCCS'06},
	pages        = {90–101},
	note         = {Citation Key: gu2006a tex.citation-number: 39}
}
@article{Han_Lu_Xu_2014,
	title        = {Characterizing the power of moving target defense via cyber epidemic dynamics},
	author       = {Han, Y. and Lu, W. and Xu, S.},
	year         = 2014,
	journal      = {Proc. HotSoS'14},
	volume       = 10,
	number       = 1,
	note         = {Citation Key: han2014a}
}
@inproceedings{Hardy_Crete-Nishihata_Kleemola_Senft_Sonne_Wiseman_Gill_Deibert_2014,
	title        = {Targeted threat index: Characterizing and quantifying politically-motivated targeted malware},
	author       = {Hardy, S. and Crete-Nishihata, M. and Kleemola, K. and Senft, A. and Sonne, B. and Wiseman, G. and Gill, P. and Deibert, R.},
	year         = 2014,
	booktitle    = {Proc. USENIX security symposium. Google scholar},
	note         = {Citation Key: hardy2014a}
}
@inbook{Herlands_Hobson_Donovan_2014,
	title        = {Effective entropy: Security-centric metric for memory randomization techniques},
	author       = {Herlands, W. and Hobson, T. and Donovan, P.},
	year         = 2014,
	booktitle    = {Workshop on Cyber Security Experimentation and Test. Google Scholar},
	note         = {Citation Key: herlands2014a}
}
@article{Holm_2014,
	title        = {A large-scale study of the time required to compromise a computer system},
	author       = {Holm, H.},
	year         = 2014,
	journal      = {IEEE TDSC},
	volume       = {11, 1},
	pages        = {2–15},
	note         = {Citation Key: holm2014a}
}
@article{Homer_Zhang_Ou_Schmidt_Du_Rajagopalan_Singhal_2013,
	title        = {Aggregating vulnerability metrics in enterprise networks using attack graphs},
	author       = {Homer, John and Zhang, Su and Ou, Xinming and Schmidt, David and Du, Yanhui and Rajagopalan, S. Raj and Singhal, Anoop},
	year         = 2013,
	month        = sep,
	journal      = {Journal of Computer Security},
	volume       = 21,
	number       = 4,
	pages        = {561–597},
	doi          = {10.3233/JCS-130475},
	issn         = {18758924, 0926227X},
	note         = {tex.ids: homer2013a, homerAggregatingVulnerabilityMetrics2013a, homerAggregatingVulnerabilityMetrics2013b tex.citation-number: 102.},
	abstractnote = {Quantifying security risk is an important and yet difficult task in enterprise network security management. While metrics exist for individual software vulnerabilities, there is currently no standard way of aggregating such metrics. We present a model that can be used to aggregate vulnerability metrics in an enterprise network, producing quantitative metrics that measure the likelihood breaches can occur within a given network configuration. A clear semantic model for this aggregation is an important first step toward a comprehensive network security metric model. We utilize existing work in attack graphs and apply probabilistic reasoning to produce an aggregation that has clear semantics and sound computation. We ensure that shared dependencies between attack paths have a proportional effect on the final calculation. We correctly reason over cycles, ensuring that privileges are evaluated without any self-referencing effect. We introduce additional modeling artifacts in our probabilistic graphical model to capture and account for hidden correlations among exploit steps. The paper shows that a clear semantic model for aggregation is critical in interpreting the results, calibrating the metric model, and explaining insights gained from empirical evaluation. Our approach has been rigorously evaluated using a number of network models, as well as data from production systems.}
}
@inbook{Howe_Ray_Roberts_Urbanska_Byrne_2012,
	title        = {The psychology of security for the home computer user},
	author       = {Howe, A. and Ray, I. and Roberts, M. and Urbanska, M. and Byrne, Z.},
	year         = 2012,
	booktitle    = {IEEE symp. on security and privacy},
	pages        = {209–223},
	note         = {Citation Key: howe2012a}
}
@article{Huang_Joseph_Nelson_Rubinstein_Tygar,
	title        = {Adversarial machine learning},
	author       = {Huang, Ling and Joseph, Anthony D and Nelson, Blaine and Rubinstein, Benjamin I P and Tygar, J D},
	pages        = 15,
	note         = {tex.ids: huang2011a},
	abstractnote = {In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning--the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques.}
}
@article{Idika_Bhargava_2012,
	title        = {Extending attack graph-based security metrics and aggregating their application},
	author       = {Idika, Nwokedi and Bhargava, Bharat},
	year         = 2012,
	journal      = {IEEE Transactions on dependable and secure computing},
	volume       = 9,
	number       = 1,
	pages        = {75–85},
	note         = {tex.ids: idika2012a, idikaExtendingAttackGraphBased2012 tex.citation-number: 10}
}
@article{Jansen_2009,
	title        = {Directions in Security Metrics Research},
	author       = {Jansen, Wayne},
	year         = 2009,
	month        = apr,
	doi          = {https://doi.org/10.6028/NIST.IR.7564},
	url          = {https://csrc.nist.gov/publications/detail/nistir/7564/final},
	note         = {tex.ids: jansen2009a, jansenDirectionsSecurityMetrics2009a},
	abstractnote = {More than 100 years ago, Lord Kelvin insightfully observed that measurement is vital to deep knowledge and understanding in physical science. During the last few decades, researchers have made various attempts to develop measures and systems of measurement for computer security with varying degrees of success. This paper provides an overview of the security metrics area and looks at possible avenues of research that could be pursued to advance the state of the art.}
}
@book{Jaquith_2007,
	title        = {Security Metrics: Replacing Fear, Uncertainty, and Doubt},
	author       = {Jaquith, Andrew},
	year         = 2007,
	month        = mar,
	publisher    = {Pearson Education},
	isbn         = {978-0-13-271577-5},
	note         = {tex.ids: jaquith2007a, jaquithSecurityMetricsReplacing2007a tex.citation-number: 7 googlebooksid: Af8F00gTRN4C tex.publisher: Addison-Wesley Professional},
	abstractnote = {The Definitive Guide to Quantifying, Classifying, and Measuring Enterprise IT Security Operations      Security Metrics is the first comprehensive best-practice guide to defining, creating, and utilizing security metrics in the enterprise.    Using sample charts, graphics, case studies, and war stories, Yankee Group Security Expert Andrew Jaquith demonstrates exactly how to establish effective metrics based on your organization's unique requirements. You'll discover how to quantify hard-to-measure security activities, compile and analyze all relevant data, identify strengths and weaknesses, set cost-effective priorities for improvement, and craft compelling messages for senior management.     Security Metrics successfully bridges management's quantitative viewpoint with the nuts-and-bolts approach typically taken by security professionals. It brings together expert solutions drawn from Jaquith's extensive consulting work in the software, aerospace, and financial services industries, including new metrics presented nowhere else. You'll learn how to:   \textbullet{} Replace nonstop crisis response with a systematic approach to security improvement \textbullet{} Understand the differences between ``good'' and ``bad'' metrics \textbullet{} Measure coverage and control, vulnerability management, password quality, patch latency, benchmark scoring, and business-adjusted risk \textbullet{} Quantify the effectiveness of security acquisition, implementation, and other program activities  \textbullet{} Organize, aggregate, and analyze your data to bring out key insights \textbullet{} Use visualization to understand and communicate security issues more clearly  \textbullet{} Capture valuable data from firewalls and antivirus logs, third-party auditor reports, and other resources \textbullet{} Implement balanced scorecards that present compact, holistic views of organizational security effectiveness}
}
@inproceedings{Jha_Sheyner_Wing_2002,
	title        = {Two formal analys s of attack graphs},
	author       = {Jha, S. and Sheyner, O. and Wing, J.},
	year         = 2002,
	booktitle    = {Proc. IEEE CSF},
	pages        = {49–59},
	note         = {Citation Key: jha2002a tex.citation-number: 79}
}
@inproceedings{Johnson_Chuang_Grossklags_Christin_2012,
	title        = {Metrics for measuring ISP badness: The case of spam},
	author       = {Johnson, B. and Chuang, J. and Grossklags, J. and Christin, N.},
	year         = 2012,
	booktitle    = {Proc. FC'12. 89–97.Google scholar},
	note         = {Citation Key: johnson2012a}
}
@article{Jonsson_Olovsson_1997,
	title        = {A quantitative model of the security intrusion process based on attacker behavior},
	author       = {Jonsson, Erland and Olovsson, Tomas},
	year         = 1997,
	month        = apr,
	journal      = {IEEE Transactions on Software Engineering; New York},
	volume       = 23,
	number       = 4,
	pages        = {235–245},
	doi          = {http://dx.doi.org/10.1109/32.588541},
	issn         = {00985589},
	note         = {tex.ids: jonsson1997a, jonssonQuantitativeModelSecurity1997a tex.citation-number: 69},
	abstractnote = {The conceptual framework in which security can be split into 2 generic types of characteristics, behavioral and preventive, is discussed. Based on empirical data collected from intrusion experts, a hypothesis is worked out on typical attacker behavior. The hypothesis suggests that the attacking process can be split into 3 phases: 1. the learning phase, 2. the standard attack phase and 3. the innovative attack phase. The probability for successful attacks during the learning and innovative phases is expected to be small, although for different reasons. During the standard attack phase it is expected to be considerably higher.}
}
@inproceedings{Kelley_Komanduri_Mazurek_Shay_Vidas_Bauer_Christin_Cranor_Lopez,
	title        = {Guess again (and again and again): Measuring password strength by simulating password-cracking algorithms},
	author       = {Kelley, Patrick Gage and Komanduri, Saranga and Mazurek, Michelle L and Shay, Richard and Vidas, Timothy and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Lopez, Julio},
	pages        = 15,
	issn         = {1081-6011},
	note         = {tex.ids: kelley2012a, kelleyGuessAgainAgain2012},
	abstractnote = {Text-based passwords remain the dominant authentication method in computer systems, despite significant advancement in attackers' capabilities to perform password cracking. In response to this threat, password composition policies have grown increasingly complex. However, there is insufficient research defining metrics to characterize password strength and using them to evaluate password-composition policies. In this paper, we analyze 12,000 passwords collected under seven composition policies via an online study. We develop an efficient distributed method for calculating how effectively several heuristic password-guessing algorithms guess passwords. Leveraging this method, we investigate (a) the resistance of passwords created under different conditions to guessing; (b) the performance of guessing algorithms under different training sets; (c) the relationship between passwords explicitly created under a given composition policy and other passwords that happen to meet the same requirements; and (d) the relationship between guessability, as measured with password-cracking algorithms, and entropy estimates. Our findings advance understanding of both password-composition policies and metrics for quantifying password security.}
}
@inproceedings{Konte_Perdisci_Feamster_2015,
	title        = {ASwatch: An AS Reputation System to Expose Bulletproof Hosting ASes},
	author       = {Konte, Maria and Perdisci, Roberto and Feamster, Nick},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication - SIGCOMM '15},
	publisher    = {ACM Press},
	pages        = {625–638},
	doi          = {10.1145/2785956.2787494},
	isbn         = {978-1-4503-3542-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2785956.2787494},
	note         = {tex.ids: konte2015a},
	place        = {London, United Kingdom},
	abstractnote = {Bulletproof hosting Autonomous Systems (ASes)--malicious ASes fully dedicated to supporting cybercrime--provide freedom and resources for a cyber-criminal to operate. Their services include hosting a wide range of illegal content, botnet C\&C servers, and other malicious resources. Thousands of new ASes are registered every year, many of which are often used exclusively to facilitate cybercrime. A natural approach to squelching bulletproof hosting ASes is to develop a reputation system that can identify them for takedown by law enforcement and as input to other attack detection systems (e.g., spam filters, botnet detection systems). Unfortunately, current AS reputation systems rely primarily on data-plane monitoring of malicious activity from IP addresses (and thus can only detect malicious ASes after attacks are underway), and are not able to distinguish between malicious and legitimate but abused ASes.}
}
@inproceedings{Kuhrer_Rossow_Holz_2014,
	title        = {Paint It Black: Evaluating the Effectiveness of Malware Blacklists},
	author       = {K\"{u}hrer, Marc and Rossow, Christian and Holz, Thorsten},
	year         = 2014,
	booktitle    = {Research in Attacks, Intrusions and Defenses},
	publisher    = {Springer International Publishing},
	volume       = 8688,
	pages        = {1–21},
	doi          = {10.1007/978-3-319-11379-1\_1},
	isbn         = {978-3-319-11378-4},
	url          = {http://link.springer.com/10.1007/978-3-319-11379-1\_1},
	note         = {tex.ids: kuehrer2014a},
	place        = {Cham},
	abstractnote = {Blacklists are commonly used to protect computer systems against the tremendous number of malware threats. These lists include abusive hosts such as malware sites or botnet Command \& Control and dropzone servers to raise alerts if suspicious hosts are contacted. Up to now, though, little is known about the effectiveness of malware blacklists. In this paper, we empirically analyze 15 public malware blacklists and 4 blacklists operated by antivirus (AV) vendors. We aim to categorize the blacklist content to understand the nature of the listed domains and IP addresses. First, we propose a mechanism to identify parked domains in blacklists, which we find to constitute a substantial number of blacklist entries. Second, we develop a graph-based approach to identify sinkholes in the blacklists, i.e., servers that host malicious domains which are controlled by security organizations. In a thorough evaluation of blacklist effectiveness, we show to what extent real-world malware domains are actually covered by blacklists. We find that the union of all 15 public blacklists includes less than 20\% of the malicious domains for a majority of prevalent malware families and most AV vendor blacklists fail to protect against malware that utilizes Domain Generation Algorithms.},
	editor       = {Stavrou, Angelos and Bos, Herbert and Portokalidis, Georgios}
}
@article{Lampson,
	title        = {Practical Principles for Computer Security},
	author       = {Lampson, Butler},
	pages        = 47,
	note         = {tex.ids: lampson2006a}
}
@article{Landwehr_Bull_McDermott_Choi_1994,
	title        = {A taxonomy of computer program security flaws},
	author       = {Landwehr, Carl E. and Bull, Alan R. and McDermott, John P. and Choi, William S.},
	year         = 1994,
	month        = sep,
	journal      = {ACM Computing Surveys},
	volume       = 26,
	number       = 3,
	pages        = {211–254},
	doi          = {10.1145/185403.185412},
	issn         = {03600300},
	note         = {tex.ids: landwehr1994a}
}
@inproceedings{Larsen_Homescu_Brunthaler_Franz_2014,
	title        = {SoK: Automated Software Diversity},
	author       = {Larsen, Per and Homescu, Andrei and Brunthaler, Stefan and Franz, Michael},
	year         = 2014,
	month        = may,
	booktitle    = {2014 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {276–291},
	doi          = {10.1109/SP.2014.25},
	isbn         = {978-1-4799-4686-0},
	url          = {http://ieeexplore.ieee.org/document/6956570/},
	note         = {tex.ids: larsen2014a},
	place        = {San Jose, CA},
	abstractnote = {The idea of automatic software diversity is at least two decades old. The deficiencies of currently deployed defenses and the transition to online software distribution (the ``App store'' model) for traditional and mobile computers has revived the interest in automatic software diversity. Consequently, the literature on diversity grew by more than two dozen papers since 2008.}
}
@article{Lee_Fan_Miller_Stolfo_Zadok_2002,
	title        = {Toward cost-sensitive modeling for intrusion detection and response},
	author       = {Lee, Wenke and Fan, Wei and Miller, Matthew and Stolfo, Salvatore J. and Zadok, Erez},
	year         = 2002,
	month        = mar,
	journal      = {Journal of Computer Security},
	volume       = 10,
	number       = {1/2},
	pages        = 5,
	doi          = {10.3233/JCS-2002-101-202},
	issn         = {0926227X},
	note         = {tex.ids: lee2002a},
	abstractnote = {Intrusion detection systems (IDSs) must maximize the realization of security goals while minimizing costs. In this paper, we study the problem of building cost-sensitive intrusion detection models. We examine the major cost factors associated with an IDS, which include development cost, operational cost, damage cost due to successful intrusions, and the cost of manual and automated response to intrusions. These cost factors can be qualified according to a defined attack taxonomy and site-specific security policies and priorities. We define cost models to formulate the total expected cost of an IDS, and present cost-sensitive machine learning techniques that can produce detection models that are optimized for user-defined cost metrics. Empirical experiments show that our cost-sensitive modeling and deployment techniques are effective in reducing the overall cost of intrusion detection.}
}
@inproceedings{LeMay_Ford_Keefe_Sanders_Muehrcke_2011,
	title        = {Model-based Security Metrics Using ADversary VIew Security Evaluation (ADVISE)},
	author       = {LeMay, Elizabeth and Ford, Michael D. and Keefe, Ken and Sanders, William H. and Muehrcke, Carol},
	year         = 2011,
	month        = sep,
	booktitle    = {2011 Eighth International Conference on Quantitative Evaluation of SysTems},
	pages        = {191–200},
	doi          = {10.1109/QEST.2011.34},
	issn         = {null},
	note         = {tex.ids: lemay2011a},
	abstractnote = {System architects need quantitative security metrics to make informed trade-off decisions involving system security. The security metrics need to provide insight on weak points in the system defense, considering characteristics of both the system and its adversaries. To provide such metrics, we formally define the ADversary View Security Evaluation (ADVISE) method. Our approach is to create an executable state-based security model of a system and an adversary that represents how the adversary is likely to attack the system and the results of such an attack. The attack decision function uses information about adversary attack preferences and possible attacks against the system to mimic how the adversary selects the most attractive next attack step. The adversary's decision involves looking ahead some number of attack steps. System architects can use ADVISE to compare the security strength of system architecture variants and analyze the threats posed by different adversaries. We demonstrate the feasibility and benefits of ADVISE using a case study. To produce quantitative model-based security metrics, we have implemented the ADVISE method in a tool that facilitates user input of system and adversary data and automatically generates executable models.}
}
@inproceedings{levesque2013a,
	title        = {A clinical study of risk factors related to malware infections},
	author       = {Lalonde Levesque, Fanny and Nsiempba, Jude and Fernandez, Jos\'{e} M. and Chiasson, Sonia and Somayaji, Anil},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 ACM SIGSAC conference on Computer \& communications security - CCS '13},
	publisher    = {ACM Press},
	pages        = {97–108},
	doi          = {10.1145/2508859.2516747},
	isbn         = {978-1-4503-2477-9},
	url          = {http://dl.acm.org/citation.cfm?doid=2508859.2516747},
	note         = {tex.ids: levesque2013a},
	place        = {Berlin, Germany},
	abstractnote = {The success of malicious software (malware) depends upon both technical and human factors. The most security conscious users are vulnerable to zero-day exploits; the best security mechanisms can be circumvented by poor user choices. While there has been significant research addressing the technical aspects of malware attack and defense, there has been much less research reporting on how human behavior interacts with both malware and current malware defenses. In this paper we describe a proof-of-concept field study designed to examine the interactions between users, antivirus (anti-malware) software, and malware as they occur on deployed systems. The 4-month study, conducted in a fashion similar to the clinical trials used to evaluate medical interventions, involved 50 subjects whose laptops were instrumented to monitor possible infections and gather data on user behavior. Although the population size was limited, this initial study produced some intriguing, non-intuitive insights into the efficacy of current defenses, particularly with regards to the technical sophistication of end users. We assert that this work shows the feasibility and utility of testing security software through long-term field studies with greater ecological validity than can be achieved through other means.}
}
@inproceedings{Levin_2003,
	title        = {Lessons learned in using live red teams in IA experiments},
	author       = {Levin, D.},
	year         = 2003,
	booktitle    = {Proceedings DARPA Information Survivability Conference and Exposition},
	publisher    = {IEEE Comput. Soc},
	pages        = {110–119},
	doi          = {10.1109/DISCEX.2003.1194877},
	isbn         = {978-0-7695-1897-8},
	url          = {http://ieeexplore.ieee.org/document/1194877/},
	note         = {tex.ids: levin2003a},
	place        = {Washington, DC, USA},
	abstractnote = {The DARPA Information Assurance (IA) and Operational Partners in Experimentation (OPX) Programs have conducted over a dozen experiments involving live red teams since April 1999. This paper explores some of the lessons learned that are common among those experiments.}
}
@article{Li_Parker_Xu_2011,
	title        = {A stochastic model for quantitative security analysis of networked systems},
	author       = {Li, X. and Parker, P. and Xu, S.},
	year         = 2011,
	journal      = {IEEE TDSC},
	volume       = {8, 1},
	pages        = {28–43},
	note         = {Citation Key: li2011a}
}
@book{Lippmann_Riordan_Yu_Watson_2012,
	title        = {Continuous Security Metrics for Prevalent Network Threats: Introduction and First Four Metrics:},
	author       = {Lippmann, R. P. and Riordan, J. F. and Yu, T. H. and Watson, K. K.},
	year         = 2012,
	month        = may,
	doi          = {10.21236/ADA565825},
	url          = {http://www.dtic.mil/docs/citations/ADA565825},
	note         = {tex.ids: lippmann2012a},
	place        = {Fort Belvoir, VA},
	institution  = {Defense Technical Information Center}
}
@inproceedings{Liu_Man_2005,
	title        = {Network vulnerability assessment using Bayesian networks},
	author       = {Liu, Yu and Man, Hong},
	year         = 2005,
	month        = mar,
	booktitle    = {Data Mining, Intrusion Detection, Information Assurance, and Data Networks Security 2005},
	publisher    = {International Society for Optics and Photonics},
	volume       = 5812,
	pages        = {61–71},
	doi          = {10.1117/12.604240},
	url          = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5812/0000/Network-vulnerability-assessment-using-Bayesian-networks/10.1117/12.604240.short},
	note         = {tex.ids: liu2005a, liuNetworkVulnerabilityAssessment2005a, liuNetworkVulnerabilityAssessment2005b tex.citation-number: 104},
	abstractnote = {While computer vulnerabilities have been continually reported in laundry-list format by most commercial scanners, a comprehensive network vulnerability assessment has been an increasing challenge to security analysts. Researchers have proposed a variety of methods to build attack trees with chains of exploits, based on which post-graph vulnerability analysis can be performed. The most recent approaches attempt to build attack trees by enumerating all potential attack paths, which are space consuming and result in poor scalability. This paper presents an approach to use Bayesian network to model potential attack paths. We call such graph as ``Bayesian attack graph''. It provides a more compact representation of attack paths than conventional methods. Bayesian inference methods can be conveniently used for probabilistic analysis. In particular, we use the Bucket Elimination algorithm for belief updating, and we use Maximum Probability Explanation algorithm to compute an optimal subset of attack paths relative to prior knowledge on attackers and attack mechanisms. We tested our model on an experimental network. Test results demonstrate the effectiveness of our approach.}
}
@inproceedings{Liu_Sarabi_Zhang_Naghizadeh_Karir_Bailey_Liu,
	title        = {Cloudy with a Chance of Breach:   Forecasting Cyber Security Incidents},
	author       = {Liu, Yang and Sarabi, Armin and Zhang, Jing and Naghizadeh, Parinaz and Karir, Manish and Bailey, Michael and Liu, Mingyan},
	pages        = 50,
	note         = {tex.ids: liu2015a}
}
@inproceedings{Lowd_Meek_2005,
	title        = {Adversarial learning},
	author       = {Lowd, Daniel and Meek, Christopher},
	year         = 2005,
	booktitle    = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining  - KDD '05},
	publisher    = {ACM Press},
	pages        = 641,
	doi          = {10.1145/1081870.1081950},
	isbn         = {978-1-59593-135-1},
	url          = {http://portal.acm.org/citation.cfm?doid=1081870.1081950},
	note         = {tex.ids: lowd2005a tex.publisher: Google Scholar},
	place        = {Chicago, Illinois, USA},
	abstractnote = {Many classification tasks, such as spam filtering, intrusion detection, and terrorism detection, are complicated by an adversary who wishes to avoid detection. Previous work on adversarial classification has made the unrealistic assumption that the attacker has perfect knowledge of the classifier [2]. In this paper, we introduce the adversarial classifier reverse engineering (ACRE) learning problem, the task of learning sufficient information about a classifier to construct adversarial attacks. We present efficient algorithms for reverse engineering linear classifiers with either continuous or Boolean features and demonstrate their effectiveness using real data from the domain of spam filtering.}
}
@inproceedings{Lu_Song_Lee_Chung_Kim_Lee_2015,
	title        = {ASLR-Guard: Stopping Address Space Leakage for Code Reuse Attacks},
	author       = {Lu, Kangjie and Song, Chengyu and Lee, Byoungyoung and Chung, Simon P. and Kim, Taesoo and Lee, Wenke},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {280–291},
	doi          = {10.1145/2810103.2813694},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813694},
	note         = {tex.ids: lu2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {A general prerequisite for a code reuse attack is that the attacker needs to locate code gadgets that perform the desired operations and then direct the control flow of a vulnerable application to those gadgets. Address Space Layout Randomization (ASLR) attempts to stop code reuse attacks by making the first part of the prerequisite unsatisfiable. However, research in recent years has shown that this protection is often defeated by commonly existing information leaks, which provides attackers clues about the whereabouts of certain code gadgets. In this paper, we present ASLR-GUARD, a novel mechanism that completely prevents the leaks of code pointers, and render other information leaks (e.g., the ones of data pointers) useless in deriving code address. The main idea behind ASLR-GUARD is to render leak of data pointer useless in deriving code address by separating code and data, provide a secure storage for code pointers, and encode the code pointers when they are treated as data. ASLR-GUARD can either prevent code pointer leaks or render their leaks harmless. That is, ASLR-GUARD makes it impossible to overwrite code pointers with values that point to or will hijack the control flow to a desired address when the code pointers are dereferenced. We have implemented a prototype of ASLR-GUARD, including a compilation toolchain and a C/C++ runtime. Our evaluation results show that (1) ASLR-GUARD supports normal operations correctly; (2) it completely stops code address leaks and can resist against recent sophisticated attacks; (3) it imposes almost no runtime overhead (< 1\%) for C/C++ programs in the SPEC benchmark. Therefore, ASLR-GUARD is very practical and can be applied to secure many applications.}
}
@inproceedings{Lu_Xu_Yi_2013,
	title        = {Optimizing active cyber defense dynamics},
	author       = {Lu, W. and Xu, S. and Yi, X.},
	year         = 2013,
	booktitle    = {Proc. GameSec'13},
	pages        = {206–225},
	note         = {Citation Key: lu2013a}
}
@article{M.I.T.R.E._2014,
	title        = {Common weakness scoring system (CWSS version 1.0.1},
	author       = {M.I.T.R.E.},
	year         = 2014,
	url          = {https://cwe.mitre.},
	note         = {Citation Key: m2014a}
}
@inproceedings{Madan_Gogeva-Popstojanova_Vaidyanathan_Trivedi_2002,
	title        = {Modeling and quantification of security attributes of software systems},
	author       = {Madan, Bharat B. and Gogeva-Popstojanova, K. and Vaidyanathan, Kalyanaraman and Trivedi, Kishor S.},
	year         = 2002,
	booktitle    = {Proceedings International Conference on Dependable Systems and Networks},
	publisher    = {IEEE},
	pages        = {505–514},
	note         = {tex.ids: madan2002a, madanModelingQuantificationSecurity2002a, madanModelingQuantificationSecurity2002b tex.citation-number: 131}
}
@article{Manadhata_Wing_2010,
	title        = {An attack surface metric},
	author       = {Manadhata, Pratyusa K. and Wing, Jeannette M.},
	year         = 2010,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 37,
	number       = 3,
	pages        = {371–386},
	note         = {tex.ids: manadhata2011a, manadhataAttackSurfaceMetric, manadhataAttackSurfaceMetric2011, manadhataAttackSurfaceMetric2011a tex.citation-number: 32}
}
@inproceedings{Marczak_Scott-Railton_Paxson_Marquis-Boire,
	title        = {When Governments Hack Opponents: A Look at Actors and Technology},
	author       = {Marczak, William R and Scott-Railton, John and Paxson, Vern and Marquis-Boire, Morgan},
	pages        = 16,
	note         = {tex.ids: marczak2014a, marczakWhenGovernmentsHacka},
	abstractnote = {Repressive nation-states have long monitored telecommunications to keep tabs on political dissent. The Internet and online social networks, however, pose novel technical challenges to this practice, even as they open up new domains for surveillance. We analyze an extensive collection of suspicious files and links targeting activists, opposition members, and nongovernmental organizations in the Middle East over the past several years. We find that these artifacts reflect efforts to attack targets' devices for the purposes of eavesdropping, stealing information, and/or unmasking anonymous users. We describe attack campaigns we have observed in Bahrain, Syria, and the United Arab Emirates, investigating attackers, tools, and techniques. In addition to off-the-shelf remote access trojans and the use of third-party IP-tracking services, we identify commercial spyware marketed exclusively to governments, including Gamma's FinSpy and Hacking Team's Remote Control System (RCS). We describe their use in Bahrain and the UAE, and map out the potential broader scope of this activity by conducting global scans of the corresponding command-and-control (C\&C) servers. Finally, we frame the real-world consequences of these campaigns via strong circumstantial evidence linking hacking to arrests, interrogations, and imprisonment.}
}
@inproceedings{McHugh_2006,
	title        = {Quality of protection: measuring the unmeasurable?},
	author       = {McHugh, John},
	year         = 2006,
	booktitle    = {Proceedings of the 2nd ACM workshop on Quality of protection  - QoP '06},
	publisher    = {ACM Press},
	pages        = {1–2},
	doi          = {10.1145/1179494.1179495},
	isbn         = {978-1-59593-553-3},
	url          = {http://portal.acm.org/citation.cfm?doid=1179494.1179495},
	note         = {tex.ids: mchugh2006a tex.citation-number: 145.},
	place        = {Alexandria, Virginia, USA}
}
@inproceedings{Mezzour_Carley_Carley_2015,
	title        = {An empirical study of global malware encounters},
	author       = {Mezzour, Ghita and Carley, Kathleen M. and Carley, L. Richard},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 Symposium and Bootcamp on the Science of Security - HotSoS '15},
	publisher    = {ACM Press},
	pages        = {1–11},
	doi          = {10.1145/2746194.2746202},
	isbn         = {978-1-4503-3376-4},
	url          = {http://dl.acm.org/citation.cfm?doid=2746194.2746202},
	note         = {tex.ids: mezzour2015a, mezzourEmpiricalStudyGlobal2015a},
	place        = {Urbana, Illinois},
	abstractnote = {The number of trojans, worms, and viruses that computers encounter varies greatly across countries. Empirically identifying factors behind such variation can provide a scientific empirical basis to policy actions to reduce malware encounters in the most affected countries. However, our understanding of these factors is currently mainly based on expert opinions, not empirical evidence.}
}
@article{Microsoft_2013,
	title        = {Security intelligence report},
	author       = {Microsoft},
	year         = 2013,
	url          = {http://www.microsoft.com/security/sir/},
	note         = {Citation Key: microsoft2013a}
}
@article{Milenkoski_Vieira_Kounev_Avritzer_Payne_2015,
	title        = {Evaluating Computer Intrusion Detection Systems: A Survey of Common Practices},
	author       = {Milenkoski, Aleksandar and Vieira, Marco and Kounev, Samuel and Avritzer, Alberto and Payne, Bryan D.},
	year         = 2015,
	month        = sep,
	journal      = {ACM Computing Surveys},
	volume       = 48,
	number       = 1,
	pages        = {1–41},
	doi          = {10.1145/2808691},
	issn         = {03600300},
	note         = {tex.ids: milenkoski2015a},
	abstractnote = {In Appendix A, we provide an overview of major developments in the area of IDS evaluation in a chronological manner.}
}
@inproceedings{Mohaisen_Alrawi_2014,
	title        = {AV-Meter: An Evaluation of Antivirus Scans and Labels},
	author       = {Mohaisen, Aziz and Alrawi, Omar},
	year         = 2014,
	booktitle    = {Detection of Intrusions and Malware, and Vulnerability Assessment},
	publisher    = {Springer International Publishing},
	volume       = 8550,
	pages        = {112–131},
	doi          = {10.1007/978-3-319-08509-8\_7},
	isbn         = {978-3-319-08508-1},
	url          = {http://link.springer.com/10.1007/978-3-319-08509-8\_7},
	note         = {tex.ids: mohaisen2014a, mohaisenAVMeterEvaluationAntivirus2014a},
	place        = {Cham},
	abstractnote = {Antivirus scanners are designed to detect malware and, to a lesser extent, to label detections based on a family association. The labeling provided by AV vendors has many applications such as guiding efforts of disinfection and countermeasures, intelligence gathering, and attack attribution, among others. Furthermore, researchers rely on AV labels to establish a baseline of ground truth to compare their detection and classification algorithms. This is done despite many papers pointing out the subtle problem of relying on AV labels. However, the literature lacks any systematic study on validating the performance of antivirus scanners, and the reliability of those labels or detection.},
	editor       = {Dietrich, Sven}
}
@article{Morales_Xu_Sandhu_2012,
	title        = {Analyzing malware detection eciency with multiple anti-malware programs},
	author       = {Morales, J. and Xu, S. and Sandhu, R.},
	year         = 2012,
	journal      = {ASE Sci. J},
	volume       = {1, 2},
	note         = {Citation Key: morales2012a}
}
@inproceedings{Nappa_Johnson_Bilge_Caballero_Dumitras_2015,
	title        = {The Attack of the Clones: A Study of the Impact of Shared Code on Vulnerability Patching},
	author       = {Nappa, Antonio and Johnson, Richard and Bilge, Leyla and Caballero, Juan and Dumitras, Tudor},
	year         = 2015,
	month        = may,
	booktitle    = {2015 IEEE Symposium on Security and Privacy},
	pages        = {692–708},
	doi          = {10.1109/SP.2015.48},
	issn         = {2375-1207},
	note         = {tex.ids: nappa2015a},
	abstractnote = {Vulnerability exploits remain an important mechanism for malware delivery, despite efforts to speed up the creation of patches and improvements in software updating mechanisms. Vulnerabilities in client applications (e.g., Browsers, multimedia players, document readers and editors) are often exploited in spear phishing attacks and are difficult to characterize using network vulnerability scanners. Analyzing their lifecycle requires observing the deployment of patches on hosts around the world. Using data collected over 5 years on 8.4 million hosts, available through Symantec's WINE platform, we present the first systematic study of patch deployment in client-side vulnerabilities. We analyze the patch deployment process of 1,593 vulnerabilities from 10 popular client applications, and we identify several new threats presented by multiple installations of the same program and by shared libraries distributed with several applications. For the 80 vulnerabilities in our dataset that affect code shared by two applications, the time between patch releases in the different applications is up to 118 days (with a median of 11 days). Furthermore, as the patching rates differ considerably among applications, many hosts patch the vulnerability in one application but not in the other one. We demonstrate two novel attacks that enable exploitation by invoking old versions of applications that are used infrequently, but remain installed. We also find that the median fraction of vulnerable hosts patched when exploits are released is at most 14\%. Finally, we show that the patching rate is affected by user-specific and application-specific factors, for example, hosts belonging to security analysts and applications with an automated updating mechanism have significantly lower median times to patch.}
}
@inproceedings{Nayak_Marino_Efstathopoulos_Dumitras_2014,
	title        = {Some Vulnerabilities Are Different Than Others},
	author       = {Nayak, Kartik and Marino, Daniel and Efstathopoulos, Petros and Dumitra\c{s}, Tudor},
	year         = 2014,
	volume       = 8688,
	pages        = {426–446},
	doi          = {10.1007/978-3-319-11379-1\_21},
	url          = {http://link.springer.com/10.1007/978-3-319-11379-1\_21},
	note         = {tex.ids: nayak2014a},
	abstractnote = {The security of deployed and actively used systems is a moving target, influenced by factors not captured in the existing security metrics. For example, the count and severity of vulnerabilities in source code, as well as the corresponding attack surface, are commonly used as measures of a software product's security. But these measures do not provide a full picture. For instance, some vulnerabilities are never exploited in the wild, partly due to security technologies that make exploiting them difficult. As for attack surface, its effectiveness has not been validated empirically in the deployment environment. We introduce several security metrics derived from field data that help to complete the picture. They include the count of vulnerabilities exploited and the size of the attack surface actually exercised in real-world attacks. By evaluating these metrics on nearly 300 million reports of intrusion-protection telemetry, collected on more than six million hosts, we conduct an empirical study of security in the deployment environment. We find that none of the products in our study have more than 35\% of their disclosed vulnerabilities exploited in the wild. Furthermore, the exploitation ratio and the exercised attack surface tend to decrease with newer product releases. We also find that hosts that quickly upgrade to newer product versions tend to have reduced exercised attack-surfaces. The metrics proposed enable a more complete assessment of the security posture of enterprise infrastructure. Additionally, they open up new research directions for improving security by focusing on the vulnerabilities and attacks that have the highest impact in practice.}
}
@inproceedings{Neupane_Rahman_Saxena_Hirshfield_2015,
	title        = {A Multi-Modal Neuro-Physiological Study of Phishing Detection and Malware Warnings},
	author       = {Neupane, Ajaya and Rahman, Md. Lutfor and Saxena, Nitesh and Hirshfield, Leanne},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {479–491},
	doi          = {10.1145/2810103.2813660},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813660},
	note         = {tex.ids: neupane2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Detecting phishing attacks (identifying fake vs. real websites) and heeding security warnings represent classical user-centered security tasks subjected to a series of prior investigations. However, our understanding of user behavior underlying these tasks is still not fully mature, motivating further work concentrating at the neurophysiological level governing the human processing of such tasks. We pursue a comprehensive three-dimensional study of phishing detection and malware warnings, focusing not only on what users' task performance is but also on how users process these tasks based on: (1) neural activity captured using Electroencephalogram (EEG) cognitive metrics, and (2) eye gaze patterns captured using an eyetracker. Our primary novelty lies in employing multi-modal neurophysiological measures in a single study and providing a near realistic set-up (in contrast to a recent neuro-study conducted inside an fMRI scanner). Our work serves to advance, extend and support prior knowledge in several significant ways. Specifically, in the context of phishing detection, we show that users do not spend enough time analyzing key phishing indicators and often fail at detecting these attacks, although they may be mentally engaged in the task and subconsciously processing real sites differently from fake sites. In the malware warning tasks, in contrast, we show that users are frequently reading, possibly comprehending, and eventually heeding the message embedded in the warning.}
}
@article{Nicol_Sanders_Katz_Scherlis_Dumitra_Williams_Singh_2015,
	title        = {The science of security 5 hard problems},
	author       = {Nicol, D. and Sanders, B. and Katz, J. and Scherlis, B. and Dumitra, T. and Williams, L. and Singh, M.},
	year         = 2015,
	url          = {http://cps-vo.org/node/21590.},
	note         = {Citation Key: nicol2015a}
}
@article{Nicol_Sanders_Trivedi_2004,
	title        = {Model-based evaluation: from dependability to security},
	author       = {Nicol, D.M. and Sanders, W.H. and Trivedi, K.S.},
	year         = 2004,
	month        = jan,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	volume       = 1,
	number       = 1,
	pages        = {48–65},
	doi          = {10.1109/TDSC.2004.11},
	issn         = {2160-9209},
	note         = {tex.ids: nicol2004a, nicolModelbasedEvaluationDependability2004a tex.citation-number: 52},
	abstractnote = {The development of techniques for quantitative, model-based evaluation of computer system dependability has a long and rich history. A wide array of model-based evaluation techniques is now available, ranging from combinatorial methods, which are useful for quick, rough-cut analyses, to state-based methods, such as Markov reward models, and detailed, discrete-event simulation. The use of quantitative techniques for security evaluation is much less common, and has typically taken the form of formal analysis of small parts of an overall design, or experimental red team-based approaches. Alone, neither of these approaches is fully satisfactory, and we argue that there is much to be gained through the development of a sound model-based methodology for quantifying the security one can expect from a particular design. In this work, we survey existing model-based techniques for evaluating system dependability, and summarize how they are now being extended to evaluate system security. We find that many techniques from dependability evaluation can be applied in the security domain, but that significant challenges remain, largely due to fundamental differences between the accidental nature of the faults commonly assumed in dependability evaluation, and the intentional, human nature of cyber attacks.}
}
@inproceedings{Niu_Tan_2015,
	title        = {Per-Input Control-Flow Integrity},
	author       = {Niu, Ben and Tan, Gang},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {914–926},
	doi          = {10.1145/2810103.2813644},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813644},
	note         = {tex.ids: niu2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Control-Flow Integrity (CFI) is an effective approach to mitigating control-flow hijacking attacks. Conventional CFI techniques statically extract a control-flow graph (CFG) from a program and instrument the program to enforce that CFG. The statically generated CFG includes all edges for all possible inputs; however, for a concrete input, the CFG may include many unnecessary edges.}
}
@inproceedings{Noel_Jajodia_2014,
	title        = {Metrics suite for network attack graph analytics},
	author       = {Noel, Steven and Jajodia, Sushil},
	year         = 2014,
	booktitle    = {Proceedings of the 9th Annual Cyber and Information Security Research Conference on - CISR '14},
	publisher    = {ACM Press},
	pages        = {5–8},
	doi          = {10.1145/2602087.2602117},
	isbn         = {978-1-4503-2812-8},
	url          = {http://dl.acm.org/citation.cfm?doid=2602087.2602117},
	note         = {tex.ids: noel2014a, noelMetricsSuiteNetwork2014a},
	place        = {Oak Ridge, Tennessee},
	abstractnote = {We describe a suite of metrics for measuring network-wide cyber security risk based on a model of multi-step attack vulnerability (attack graphs). Our metrics are grouped into families, with family-level metrics combined into an overall metric for network vulnerability risk. The Victimization family measures risk in terms of key attributes of risk across all known network vulnerabilities. The Size family is an indication of the relative size of the attack graph. The Containment family measures risk in terms of minimizing vulnerability exposure across protection boundaries. The Topology family measures risk through graph theoretic properties (connectivity, cycles, and depth) of the attack graph. We display these metrics (at the individual, family, and overall levels) in interactive visualizations, showing multiple metrics trends over time.}
}
@article{Ortalo_Deswarte_Kaaniche_1999,
	title        = {Experimenting with quantitative evaluation tools for monitoring operational security},
	author       = {Ortalo, Rodolphe and Deswarte, Yves and Ka\^{a}niche, Mohamed},
	year         = 1999,
	journal      = {IEEE Transactions on Software Engineering},
	volume       = 25,
	number       = 5,
	pages        = {633–650},
	note         = {tex.ids: ortalo1999a, ortaloExperimentingQuantitativeEvaluation1999a}
}
@book{Ou_Singhal_2011,
	title        = {Quantitative Security Risk Assessment of Enterprise Networks},
	author       = {Ou, Xinming and Singhal, Anoop},
	year         = 2011,
	publisher    = {Springer New York},
	series       = {SpringerBriefs in Computer Science},
	doi          = {10.1007/978-1-4614-1860-3},
	isbn         = {978-1-4614-1859-7},
	url          = {http://link.springer.com/10.1007/978-1-4614-1860-3},
	note         = {tex.ids: ou2011a},
	place        = {New York, NY},
	collection   = {SpringerBriefs in Computer Science}
}
@inproceedings{Pamula_Jajodia_Ammann_Swarup_2006,
	title        = {A weakest-adversary security metric for network configuration security analysis},
	author       = {Pamula, Joseph and Jajodia, Sushil and Ammann, Paul and Swarup, Vipin},
	year         = 2006,
	booktitle    = {Proceedings of the 2nd ACM workshop on Quality of protection  - QoP '06},
	publisher    = {ACM Press},
	pages        = 31,
	doi          = {10.1145/1179494.1179502},
	isbn         = {978-1-59593-553-3},
	url          = {http://portal.acm.org/citation.cfm?doid=1179494.1179502},
	note         = {tex.ids: pamula2006a, pamulaWeakestadversarySecurityMetric2006a tex.citation-number: 96},
	place        = {Alexandria, Virginia, USA},
	abstractnote = {A security metric measures or assesses the extent to which a system meets its security objectives. Since meaningful quantitative security metrics are largely unavailable, the security community primarily uses qualitative metrics for security. In this paper, we present a novel quantitative metric for the security of computer networks that is based on an analysis of attack graphs. The metric measures the security strength of a network in terms of the strength of the weakest adversary who can successfully penetrate the network. We present an algorithm that computes the minimal sets of required initial attributes for the weakest adversary to possess in order to successfully compromise a network; given a specific network configuration, set of known exploits, a specific goal state, and an attacker class (represented by a set of all initial attacker attributes). We also demonstrate, by example, that diverse network configurations are not always beneficial for network security in terms of penetrability.}
}
@article{Pfleeger_2009,
	title        = {Useful Cybersecurity Metrics},
	author       = {Pfleeger, Shari Lawrence},
	year         = 2009,
	month        = jun,
	journal      = {IT Professional Magazine; Washington},
	volume       = 11,
	number       = 3,
	pages        = {38–45},
	doi          = {http://dx.doi.org/10.1109/MITP.2009.63},
	issn         = 15209202,
	note         = {tex.ids: pfleeger2009a},
	abstractnote = {Measuring cybersecurity is difficult, but other disciplines can offer important lessons and techniques for building a system that can help test hypotheses about system security. [PUBLICATION ABSTRACT]}
}
@article{Pfleeger_Cunningham_2010,
	title        = {Why Measuring Security Is Hard},
	author       = {Pfleeger, Shari and Cunningham, Robert},
	year         = 2010,
	month        = jul,
	journal      = {IEEE Security Privacy},
	volume       = 8,
	number       = 4,
	pages        = {46–54},
	doi          = {10.1109/MSP.2010.60},
	issn         = {1558-4046},
	note         = {tex.ids: pfleeger2010a tex.citation-number: 140},
	abstractnote = {For many years, we've been trying to measure ``security'' so that we can increase accountability, demonstrate compliance, and determine whether and by how much our investments in products and processes are making our systems more secure. This article investigates why security measurement is difficult and what strategies might help address our needs.}
}
@inproceedings{Phillips_Swiler_1998,
	title        = {A graph-based system for network-vulnerability analysis},
	author       = {Phillips, Cynthia and Swiler, Laura Painton},
	year         = 1998,
	booktitle    = {Proceedings of the 1998 workshop on New security paradigms  - NSPW '98},
	publisher    = {ACM Press},
	pages        = {71–79},
	doi          = {10.1145/310889.310919},
	isbn         = {978-1-58113-168-0},
	url          = {http://portal.acm.org/citation.cfm?doid=310889.310919},
	note         = {tex.ids: phillips1998a, phillipsGraphbasedSystemNetworkvulnerability1998a tex.citation-number: 83},
	place        = {Charlottesville, Virginia, United States},
	abstractnote = {This paper presents a graph-based approach to network vulnerability analysis. The method is flexible, allowing analysis of attacks from both outside and inside the network. It can analyze risks to a specific network asset, or examine the universe of possible consequences following a successful attack. The graph-based tool can identify the set of attack paths that have a high probability of success (or a low ``effort'' cost) for the attacker. The system could be used to test the effectiveness of making configuration changes, implementing an intrusion detection system, etc.}
}
@inproceedings{Prakash_Wellman_2015,
	title        = {Empirical Game-Theoretic Analysis for Moving Target Defense},
	author       = {Prakash, Achintya and Wellman, Michael P.},
	year         = 2015,
	booktitle    = {Proceedings of the Second ACM Workshop on Moving Target Defense - MTD '15},
	publisher    = {ACM Press},
	pages        = {57–65},
	doi          = {10.1145/2808475.2808483},
	isbn         = {978-1-4503-3823-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2808475.2808483},
	note         = {tex.ids: prakash2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {The effectiveness of a moving target defense depends on how it is deployed through specific system operations over time, and how attackers may respond to this deployment. We define a generic cyber-defense scenario, and examine the interplay between attack and defense strategies using empirical game-theoretic techniques. In this approach, the scenario is defined procedurally by a simulator, and data derived from systematic simulation is used to induce a game model. We explore a space of 72 game instances, defined by differences in agent objectives, attack cost, and ability of the defender to detect attack actions. We observe a range of qualitative strategic behaviors, which vary in clear patterns across environmental conditions. In particular, we find that the efficacy of deterrent defense is critically sensitive to detection capability, and in the absence of perfect detection the defender is often driven to proactive moving-target actions.}
}
@inproceedings{Rajab_Monrose_Terzis_2005,
	title        = {On the effectiveness of distributed worm monitoring},
	author       = {Rajab, M. and Monrose, F. and Terzis, A.},
	year         = 2005,
	booktitle    = {Proc. USENIX security symposium. Google scholar},
	note         = {Citation Key: rajab2005a}
}
@article{Reiter_Stubblebine_1999,
	title        = {Authentication metric analysis and design},
	author       = {Reiter, Michael K. and Stubblebine, Stuart G.},
	year         = 1999,
	month        = may,
	journal      = {ACM Transactions on Information and System Security},
	volume       = 2,
	number       = 2,
	pages        = {138–158},
	doi          = {10.1145/317087.317088},
	issn         = 10949224,
	note         = {tex.ids: reiter1999a, reiterAuthenticationMetricAnalysis1999a}
}
@inproceedings{Ritchey_Ammann_2000,
	title        = {Using model checking to analyze network vulnerabilities},
	author       = {Ritchey, R.W. and Ammann, P.},
	year         = 2000,
	booktitle    = {Proceeding 2000 IEEE Symposium on Security and Privacy. S\&P 2000},
	publisher    = {IEEE Comput. Soc},
	pages        = {156–165},
	doi          = {10.1109/SECPRI.2000.848453},
	isbn         = {978-0-7695-0665-4},
	url          = {http://ieeexplore.ieee.org/document/848453/},
	note         = {tex.ids: ritchey2000a, ritcheyUsingModelChecking2000a tex.citation-number: 90 ISSN: 1081-6011},
	place        = {Berkeley, CA, USA},
	abstractnote = {Even well administered networks are vulnerable to attacks due to the security ramifications of offering a variety of combined services. That is, services that are secure when offered in isolation nonetheless provide an attacker with a vulnerability to exploit when offered simultaneously. Many current tools address vulnerabilities in the context of a single host. In this paper we address vulnerabilities due to the configuration of various hosts in a network.}
}
@inproceedings{rndic_Laskov_2014,
	title        = {Practical Evasion of a Learning-Based Classifier: A Case Study},
	author       = {rndic, Nedim and Laskov, Pavel},
	year         = 2014,
	month        = may,
	booktitle    = {2014 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {197–211},
	doi          = {10.1109/SP.2014.20},
	isbn         = {978-1-4799-4686-0},
	url          = {http://ieeexplore.ieee.org/document/6956565/},
	note         = {tex.ids: rndic2014a},
	place        = {San Jose, CA},
	abstractnote = {Learning-based classifiers are increasingly used for detection of various forms of malicious data. However, if they are deployed online, an attacker may attempt to evade them by manipulating the data. Examples of such attacks have been previously studied under the assumption that an attacker has full knowledge about the deployed classifier. In practice, such assumptions rarely hold, especially for systems deployed online. A significant amount of information about a deployed classifier system can be obtained from various sources. In this paper, we experimentally investigate the effectiveness of classifier evasion using a real, deployed system, PDFRATE, as a test case. We develop a taxonomy for practical evasion strategies and adapt known evasion algorithms to implement specific scenarios in our taxonomy. Our experimental results reveal a substantial drop of PDFRATE's classification scores and detection accuracy after it is exposed even to simple attacks. We further study potential defense mechanisms against classifier evasion. Our experiments reveal that the original technique proposed for PDFRATE is only effective if the executed attack exactly matches the anticipated one. In the discussion of the findings of our study, we analyze some potential techniques for increasing robustness of learningbased systems against adversarial manipulation of data.}
}
@book{Roberts_1979,
	title        = {Measurement theory, with applications to decision making, utility and the social sciences},
	author       = {Roberts, F.},
	year         = 1979,
	publisher    = {Addison-Wesley, Boston.Google Scholar},
	note         = {Citation Key: roberts1979a}
}
@article{Roundy_Miller_2013,
	title        = {Binary-code obfuscations in prevalent packer tools},
	author       = {Roundy, Kevin A. and Miller, Barton P.},
	year         = 2013,
	month        = oct,
	journal      = {ACM Computing Surveys},
	volume       = 46,
	number       = 1,
	pages        = {1–32},
	doi          = {10.1145/2522968.2522972},
	issn         = {03600300},
	note         = {tex.ids: roundy2013a}
}
@inproceedings{Sabottke_Suciu_Dumitras,
	title        = {Vulnerability Disclosure in the Age of Social Media: Exploiting Twitter for Predicting Real-World Exploits},
	author       = {Sabottke, Carl and Suciu, Octavian-Petru and Dumitras, Tudor},
	pages        = 16,
	note         = {tex.ids: sabottke2015a},
	abstractnote = {In recent years, the number of software vulnerabilities discovered has grown significantly. This creates a need for prioritizing the response to new disclosures by assessing which vulnerabilities are likely to be exploited and by quickly ruling out the vulnerabilities that are not actually exploited in the real world. We conduct a quantitative and qualitative exploration of the vulnerability-related information disseminated on Twitter. We then describe the design of a Twitter-based exploit detector, and we introduce a threat model specific to our problem. In addition to response prioritization, our detection techniques have applications in risk modeling for cyber-insurance and they highlight the value of information provided by the victims of attacks.}
}
@article{Sanders_2014,
	title        = {Quantitative Security Metrics: Unattainable Holy Grail or a Vital Breakthrough within Our Reach?},
	author       = {Sanders, William H.},
	year         = 2014,
	month        = mar,
	journal      = {IEEE Security Privacy},
	volume       = 12,
	number       = 2,
	pages        = {67–69},
	doi          = {10.1109/MSP.2014.31},
	issn         = {1558-4046},
	note         = {tex.ids: sanders2014a},
	abstractnote = {It's long been well understood that you can calculate useful estimations of systems' reliability against accidental failure. It's also well understood that trying to calculate systems' level of security against possibly intelligent, determined, well-funded, and creative adversaries is a far greater challenge. Nevertheless, even a less-than-perfect predictive capacity, if its limitations are respected, is clearly better than none at all. Without promising perfection, such a capacity would offer crucial support to decision making that impacts system security.}
}
@article{Schneier_2000,
	title        = {Secrets 8 lies: Digital security in a networked world},
	author       = {Schneier, B.},
	year         = 2000,
	note         = {Citation Key: schneier2000a}
}
@inproceedings{Shacham_Page_Pfaff_Goh_Modadugu_Boneh_2004,
	title        = {On the effectiveness of address-space randomization},
	author       = {Shacham, Hovav and Page, Matthew and Pfaff, Ben and Goh, Eu-Jin and Modadugu, Nagendra and Boneh, Dan},
	year         = 2004,
	booktitle    = {Proceedings of the 11th ACM conference on Computer and communications security  - CCS '04},
	publisher    = {ACM Press},
	pages        = 298,
	doi          = {10.1145/1030083.1030124},
	isbn         = {978-1-58113-961-7},
	url          = {http://portal.acm.org/citation.cfm?doid=1030083.1030124},
	note         = {tex.ids: shacham2004a},
	place        = {Washington DC, USA},
	abstractnote = {Address-space randomization is a technique used to fortify systems against buffer overflow attacks. The idea is to introduce artificial diversity by randomizing the memory location of certain system components. This mechanism is available for both Linux (via PaX ASLR) and OpenBSD. We study the effectiveness of address-space randomization and find that its utility on 32-bit architectures is limited by the number of bits available for address randomization. In particular, we demonstrate a derandomization attack that will convert any standard buffer-overflow exploit into an exploit that works against systems protected by address-space randomization. The resulting exploit is as effective as the original, albeit somewhat slower: on average 216 seconds to compromise Apache running on a Linux PaX ASLR system. The attack does not require running code on the stack.}
}
@inproceedings{Sheng_Holbrook_Kumaraguru_Cranor_Downs_2010,
	title        = {Who falls for phish?: a demographic analysis of phishing susceptibility and effectiveness of interventions},
	author       = {Sheng, Steve and Holbrook, Mandy and Kumaraguru, Ponnurangam and Cranor, Lorrie Faith and Downs, Julie},
	year         = 2010,
	booktitle    = {Proceedings of the 28th international conference on Human factors in computing systems - CHI '10},
	publisher    = {ACM Press},
	pages        = 373,
	doi          = {10.1145/1753326.1753383},
	isbn         = {978-1-60558-929-9},
	url          = {http://portal.acm.org/citation.cfm?doid=1753326.1753383},
	note         = {tex.ids: sheng2010a},
	place        = {Atlanta, Georgia, USA},
	abstractnote = {In this paper we present the results of a roleplay survey instrument administered to 1001 online survey respondents to study both the relationship between demographics and phishing susceptibility and the effectiveness of several antiphishing educational materials. Our results suggest that women are more susceptible than men to phishing and participants between the ages of 18 and 25 are more susceptible to phishing than other age groups. We explain these demographic factors through a mediation analysis. Educational materials reduced users' tendency to enter information into phishing webpages by 40\% percent; however, some of the educational materials we tested also slightly decreased participants' tendency to click on legitimate links.}
}
@inproceedings{Sheyner_Haines_Jha_Lippmann_Wing_2002,
	title        = {Automated generation and analysis of attack graphs},
	author       = {Sheyner, Oleg and Haines, Joshua and Jha, Somesh and Lippmann, Richard and Wing, Jeannette M.},
	year         = 2002,
	booktitle    = {Security and privacy, 2002. Proceedings. 2002 IEEE Symposium on},
	publisher    = {IEEE},
	pages        = {273–284},
	issn         = {1081-6011},
	url          = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1004377},
	note         = {tex.ids: sheyner2002a, sheynerAutomatedGenerationAnalysis2002a}
}
@article{Singhal_Ou,
	title        = {Security Risk Analysis of Enterprise Networks Using Probabilistic Attack Graphs},
	author       = {Singhal, Anoop and Ou, Ximming},
	pages        = 24,
	note         = {tex.ids: singhal2011a, singhalSecurityRiskAnalysis2017 tex.publisher: National Institute of Standards and Technology}
}
@inproceedings{Snow_Monrose_Davi_Dmitrienko_Liebchen_Sadeghi_2013,
	title        = {Just-In-Time Code Reuse: On the Effectiveness of Fine-Grained Address Space Layout Randomization},
	author       = {Snow, Kevin Z. and Monrose, Fabian and Davi, Lucas and Dmitrienko, Alexandra and Liebchen, Christopher and Sadeghi, Ahmad-Reza},
	year         = 2013,
	month        = may,
	booktitle    = {2013 IEEE Symposium on Security and Privacy},
	pages        = {574–588},
	doi          = {10.1109/SP.2013.45},
	issn         = {1081-6011},
	note         = {tex.ids: snow2013a},
	abstractnote = {Fine-grained address space layout randomization (ASLR) has recently been proposed as a method of efficiently mitigating runtime attacks. In this paper, we introduce the design and implementation of a framework based on a novel attack strategy, dubbed just-in-time code reuse, that undermines the benefits of fine-grained ASLR. Specifically, we derail the assumptions embodied in fine-grained ASLR by exploiting the ability to repeatedly abuse a memory disclosure to map an application's memory layout on-the-fly, dynamically discover API functions and gadgets, and JIT-compile a target program using those gadgets – all within a script environment at the time an exploit is launched. We demonstrate the power of our framework by using it in conjunction with a real-world exploit against Internet Explorer, and also provide extensive evaluations that demonstrate the practicality of just-in-time code reuse attacks. Our findings suggest that fine-grained ASLR may not be as promising as first thought.}
}
@article{Stakhanova_Strasburg_Basu_Wong_2012,
	title        = {Towards cost-sensitive assessment of intrusion response selection},
	author       = {Stakhanova, Natalia and Strasburg, Chris and Basu, Samik and Wong, Johnny S.},
	year         = 2012,
	month        = jun,
	journal      = {Journal of Computer Security},
	volume       = 20,
	number       = {2–3},
	pages        = {169–198},
	doi          = {10.3233/JCS-2011-0436},
	issn         = {18758924, 0926227X},
	note         = {tex.ids: stakhanova2012a},
	abstractnote = {In recent years, cost-sensitive intrusion response has gained significant interest mainly due to its emphasis on the balance between potential damage incurred by the intrusion and cost of the response. However, one of the challenges in applying this approach is defining consistent and adaptable measurements of these cost factors on the basis of requirements and policy of the system being protected against intrusions.}
}
@article{Stevens_1946,
	title        = {On the Theory of Scales of Measurement},
	author       = {Stevens, S. S.},
	year         = 1946,
	journal      = {Science, New Series},
	volume       = 103,
	number       = 2684,
	pages        = {677–680},
	note         = {tex.ids: stevens1946a}
}
@inproceedings{stolfo2000a,
	title        = {Cost-based modeling for fraud and intrusion detection: results from the JAM project},
	author       = {Stolfo, S.J. and Wei Fan and Wenke Lee and Prodromidis, A. and Chan, P.K.},
	year         = 1999,
	booktitle    = {Proceedings DARPA Information Survivability Conference and Exposition. DISCEX'00},
	publisher    = {IEEE Comput. Soc},
	volume       = 2,
	pages        = {130–144},
	doi          = {10.1109/DISCEX.2000.821515},
	isbn         = {978-0-7695-0490-2},
	url          = {http://ieeexplore.ieee.org/document/821515/},
	note         = {tex.ids: stolfo2000a},
	place        = {Hilton Head, SC, USA},
}
@inproceedings{Stone-Gross_Kruegel_Almeroth_Moser_Kirda_2009,
	title        = {FIRE: FInding Rogue nEtworks},
	author       = {Stone-Gross, Brett and Kruegel, Christopher and Almeroth, Kevin and Moser, Andreas and Kirda, Engin},
	year         = 2009,
	month        = dec,
	booktitle    = {2009 Annual Computer Security Applications Conference},
	publisher    = {IEEE},
	pages        = {231–240},
	doi          = {10.1109/ACSAC.2009.29},
	isbn         = {978-1-4244-5327-6},
	url          = {http://ieeexplore.ieee.org/document/5380682/},
	note         = {tex.ids: stone-gross2009a},
	place        = {Honolulu, Hawaii, USA},
	abstractnote = {For many years, online criminals have been able to conduct their illicit activities by masquerading behind disreputable Internet Service Providers (ISPs). For example, organizations such as the Russian Business Network (RBN), Atrivo (a.k.a., Intercage), McColo, and most recently, the Triple Fiber Network (3FN) operated with impunity, providing a safe haven for Internet criminals for their own financial gain. What primarily sets these ISPs apart from others is the significant longevity of the malicious activities on their networks and the apparent lack of action taken in response to abuse reports. Interestingly, even though the Internet provides a certain degree of anonymity, such ISPs fear public attention. Once exposed, rogue networks often cease their malicious activities quickly, or are de-peered (disconnected) by their upstream providers. As a result, the Internet criminals are forced to relocate their operations.}
}
@inproceedings{Strasburg_Stakhanova_Basu_Wong_2009,
	title        = {A Framework for Cost Sensitive Assessment of Intrusion Response Selection},
	author       = {Strasburg, Chris and Stakhanova, Natalia and Basu, Samik and Wong, Johnny S.},
	year         = 2009,
	booktitle    = {2009 33rd Annual IEEE International Computer Software and Applications Conference},
	publisher    = {IEEE},
	pages        = {355–360},
	doi          = {10.1109/COMPSAC.2009.54},
	isbn         = {978-0-7695-3726-9},
	url          = {http://ieeexplore.ieee.org/document/5254241/},
	note         = {tex.ids: strasburg2009a},
	place        = {Seattle, Washington, USA},
	abstractnote = {In recent years, cost-sensitive intrusion response has gained significant interest, mainly due to its emphasis on the balance between potential damage incurred by the intrusion and cost of the response. However, one of the challenges in applying this approach is defining a consistent and adaptable measurement of these cost factors on the basis of system requirements and policy. In this paper, we present a host-based framework for the cost-sensitive assessment and selection of intrusion response. Specifically, we introduce a set of measurements that characterize the potential costs associated with the intrusion handling process, and propose an intrusion response evaluation method with respect to the risk of potential intrusion damage, the effectiveness of the response action and the response cost for a system. We provide an implementation of the proposed solution as an IDS-independent plugin tool and demonstrate its advantages on the several attack examples.}
}
@inproceedings{Tang_Sethumadhavan_Stolfo_2015,
	title        = {Heisenbyte: Thwarting Memory Disclosure Attacks using Destructive Code Reads},
	author       = {Tang, Adrian and Sethumadhavan, Simha and Stolfo, Salvatore},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
	publisher    = {ACM Press},
	pages        = {256–267},
	doi          = {10.1145/2810103.2813685},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813685},
	note         = {tex.ids: tang2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Vulnerabilities that disclose executable memory pages enable a new class of powerful code reuse attacks that build the attack payload at runtime. In this work, we present Heisenbyte, a system to protect against memory disclosure attacks. Central to Heisenbyte is the concept of destructive code reads – code is garbled right after it is read. Garbling the code after reading it takes away from the attacker her ability to leverage memory disclosure bugs in both static code and dynamically generated just-in-time code. By leveraging existing virtualization support, Heisenbyte's novel use of destructive code reads sidesteps the problem of incomplete binary disassembly in binaries, and extends protection to close-sourced COTS binaries, which are two major limitations of prior solutions against memory disclosure vulnerabilities. Our experiments demonstrate that Heisenbyte can tolerate some degree of imperfect static analysis in disassembled binaries, while effectively thwarting dynamic code reuse exploits in both static and JIT code, at a modest 1.8\% average runtime overhead due to virtualization and 16.5\% average overhead due to the destructive code reads.}
}
@article{Tavallaee_Stakhanova_Ghorbani_2010,
	title        = {Toward Credible Evaluation of Anomaly-Based Intrusion-Detection Methods},
	author       = {Tavallaee, Mahbod and Stakhanova, Natalia and Ghorbani, Ali Akbar},
	year         = 2010,
	month        = sep,
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume       = 40,
	number       = 5,
	pages        = {516–524},
	doi          = {10.1109/TSMCC.2010.2048428},
	issn         = {1094-6977, 1558-2442},
	note         = {tex.ids: tavallaee2010a},
	abstractnote = {Since the first introduction of anomaly-based intrusion detection to the research community in 1987, the field has grown tremendously. A variety of methods and techniques introducing new capabilities in detecting novel attacks were developed. Most of these techniques report a high detection rate of 98\% at the low false alarm rate of 1\%. In spite of the anomaly-based approach's appeal, the industry generally favors signature-based detection for mainstream implementation of intrusion-detection systems. While a variety of anomaly-detection techniques have been proposed, adequate comparison of these methods' strengths and limitations that can lead to potential commercial application is difficult. Since the validity of experimental research in academic computer science, in general, is questionable, it is plausible to assume that research in anomaly detection shares the above problem. The concerns about the validity of these methods may partially explain why anomaly-based intrusion-detection methods are not adopted by industry. To investigate this issue, we review the current state of the experimental practice in the area of anomaly-based intrusion detection and survey 276 studies in this area published during the period of 2000–2008. We summarize our observations and identify the common pitfalls among surveyed works.}
}
@article{Thakore,
	title        = {A QUANTITATIVE METHODOLOGY FOR EVALUATING AND DEPLOYING SECURITY MONITORS},
	author       = {Thakore, Uttam},
	pages        = 87,
	note         = {tex.ids: thakore2015a, thakoreQUANTITATIVEMETHODOLOGYEVALUATINGa}
}
@inproceedings{Ugarte-Pedrero_Balzarotti_Santos_Bringas_2015,
	title        = {SoK: Deep Packer Inspection: A Longitudinal Study of the Complexity of Run-Time Packers},
	author       = {Ugarte-Pedrero, Xabier and Balzarotti, Davide and Santos, Igor and Bringas, Pablo G.},
	year         = 2015,
	month        = may,
	booktitle    = {2015 IEEE Symposium on Security and Privacy},
	publisher    = {IEEE},
	pages        = {659–673},
	doi          = {10.1109/SP.2015.46},
	isbn         = {978-1-4673-6949-7},
	issn         = {2375-1207},
	url          = {https://ieeexplore.ieee.org/document/7163053/},
	note         = {tex.ids: ugarte-pedrero2015a, ugarte-pedreroSoKDeepPacker2015a, ugarte-pedreroSoKDeepPacker2015b},
	place        = {San Jose, CA},
	abstractnote = {Run-time packers are often used by malware-writers to obfuscate their code and hinder static analysis. The packer problem has been widely studied, and several solutions have been proposed in order to generically unpack protected binaries. Nevertheless, these solutions commonly rely on a number of assumptions that may not necessarily reflect the reality of the packers used in the wild. Moreover, previous solutions fail to provide useful information about the structure of the packer or its complexity. In this paper, we describe a framework for packer analysis and we propose a taxonomy to measure the runtime complexity of packers.}
}
@article{unknown2011a,
	year         = 2011,
	journal      = {National Science and Technology Council},
	url          = {https://www.nitrd.gov/SUBCOMMITTEE/csia/Fed\_Cybersecurity\_RD\_Strategic\_Plan\_2011.pdf.},
	note         = {Citation Key: unknown2011a},
}
@article{Ur_Segreti_Bauer_Christin_Cranor_Komanduri_Kurilova_Mazurek_Melicher_Shay,
	title        = {Measuring Real-World Accuracies and Biases in Modeling Password Guessability},
	author       = {Ur, Blase and Segreti, Sean M and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Komanduri, Saranga and Kurilova, Darya and Mazurek, Michelle L and Melicher, William and Shay, Richard},
	pages        = 19,
	note         = {tex.ids: ur2015a, urMeasuringRealWorldAccuraciesa},
	abstractnote = {Parameterized password guessability--how many guesses a particular cracking algorithm with particular training data would take to guess a password--has become a common metric of password security. Unlike statistical metrics, it aims to model real-world attackers and to provide per-password strength estimates. We investigate how cracking approaches often used by researchers compare to real-world cracking by professionals, as well as how the choice of approach biases research conclusions.}
}
@article{ur2012a,
	title        = {How Does Your Password Measure Up? The Effect of Strength Meters on Password Creation},
	author       = {Ur, Blase and Kelley, Patrick Gage and Komanduri, Saranga and Lee, Joel and Maass, Michael and Mazurek, Michelle L and Passaro, Timothy and Shay, Richard and Vidas, Timothy and Bauer, Lujo and et al.},
	pages        = 16,
	note         = {tex.ids: ur2012a},
	abstractnote = {To help users create stronger text-based passwords, many web sites have deployed password meters that provide visual feedback on password strength. Although these meters are in wide use, their effects on the security and usability of passwords have not been well studied.}
}
@article{Velleman_Wilkinson,
	title        = {Nominal, Ordinal, Interval, and Ratio Typologies are Misleading},
	author       = {Velleman, Paul and Wilkinson, Leland},
	pages        = 19,
	note         = {tex.ids: velleman1993a}
}
@inproceedings{Verendel_2009,
	title        = {Quantified security is a weak hypothesis: a critical survey of results and assumptions},
	author       = {Verendel, Vilhelm},
	year         = 2009,
	booktitle    = {Proceedings of the 2009 workshop on New security paradigms workshop - NSPW '09},
	publisher    = {ACM Press},
	pages        = 37,
	doi          = {10.1145/1719030.1719036},
	isbn         = {978-1-60558-845-2},
	url          = {http://portal.acm.org/citation.cfm?doid=1719030.1719036},
	note         = {tex.ids: verendel2009a, verendelQuantifiedSecurityWeak2009a, verendelQuantifiedSecurityWeak2009b tex.citation-number: 16},
	place        = {Oxford, United Kingdom},
	abstractnote = {This paper critically surveys previous work on quantitative representation and analysis of security. Such quantified security has been presented as a general approach to precisely assess and control security. We classify a significant part of the work between 1981 and 2008 with respect to security perspective, target of quantification, underlying assumptions and type of validation. The result shows how the validity of most methods is still strikingly unclear. Despite applying a number of techniques from fields such as computer science, economics and reliability theory to the problem it is unclear what valid results exist with respect to operational security. Quantified security is thus a weak hypothesis because a lack of validation and comparison between such methods against empirical data. Furthermore, many assumptions in formal treatments are not empirically well-supported in operational security and have been adopted from other fields. A number of risks are present with depending on quantitative methods with limited or no validation.}
}
@inbook{Villarrubia_Medina_Piattini_2004,
	title        = {Towards a classification of security metrics},
	author       = {Villarrubia, Carlos and Medina, Eduardo F. and Piattini, Mario},
	year         = 2004,
	booktitle    = {WOSIS},
	pages        = {342--350,},
	note         = {Citation Key: villarrubia2004a}
}
@book{Wagner_Eckhoff_2015,
	title        = {Technical privacy metrics: A systematic survey},
	author       = {Wagner, I. and Eckhoff, D.},
	year         = 2015,
	note         = {Citation Key: wagner2015a tex.arxiv: 1512.00327}
}
@inproceedings{Wang_Islam_Long_Singhal_Jajodia_2008,
	title        = {An attack graph-based probabilistic security metric},
	author       = {Wang, Lingyu and Islam, Tania and Long, Tao and Singhal, Anoop and Jajodia, Sushil},
	year         = 2008,
	booktitle    = {IFIP Annual Conference on Data and Applications Security and Privacy},
	publisher    = {Springer},
	pages        = {283–296},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-70567-3\_22},
	note         = {tex.ids: wang2008a, wangAttackGraphbasedProbabilistic2008a tex.citation-number: 88}
}
@inbook{Wang_Jajodia_Singhal_Noel_2010,
	title        = {k-Zero Day Safety: Measuring the Security Risk of Networks against Unknown Attacks},
	author       = {Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop and Noel, Steven},
	year         = 2010,
	booktitle    = {Computer Security – ESORICS 2010},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 6345,
	pages        = {573–587},
	doi          = {10.1007/978-3-642-15497-3\_35},
	isbn         = {978-3-642-15496-6},
	url          = {http://link.springer.com/10.1007/978-3-642-15497-3\_35},
	note         = {tex.ids: wang2010a},
	place        = {Berlin, Heidelberg},
	abstractnote = {The security risk of a network against unknown zero day attacks has been considered as something unmeasurable since software flaws are less predictable than hardware faults and the process of finding such flaws and developing exploits seems to be chaotic [24]. In this paper, we propose a novel security metric, k-zero day safety, based on the number of unknown zero day vulnerabilities. That is, the metric counts at least how many unknown vulnerabilities are required for compromising a network asset, regardless of what vulnerabilities those are. We formally define the metric based on a model of relevant network components. We then devise algorithms for computing the metric. Finally, we discuss how to apply the metric for hardening a network.},
	editor       = {Gritzalis, Dimitris and Preneel, Bart and Theoharidou, Marianthi}
}
@inproceedings{Wei_Frinke_Carter_Ritter_2001,
	title        = {Cost-benefit analysis for network intrusion detection systems},
	author       = {Wei, H. and Frinke, D. and Carter, O. and Ritter, C.},
	year         = 2001,
	booktitle    = {Proceedings of the 28th annual computer security conference},
	publisher    = {D.C.Google Scholar},
	note         = {Citation Key: wei2001a},
	place        = {Washington}
}
@inproceedings{Weir_Aggarwal_Collins_Stern_2010,
	title        = {Testing metrics for password creation policies by attacking large sets of revealed passwords},
	author       = {Weir, Matt and Aggarwal, Sudhir and Collins, Michael and Stern, Henry},
	year         = 2010,
	booktitle    = {Proceedings of the 17th ACM conference on Computer and communications security - CCS '10},
	publisher    = {ACM Press},
	pages        = 162,
	doi          = {10.1145/1866307.1866327},
	isbn         = {978-1-4503-0245-6},
	url          = {http://portal.acm.org/citation.cfm?doid=1866307.1866327},
	note         = {tex.ids: weir2010a, weirTestingMetricsPassword2010a},
	place        = {Chicago, Illinois, USA},
	abstractnote = {In this paper we attempt to determine the effectiveness of using entropy, as defined in NIST SP800-63, as a measurement of the security provided by various password creation policies. This is accomplished by modeling the success rate of current password cracking techniques against real user passwords. These data sets were collected from several different websites, the largest one containing over 32 million passwords. This focus on actual attack methodologies and real user passwords quite possibly makes this one of the largest studies on password security to date. In addition we examine what these results mean for standard password creation policies, such as minimum password length, and character set requirements.}
}
@article{Xu_2014a,
	title        = {Cybersecurity dynamics},
	author       = {Xu, Shouhuai},
	year         = 2014,
	journal      = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security - HotSoS '14},
	pages        = {1–2},
	doi          = {10.1145/2600176.2600190},
	note         = {tex.ids: xu2014a, xuCybersecurityDynamics2014a tex.source: Google Scholar},
	abstractnote = {We explore the emerging field of Cybersecurity Dynamics, a candidate foundation for the Science of Cybersecurity.}
}
@inproceedings{Xu_2014b,
	title        = {Emergent behavior in cybersecurity},
	author       = {Xu, Shouhuai},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security - HotSoS '14},
	publisher    = {ACM Press},
	pages        = {1–2},
	doi          = {10.1145/2600176.2600189},
	isbn         = {978-1-4503-2907-1},
	url          = {http://dl.acm.org/citation.cfm?doid=2600176.2600189},
	note         = {tex.ids: xu2014c, xuEmergentBehaviorCybersecurity2014a tex.source: Google Scholar},
	place        = {Raleigh, North Carolina},
	abstractnote = {We argue that emergent behavior is inherent to cybersecurity.}
}
@article{Xu_Da_Xu,
	title        = {Cyber Epidemic Models with Dependences},
	author       = {Xu, Maochao and Da, Gaofeng and Xu, Shouhuai},
	journal      = {Internet Mathematics},
	pages        = 37,
	note         = {tex.ids: xu2015b, xuCyberEpidemicModelsa},
	abstractnote = {Studying models of cyber epidemics over arbitrary complex networks can deepen our understanding of cyber security from a whole-system perspective. In this work, we initiate the investigation of cyber epidemic models that accommodate the dependences between the cyber attack events. Due to the notorious difficulty in dealing with such dependences, essentially all existing cyber epidemic models have disregarded them. Specifically, we introduce the idea of copulas into cyber epidemic models for accommodating the dependences between the cyber attack events. We investigate the epidemic equilibrium thresholds as well as the bounds for both equilibrium and nonequilibrium infection probabilities. We further characterize the side effects of disregarding the due dependences between the cyber attack events by showing that the results thereof are unnecessarily restrictive or even incorrect.}
}
@article{Xu_Lu_Li,
	title        = {A Stochastic Model of Active Cyber Defense Dynamics},
	author       = {Xu, Shouhuai and Lu, Wenlian and Li, Hualun},
	journal      = {Internet Mathematics},
	pages        = 48,
	note         = {tex.ids: xu2015a, xuStochasticModelActivea},
	abstractnote = {The concept of active cyber defense has appeared in the literature in recent years. However, there are no mathematical models for characterizing the effectiveness of active cyber defense. In this paper, we fill the void by proposing a novel Markov process model that is native to the interaction between cyber attack and active cyber defense. Unfortunately, the native Markov process model cannot be tackled by techniques of which we are aware. We therefore simplify, via mean-field approximation, the Markov process model as a dynamical system model that is amenable to analysis. This allows us to derive a set of valuable analytic results that characterize the effectiveness of four types of active cyber defense dynamics. Simulations show that the analytic results are intrinsic to the native Markov process model, and therefore justify the validity of the dynamical system model. We also discuss side effects of the mean-field approximation and their implications.}
}
@article{Xu_Lu_Xu_2012,
	title        = {Push- and pull-based epidemic spreading in arbitrary networks: Thresholds and deeper insights},
	author       = {Xu, S. and Lu, W. and Xu, L.},
	year         = 2012,
	journal      = {ACM TAAS},
	volume       = {7, 3},
	number       = 1,
	note         = {Citation Key: xu2012b tex.address: Google Scholar}
}
@article{Xu_Lu_Xu_Zhan_2014,
	title        = {Adaptive Epidemic Dynamics in Networks: Thresholds and Control},
	author       = {Xu, Shouhuai and Lu, Wenlian and Xu, Li and Zhan, Zhenxin},
	year         = 2014,
	month        = jan,
	journal      = {ACM Transactions on Autonomous and Adaptive Systems},
	volume       = 8,
	number       = 4,
	pages        = {1–19},
	doi          = {10.1145/2555613},
	issn         = 15564665,
	note         = {tex.ids: xu2014d, xuAdaptiveEpidemicDynamics2014a}
}
@article{Xu_Lu_Zhan_2012,
	title        = {A stochastic model of multivirus dynamics},
	author       = {Xu, S. and Lu, W. and Zhan, Z.},
	year         = 2012,
	journal      = {IEEE Trans. Depend. Secure Comput},
	volume       = {9, 1},
	pages        = {30–45},
	note         = {Citation Key: xu2012a}
}
@article{Xu_Xu_2012,
	title        = {An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems},
	author       = {Xu, Maochao and Xu, Shouhuai},
	year         = 2012,
	month        = aug,
	journal      = {Internet Mathematics},
	volume       = 8,
	number       = 3,
	pages        = {288–320},
	doi          = {10.1080/15427951.2012.654480},
	issn         = {1542-7951, 1944-9488},
	note         = {tex.ids: mxu2012a, xuExtendedStochasticModel2012a, xuExtendedStochasticModel2012b},
	abstractnote = {Quantitative security analysis of networked computer systems has been an open problem in computer security for decades. Recently, a promising approach was proposed in [Li et al. 11], which, however, made some strong assumptions including the exponential distribution of, and the independence among, the relevant random variables. In this paper, we substantially weaken these assumptions while offering, in addition to the same types of analytical results as in [Li et al. 11], methods for obtaining the desired security quantities in practice. Moreover, we investigate the problem from a higher-level abstraction, which also leads to both analytical results and practical methods for obtaining the desired security quantities. These should represent a significant step toward ultimately solving the problem of quantitative security analysis of networked computer systems.}
}
@article{Xu_Zhan_Xu_Ye_2014,
	title        = {An Evasion and Counter-Evasion Study in Malicious Websites Detection},
	author       = {Xu, Li and Zhan, Zhenxin and Xu, Shouhuai and Ye, Keyin},
	year         = 2014,
	month        = aug,
	journal      = {arXiv:1408.1993 [cs]},
	issn         = {null},
	url          = {http://arxiv.org/abs/1408.1993},
	note         = {tex.ids: xu2014b, xuEvasionCounterevasionStudy2014 arXiv: 1408.1993},
	abstractnote = {Malicious websites are a major cyber attack vector, and effective detection of them is an important cyber defense task. The main defense paradigm in this regard is that the defender uses some kind of machine learning algorithms to train a detection model, which is then used to classify websites in question. Unlike other settings, the following issue is inherent to the problem of malicious websites detection: the attacker essentially has access to the same data that the defender uses to train his/her detection models. This `symmetry' can be exploited by the attacker, at least in principle, to evade the defender's detection models. In this paper, we present a framework for characterizing the evasion and counter-evasion interactions between the attacker and the defender, where the attacker attempts to evade the defender's detection models by taking advantage of this symmetry. Within this framework, we show that an adaptive attacker can make malicious websites evade powerful detection models, but proactive training can be an effective counter-evasion defense mechanism. The framework is geared toward the popular detection model of decision tree, but can be adapted to accommodate other classifiers.}
}
@article{Yardon_2014,
	title        = {Symantec develops new attack on cyberhacking},
	author       = {Yardon, D.},
	year         = 2014,
	month        = may,
	url          = {http://www.wsj.},
	note         = {Citation Key: yardon2014a}
}
@inproceedings{Yen_Heorhiadi_Oprea_Reiter_Juels_2014,
	title        = {An Epidemiological Study of Malware Encounters in a Large Enterprise},
	author       = {Yen, Ting-Fang and Heorhiadi, Victor and Oprea, Alina and Reiter, Michael K. and Juels, Ari},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security - CCS '14},
	publisher    = {ACM Press},
	pages        = {1117–1130},
	doi          = {10.1145/2660267.2660330},
	isbn         = {978-1-4503-2957-6},
	url          = {http://dl.acm.org/citation.cfm?doid=2660267.2660330},
	note         = {tex.ids: yen2014a, yenEpidemiologicalStudyMalware2014a},
	place        = {Scottsdale, Arizona, USA},
	abstractnote = {We present an epidemiological study of malware encounters in a large, multi-national enterprise. Our data sets allow us to observe or infer not only malware presence on enterprise computers, but also malware entry points, network locations of the computers (i.e., inside the enterprise network or outside) when the malware were encountered, and for some web-based malware encounters, web activities that gave rise to them. By coupling this data with demographic information for each host's primary user, such as his or her job title and level in the management hierarchy, we are able to paint a reasonably comprehensive picture of malware encounters for this enterprise. We use this analysis to build a logistic regression model for inferring the risk of hosts encountering malware; those ranked highly by our model have a > 3\texttimes{} higher rate of encountering malware than the base rate. We also discuss where our study confirms or refutes other studies and guidance that our results suggest.}
}
@inproceedings{Yilek_Rescorla_Shacham_Enright_Savage_2009,
	title        = {When private keys are public: results from the 2008 Debian OpenSSL vulnerability},
	author       = {Yilek, Scott and Rescorla, Eric and Shacham, Hovav and Enright, Brandon and Savage, Stefan},
	year         = 2009,
	booktitle    = {Proceedings of the 9th ACM SIGCOMM conference on Internet measurement conference - IMC '09},
	publisher    = {ACM Press},
	pages        = 15,
	doi          = {10.1145/1644893.1644896},
	isbn         = {978-1-60558-771-4},
	url          = {http://portal.acm.org/citation.cfm?doid=1644893.1644896},
	note         = {tex.ids: yilek2009a, yilekWhenPrivateKeys2009a},
	place        = {Chicago, Illinois, USA},
	abstractnote = {We report on the aftermath of the discovery of a severe vulnerability in the Debian Linux version of OpenSSL. Systems affected by the bug generated predictable random numbers, most importantly public/private keypairs. To study user response to this vulnerability, we collected a novel dataset of daily remote scans of over 50,000 SSL/TLS-enabled Web servers, of which 751 displayed vulnerable certificates. We report three primary results. First, as expected from previous work, we find an extremely slow rate of fixing, with 30\% of the hosts vulnerable when we began our survey on day 4 after disclosure still vulnerable almost six months later. However, unlike conventional vulnerabilities, which typically show a short, fast fixing phase, we observe a much flatter curve with fixing extending six months after the announcement. Second, we identify some predictive factors for the rate of upgrading. Third, we find that certificate authorities continued to issue certificates to servers with weak keys long after the vulnerability was disclosed.}
}
@inproceedings{Zaffarano_Taylor_Hamilton_2015,
	title        = {A Quantitative Framework for Moving Target Defense Effectiveness Evaluation},
	author       = {Zaffarano, Kara and Taylor, Joshua and Hamilton, Samuel},
	year         = 2015,
	booktitle    = {Proceedings of the Second ACM Workshop on Moving Target Defense - MTD '15},
	publisher    = {ACM Press},
	pages        = {3–10},
	doi          = {10.1145/2808475.2808476},
	isbn         = {978-1-4503-3823-3},
	url          = {http://dl.acm.org/citation.cfm?doid=2808475.2808476},
	note         = {tex.ids: zaffarano2015a, zaffaranoQuantitativeFrameworkMoving2015a},
	place        = {Denver, Colorado, USA},
	abstractnote = {Static defense has proven to be a brittle mechanism for defending against cyber attack. Despite this, proactive defensive measures have not been widely deployed. This is because flexible proactive defensive measures such as Moving Target Defense (MTD) have as much potential to interfere with a network's ability to support the mission as they do to defend the network. In this paper we introduce an approach to defining and measuring MTD effects applied in a network environment to help guide MTD deployment decisions that successfully balance the potential security benefits of MTD deployment against the potential productivity costs.}
}
@inproceedings{Zhan_Xu_Xu_2015,
	title        = {A Characterization of Cybersecurity Posture from Network Telescope Data},
	author       = {Zhan, Zhenxin and Xu, Maochao and Xu, Shouhuai},
	year         = 2015,
	booktitle    = {Trusted Systems},
	publisher    = {Springer International Publishing},
	volume       = 9473,
	pages        = {105–126},
	doi          = {10.1007/978-3-319-27998-5\_7},
	isbn         = {978-3-319-27997-8},
	url          = {http://link.springer.com/10.1007/978-3-319-27998-5\_7},
	note         = {tex.ids: zhan2014a, zhanCharacterizationCybersecurityPosture2015a},
	place        = {Cham},
	abstractnote = {Data-driven understanding of cybersecurity posture is an important problem that has not been adequately explored. In this paper, we analyze some real data collected by CAIDA's network telescope during the month of March 2013. We propose to formalize the concept of cybersecurity posture from the perspectives of three kinds of time series: the number of victims (i.e., telescope IP addresses that are attacked), the number of attackers that are observed by the telescope, and the number of attacks that are observed by the telescope. Characterizing cybersecurity posture therefore becomes investigating the phenomena and statistical properties exhibited by these time series, and explaining their cybersecurity meanings. For example, we propose the concept of sweep-time, and show that sweep-time should be modeled by stochastic process, rather than random variable. We report that the number of attackers (and attacks) from a certain country dominates the total number of attackers (and attacks) that are observed by the telescope. We also show that substantially smaller network telescopes might not be as useful as a large telescope.},
	editor       = {Yung, Moti and Zhu, Liehuang and Yang, Yanjiang}
}
@inproceedings{Zhang_Durumeric_Bailey_Liu_Karir_2014,
	title        = {On the Mismanagement and Maliciousness of Networks},
	author       = {Zhang, Jing and Durumeric, Zakir and Bailey, Michael and Liu, Mingyan and Karir, Manish},
	year         = 2014,
	booktitle    = {Proceedings 2014 Network and Distributed System Security Symposium},
	publisher    = {Internet Society},
	doi          = {10.14722/ndss.2014.23057},
	isbn         = {978-1-891562-35-8},
	url          = {https://www.ndss-symposium.org/ndss2014/programme/mismanagement-and-maliciousness-networks/},
	note         = {tex.ids: zhang2014a, zhangMismanagementMaliciousnessNetworks2014a},
	place        = {San Diego, CA},
	abstractnote = {In this paper, we systematically explore the widely held, anecdotal belief that mismanaged networks are responsible for a wide range of security incidents. Utilizing Internet-scale measurements of DNS resolvers, BGP routers, and SMTP, HTTP, and DNS-name servers, we find there are thousands of networks where a large fraction of network services are misconfigured. Combining global feeds of malicious activities including spam, phishing, malware, and scanning, we find a statistically significant correlation between networks that are mismanaged and networks that are responsible for maliciousness.}
}
@article{Zhang_Wang_Jajodia_Singhal_Albanese_2016,
	title        = {Network Diversity: A Security Metric for Evaluating the Resilience of Networks Against Zero-Day Attacks},
	author       = {Zhang, Mengyuan and Wang, Lingyu and Jajodia, Sushil and Singhal, Anoop and Albanese, Massimiliano},
	year         = 2016,
	month        = may,
	journal      = {IEEE Transactions on Information Forensics and Security},
	volume       = 11,
	number       = 5,
	pages        = {1071–1086},
	doi          = {10.1109/TIFS.2016.2516916},
	issn         = {1556-6013, 1556-6021},
	note         = {tex.ids: zhang2016a, zhangNetworkDiversitySecurity2016a, zhangNetworkDiversitySecurity2016b tex.citation-number: 115 publisher: IEEE},
	abstractnote = {Diversity has long been regarded as a security mechanism for improving the resilience of software and networks against various attacks. More recently, diversity has found new applications in cloud computing security, Moving Target Defense (MTD), and improving the robustness of network routing. However, most existing efforts rely on intuitive and imprecise notions of diversity, and the few existing models of diversity are mostly designed for a single system running diverse software replicas or variants. At a higher abstraction level, as a global property of the entire network, diversity and its effect on security have received limited attention. In this paper, we take the first step towards formally modeling network diversity as a security metric by designing and evaluating a series of diversity metrics. Specifically, we first devise a biodiversity-inspired metric based on the effective number of distinct resources. We then propose two complementary diversity metrics, based on the least and the average attacking efforts, respectively. We provide guidelines for instantiating the proposed metrics and present a case study on estimating software diversity. Finally, we evaluate the proposed metrics through simulation.}
}
@inproceedings{Zhang_Zhang_Ou_2014,
	title        = {After we knew it: empirical study and modeling of cost-effectiveness of exploiting prevalent known vulnerabilities across IaaS cloud},
	author       = {Zhang, Su and Zhang, Xinwen and Ou, Xinming},
	year         = 2014,
	booktitle    = {Proceedings of the 9th ACM symposium on Information, computer and communications security - ASIA CCS '14},
	publisher    = {ACM Press},
	pages        = {317–328},
	doi          = {10.1145/2590296.2590300},
	isbn         = {978-1-4503-2800-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2590296.2590300},
	note         = {tex.ids: zhang2014b, zhangWeKnewIt2014a},
	place        = {Kyoto, Japan},
	abstractnote = {Infrastructure as a Service (IaaS) cloud has been attracting more and more customers as it provides the highest level of flexibility by offering configurable virtual machines (VMs) and computing infrastructures. Public VM images are usually available for customers to customize and launch. However, the 1 to N mapping between VM images and running instances in IaaS makes vulnerabilities propagate rapidly across the entire public cloud. Besides, IaaS cloud naturally comes with a larger and more stable attack surface and more concentrated target resources than traditional surroundings. In this paper, we first identify the threat of exploiting prevalent vulnerabilities 1 over public IaaS cloud with an empirical study in Amazon EC2. We find that attackers can compromise a considerable number of VMs with trivial cost. We then do a qualitative cost-effectiveness analysis of this threat. Our main result is a two-fold observation: in IaaS cloud, exploiting prevalent vulnerabilities is much more cost-effective than traditional in-house computing environment, therefore attackers have stronger incentive; Fortunately, on the other hand, cloud defenders (cloud providers and customers) also have much lower cost-loss ratio than in traditional environment, therefore they can be more effective for defending attacks. We then build a game-theoretic model and conduct a risk-gain analysis to compare exploiting and patching strategies under cloud and traditional computing environments. Our modeling indicates that under cloud environment, both attack and defense become less cost-effective as time goes by, and the earlier actioner can be more rewarding. We propose countermeasures against such threat in order to bridge the gap between current security situation and defending mechanisms. To our best knowledge, we are the first to analyze and model the threat with prevalent knownvulnerabilities in public cloud.}
}
@inproceedings{Zheng_Lu_Xu_2015,
	title        = {Active cyber defense dynamics exhibiting rich phenomena},
	author       = {Zheng, Ren and Lu, Wenlian and Xu, Shouhuai},
	year         = 2015,
	booktitle    = {Proceedings of the 2015 Symposium and Bootcamp on the Science of Security - HotSoS '15},
	publisher    = {ACM Press},
	pages        = {1–12},
	doi          = {10.1145/2746194.2746196},
	isbn         = {978-1-4503-3376-4},
	url          = {http://dl.acm.org/citation.cfm?doid=2746194.2746196},
	note         = {tex.ids: zheng2015a, zhengActiveCyberDefense2015a, zhengActiveCyberDefense2015b, zhengActiveCyberDefense2015c},
	place        = {Urbana, Illinois},
	abstractnote = {The Internet is a man-made complex system under constant attacks (e.g., Advanced Persistent Threats and malwares). It is therefore important to understand the phenomena that can be induced by the interaction between cyber attacks and cyber defenses. In this paper, we explore the rich phenomena that can be exhibited when the defender employs active defense to combat cyber attacks. To the best of our knowledge, this is the first study that shows that active cyber defense dynamics (or more generally, cybersecurity dynamics) can exhibit the bifurcation and chaos phenomena. This has profound implications for cyber security measurement and prediction: (i) it is infeasible (or even impossible) to accurately measure and predict cyber security under certain circumstances; (ii) the defender must manipulate the dynamics to avoid such unmanageable situations in real-life defense operations.}
}
