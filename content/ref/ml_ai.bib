@inproceedings{Chawla_Lazarevic_Hall_Bowyer_2003,
	title        = {SMOTEBoost: Improving prediction of the minority class in boosting},
	author       = {Chawla, Nitesh V. and Lazarevic, Aleksandar and Hall, Lawrence O. and Bowyer, Kevin W.},
	year         = 2003,
	booktitle    = {European Conference on Principles of Data Mining and Knowledge Discovery},
	publisher    = {Springer},
	pages        = {107–119},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-39804-2_12}
}
@inbook{Isaksson_Dunham_Hahsler_2012,
	title        = {SOStream: Self Organizing Density-Based Clustering over Data Stream},
	author       = {Isaksson, Charlie and Dunham, Margaret H. and Hahsler, Michael},
	year         = 2012,
	booktitle    = {Machine Learning and Data Mining in Pattern Recognition},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 7376,
	pages        = {264–278},
	isbn         = {978-3-642-31536-7},
	url          = {http://link.springer.com/10.1007/978-3-642-31537-4_21},
	place        = {Berlin, Heidelberg},
	editor       = {Perner, PetraEditor}
}
@inproceedings{Kang_Hauswald_Gao_Rovinski_Mudge_Mars_Tang_2017,
	title        = {Neurosurgeon: Collaborative intelligence between the cloud and mobile edge},
	author       = {Kang, Yiping and Hauswald, Johann and Gao, Cao and Rovinski, Austin and Mudge, Trevor and Mars, Jason and Tang, Lingjia},
	year         = 2017,
	booktitle    = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher    = {ACM},
	pages        = {615–629}
}
@article{King_Zeng_2001,
	title        = {Logistic regression in rare events data},
	author       = {King, Gary and Zeng, Langche},
	year         = 2001,
	journal      = {Political analysis},
	volume       = 9,
	number       = 2,
	pages        = {137–163}
}
@article{Kingma_Ba_2014,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik and Ba, Jimmy},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.6980},
	url          = {https://arxiv.org/abs/1412.6980}
}
@article{LeCun_Bengio_Hinton_2015,
	title        = {Deep learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	month        = {05},
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436–444},
	doi          = {10.1038/nature14539},
	issn         = {0028-0836},
	abstractnote = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}
@inproceedings{Maclaurin_Duvenaud_Adams_2015,
	title        = {Gradient-based Hyperparameter Optimization through Reversible Learning.},
	author       = {Maclaurin, Dougal and Duvenaud, David K. and Adams, Ryan P.},
	year         = 2015,
	booktitle    = {ICML},
	pages        = {2113–2122},
	url          = {http://www.jmlr.org/proceedings/papers/v37/maclaurin15.pdf}
}
@article{Snoek_Larochelle_Adams_2012,
	title        = {Practical Bayesian Optimization of Machine Learning Algorithms},
	author       = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	year         = 2012,
	month        = {06},
	journal      = {arXiv:1206.2944 [cs, stat]},
	url          = {http://arxiv.org/abs/1206.2944},
	note         = {arXiv: 1206.2944},
	abstractnote = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a “black art” that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.}
}
@article{Snoek_Rippel_Swersky_Kiros_Satish_Sundaram_Patwary_Prabhat_Adams_2015,
	title        = {Scalable Bayesian Optimization Using Deep Neural Networks},
	author       = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
	year         = 2015,
	month        = {02},
	journal      = {arXiv:1502.05700 [stat]},
	url          = {http://arxiv.org/abs/1502.05700},
	note         = {arXiv: 1502.05700},
	abstractnote = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}
@article{Boutaba_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
@article{Buczak_Guven_2016,
	title        = {A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection},
	author       = {Buczak, Anna L. and Guven, Erhan},
	year         = 2016,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 18,
	number       = 2,
	pages        = {1153–1176},
	doi          = {10.1109/COMST.2015.2494502},
	issn         = {2373-745X},
	abstractnote = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@book{ml_telecom_med,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	place        = {Washington, D.C.},
	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
}
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker’s goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM ’18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network’s normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices’ context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks’ Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the ﬁeld of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE—a fast, scalable, and effective model, whose single-thread version is 10–400× faster than efﬁcient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE ﬁrst initializes network embeddings efﬁciently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and signiﬁcant efﬁciency superiority when compared to the aforementioned baselines. In addition, ProNE’s embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
@article{journa_1,
	volume       = 2,
	number       = 2,
	pages        = 6,
	abstractnote = {An intrusion detection system is software that monitors a single or a network of computers for malicious activities that are aimed at stealing or censoring information or corrupting network protocols. Most technique used in today’s intrusion detection system are not able to deal with the dynamic and complex nature of cyber-attacks on computer networks. Even though efficient adaptive methods like various techniques of machine learning can result in higher detection rates, lower false alarm rates and reasonable computation and communication cost. With the use of data mining can result in frequent pattern mining, classification, clustering and mini data stream. This survey paper describes a focused literature survey of machine learning and data mining methods for cyber analytics in support of intrusion detection. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in machine learning and data mining approaches, some well-known cyber data sets used in machine learning and data mining are described for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@article{Denker,
	title        = {Large Automatic Learning, Rule Extraction, and Generalization},
	author       = {Denker, John},
	pages        = 46
}
@book{Sutton_Barto_2018,
	title        = {Reinforcement learning: an introduction},
	author       = {Sutton, Richard S. and Barto, Andrew G.},
	year         = 2018,
	publisher    = {The MIT Press},
	series       = {Adaptive computation and machine learning series},
	isbn         = {978-0-262-03924-6},
	place        = {Cambridge, Massachusetts},
	edition      = {Second edition},
	abstractnote = {“Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field’s key ideas and algorithms.”--},
	collection   = {Adaptive computation and machine learning series}
}
@article{Zhang_Patras_Haddadi_2019,
	title        = {Deep Learning in Mobile and Wireless Networking: A Survey},
	author       = {Zhang, Chaoyun and Patras, Paul and Haddadi, Hamed},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1803.04311 [cs]},
	url          = {http://arxiv.org/abs/1803.04311},
	note         = {arXiv: 1803.04311},
	abstractnote = {The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile trafﬁc volumes, real-time extraction of ﬁne-grained analytics, and agile management of network resources, so as to maximize user experience. Fulﬁlling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space.}
}
@article{Xin_Kong_Liu_Chen_Li_Zhu_Gao_Hou_Wang_2018,
	title        = {Machine Learning and Deep Learning Methods for Cybersecurity},
	author       = {Xin, Yang and Kong, Lingshuang and Liu, Zhi and Chen, Yuling and Li, Yanmiao and Zhu, Hongliang and Gao, Mingcheng and Hou, Haixia and Wang, Chunhua},
	year         = 2018,
	journal      = {IEEE Access},
	volume       = 6,
	pages        = {35365–35381},
	doi          = {10.1109/ACCESS.2018.2836950},
	issn         = {2169-3536},
	abstractnote = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.}
}
@inproceedings{Mohamed_Salleh_Omar_2012,
	title        = {A comparative study of Reduced Error Pruning method in decision tree algorithms},
	author       = {Mohamed, W. Nor Haizan W. and Salleh, Mohd Najib Mohd and Omar, Abdul Halim},
	year         = 2012,
	month        = nov,
	booktitle    = {2012 IEEE International Conference on Control System, Computing and Engineering},
	pages        = {392–397},
	doi          = {10.1109/ICCSCE.2012.6487177},
	issn         = {null},
	abstractnote = {Decision tree is one of the most popular and efficient technique in data mining. This technique has been established and well-explored by many researchers. However, some decision tree algorithms may produce a large structure of tree size and it is difficult to understand. Furthermore, misclassification of data often occurs in learning process. Therefore, a decision tree algorithm that can produce a simple tree structure with high accuracy in term of classification rate is a need to work with huge volume of data. Pruning methods have been introduced to reduce the complexity of tree structure without decrease the accuracy of classification. One of pruning methods is the Reduced Error Pruning (REP). To better understand pruning methods, an experiment was conducted using Weka application to compare the performance in term of complexity of tree structure and accuracy of classification for J 48, REPTree, PART, JRip, and Ridor algorithms using seven standard datasets from UCI machine learning repository. In data modeling, J48 and REPTree generate tree structure as an output while PART, Ridor and JRip generate rules. In additional J48, REPTree and PART using REP method for pruning while Ridor and JRip using improvement of REP method, namely IREP and RIPPER methods. The experiment result shown performance of J48 and REPTree are competitive in producing better result. Between J48 and REPTree, average differences performance of accuracy of classification is 7.1006\% and 6.285\% for complexity of tree structure. For classification rules algorithms, Ridor is the best algorithms compare to PART and JRip due to highest percentage of accuracy of classification in five dataset from seven datasets. An algorithm that produces high accuracy with simple tree structure or simple rules can be awarded as the best algorithm in decision tree.}
}
@book{Chang_2019,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
}
@inbook{Noel_2018,
	title        = {Text Mining for Modeling Cyberattacks},
	author       = {Noel, Steven},
	year         = 2018,
	month        = jan,
	booktitle    = {Handbook of Statistics},
	doi          = {10.1016/bs.host.2018.06.001},
	abstractnote = {This chapter examines how natural language processing can be applied for building rich models for cybersecurity analytics. For this, it applies text mining to the natural-language content of Common Attack Pattern Enumeration and Classification (CAPECTM), a standardized corpus of cyberattack patterns. We adopt a vector-space model in which CAPEC attack patterns are treated as documents with term vectors. This provides a space in which to define distance measures, such as for retrieving attack patterns through term queries or finding clusters of related attack patterns. Analysis of clustering patterns, i.e., cluster hierarchies (clusters within clusters) is aided through tree visualization techniques. These analytic and visual techniques provide a range of capabilities for leveraging the content and relationships in CAPEC, e.g., for building more complex security models such as network attack graphs.}
}
