@article{Boutaba_Salahuddin_Limam_Ayoubi_Shahriar_Estrada-Solano_Caicedo_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
@article{Bruna_Zaremba_Szlam_LeCun_2014,
	title        = {Spectral Networks and Locally Connected Networks on Graphs},
	author       = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	year         = 2014,
	month        = may,
	journal      = {arXiv:1312.6203 [cs]},
	url          = {http://arxiv.org/abs/1312.6203},
	note         = {arXiv: 1312.6203},
	abstractnote = {Convolutional Neural Networks are extremely efﬁcient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals deﬁned on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efﬁcient deep architectures.}
}
@article{Buczak_Guven_2016,
	title        = {A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection},
	author       = {Buczak, Anna L. and Guven, Erhan},
	year         = 2016,
	journal      = {IEEE Communications Surveys Tutorials},
	volume       = 18,
	number       = 2,
	pages        = {1153–1176},
	doi          = {10.1109/COMST.2015.2494502},
	issn         = {2373-745X},
	abstractnote = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@article{Chen,
	title        = {Directed Graph Embedding},
	author       = {Chen, Mo},
	pages        = 6,
	abstractnote = {In this paper, we propose the Directed Graph Embedding (DGE) method that embeds vertices on a directed graph into a vector space by considering the link structure of graphs. The basic idea is to preserve the locality property of vertices on a directed graph in the embedded space. We use the transition probability together with the stationary distribution of Markov random walks to measure such locality property. It turns out that by exploring the directed links of the graph using random walks, we can get an optimal embedding on the vector space that preserves the local affinity which is inherent in the directed graph. Experiments on both synthetic data and real-world Web page data are considered. The application of our method to Web page classification problems gets a significant improvement comparing with state-of-art methods.}
}
@book{ai_cybersec,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	place        = {Washington, D.C.},
	editor       = {Johnson, Anne and Grumbling, Emily}
}
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@article{Dai_Li_Tian_Huang_Wang_Zhu_Song_2018,
	title        = {Adversarial Attack on Graph Structured Data},
	author       = {Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.02371 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.02371},
	note         = {arXiv: 1806.02371},
	abstractnote = {Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We ﬁrst propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classiﬁer. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction conﬁdence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classiﬁcation tasks. We also show such attacks can be used to diagnose the learned classiﬁers.}
}
@inproceedings{Dua_Du_2011,
	title        = {Data Mining and Machine Learning in Cybersecurity},
	author       = {Dua, Sumeet and Du, Xian},
	year         = 2011,
	doi          = {10.1201/b10867},
	abstractnote = {With the rapid advancement of information discovery techniques, machine learning and data mining continue to play a significant role in cybersecurity. Although several conferences, workshops, and journals focus on the fragmented research topics in this area, there has been no single interdisciplinary resource on past and current works and possible paths for future research in this area. This book fills this need. From basic concepts in machine learning and data mining to advanced problems in the machine learning domain, Data Mining and Machine Learning in Cybersecurity provides a unified reference for specific machine learning solutions to cybersecurity problems. It supplies a foundation in cybersecurity fundamentals and surveys contemporary challengesdetailing cutting-edge machine learning and data mining techniques. It also: Unveils cutting-edge techniques for detectingnew attacks Contains in-depth discussions of machine learning solutions to detection problems Categorizes methods for detecting, scanning, and profiling intrusions and anomalies Surveys contemporary cybersecurity problems and unveils state-of-the-art machine learning and data mining solutions Details privacy-preserving data mining methods This interdisciplinary resource includes technique review tables that allow for speedy access to common cybersecurity problems and associated data mining methods. Numerous illustrative figures help readers visualize the workflow of complex techniques and more than forty case studies provide a clear understanding of the design and application of data mining and machine learning techniques in cybersecurity.}
}
@article{Goyal_Ferrara_2018,
	title        = {Graph Embedding Techniques, Applications, and Performance: A Survey},
	author       = {Goyal, Palash and Ferrara, Emilio},
	year         = 2018,
	month        = jul,
	journal      = {Knowledge-Based Systems},
	volume       = 151,
	pages        = {78–94},
	doi          = {10.1016/j.knosys.2018.03.022},
	issn         = {09507051},
	note         = {arXiv: 1705.02801},
	abstractnote = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and diﬀerent patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We ﬁrst introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We ﬁnally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a uniﬁed interface to foster and facilitate research on the topic.}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@article{Hamilton_Ying_Leskovec,
	title        = {Representation Learning on Graphs: Methods and Applications},
	author       = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
	pages        = 23,
	abstractnote = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is ﬁnding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-deﬁned heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph convolutional networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a uniﬁed framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker’s goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@inproceedings{Kutuzov_Dorgham_Oliynyk_Biemann_Panchenko_2019,
	title        = {Making Fast Graph\-based Algorithms with Graph Metric Embeddings},
	author       = {Kutuzov, Andrey and Dorgham, Mohammad and Oliynyk, Oleksiy and Biemann, Chris and Panchenko, Alexander},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	pages        = {3349–3355},
	doi          = {10.18653/v1/P19-1325},
	url          = {https://www.aclweb.org/anthology/P19-1325},
	place        = {Florence, Italy},
	abstractnote = {The computation of distance measures between nodes in graphs is inefﬁcient and does not scale to large graphs. We explore dense vector representations as an effective way to approximate the same information: we introduce a simple yet efﬁcient and effective approach for learning graph embeddings. Instead of directly operating on the graph structure, our method takes structural measures of pairwise node similarities into account and learns dense node representations reﬂecting user-deﬁned graph distance measures, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings on semantic similarity and word sense disambiguation tasks and show evaluations on the WordNet graph and two knowledge base graphs.}
}
@article{Li_Tarlow_Brockschmidt_Zemel_2017,
	title        = {Gated Graph Sequence Neural Networks},
	author       = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
	year         = 2017,
	month        = sep,
	journal      = {arXiv:1511.05493 [cs, stat]},
	url          = {http://arxiv.org/abs/1511.05493},
	note         = {arXiv: 1511.05493},
	abstractnote = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a ﬂexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program veriﬁcation, in which subgraphs need to be described as abstract data structures.}
}
@article{Oroojlooyjadid_2019,
	title        = {A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning algorithm to Solve Inventory Optimization Problems},
	author       = {Oroojlooyjadid, Afshin and Nazari, MohammadReza and Snyder, Lawrence and Takáč, Martin},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1708.05924 [cs]},
	url          = {http://arxiv.org/abs/1708.05924},
	note         = {arXiv: 1708.05924},
	abstractnote = {The beer game is a widely used in-class game that is played in supply chain management classes to demonstrate the bullwhip effect. The game is a decentralized, multi-agent, cooperative problem that can be modeled as a serial supply chain network in which agents cooperatively attempt to minimize the total cost of the network even though each agent can only observe its own local information. Each agent chooses order quantities to replenish its stock. Under some conditions, a base-stock replenishment policy is known to be optimal. However, in a decentralized supply chain in which some agents (stages) may act irrationally (as they do in the beer game), there is no known optimal policy for an agent wishing to act optimally. We propose a machine learning algorithm, based on deep Q-networks, to optimize the replenishment decisions at a given stage. When playing alongside agents who follow a base-stock policy, our algorithm obtains near-optimal order quantities. It performs much better than a base-stock policy when the other agents use a more realistic model of human ordering behavior. Unlike most other algorithms in the literature, our algorithm does not have any limits on the beer game parameter values. Like any deep learning algorithm, training the algorithm can be computationally intensive, but this can be performed ahead of time; the algorithm executes in real time when the game is played. Moreover, we propose a transfer learning approach so that the training performed for one agent and one set of cost coefficients can be adapted quickly for other agents and costs. Our algorithm can be extended to other decentralized multi-agent cooperative games with partially observed information, which is a common type of situation in real-world supply chain problems.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM ’18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network’s normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices’ context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks’ Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@book{Sutton_Barto_2018,
	title        = {Reinforcement learning: an introduction},
	author       = {Sutton, Richard S. and Barto, Andrew G.},
	year         = 2018,
	publisher    = {The MIT Press},
	series       = {Adaptive computation and machine learning series},
	isbn         = {978-0-262-03924-6},
	place        = {Cambridge, Massachusetts},
	edition      = {Second edition},
	abstractnote = {“Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field’s key ideas and algorithms.”--},
	collection   = {Adaptive computation and machine learning series}
}
@inproceedings{Tang_Mhamdi_McLernon_Zaidi_Ghogho_2016,
	title        = {Deep learning approach for Network Intrusion Detection in Software Defined Networking},
	author       = {Tang, Tuan A and Mhamdi, Lotfi and McLernon, Des and Zaidi, Syed Ali Raza and Ghogho, Mounir},
	year         = 2016,
	month        = oct,
	booktitle    = {2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)},
	publisher    = {IEEE},
	pages        = {258–263},
	doi          = {10.1109/WINCOM.2016.7777224},
	isbn         = {978-1-5090-3837-4},
	url          = {http://ieeexplore.ieee.org/document/7777224/},
	place        = {Fez, Morocco},
	abstractnote = {Software Deﬁned Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for ﬂow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSLKDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the fortyone features of NSL-KDD Dataset. Through experiments, we conﬁrm that the deep learning approach shows strong potential to be used for ﬂow-based anomaly detection in SDN environments.}
}
@article{Xin_Kong_Liu_Chen_Li_Zhu_Gao_Hou_Wang_2018,
	title        = {Machine Learning and Deep Learning Methods for Cybersecurity},
	author       = {Xin, Yang and Kong, Lingshuang and Liu, Zhi and Chen, Yuling and Li, Yanmiao and Zhu, Hongliang and Gao, Mingcheng and Hou, Haixia and Wang, Chunhua},
	year         = 2018,
	journal      = {IEEE Access},
	volume       = 6,
	pages        = {35365–35381},
	doi          = {10.1109/ACCESS.2018.2836950},
	issn         = {2169-3536},
	note         = {tex.ids: xinMachineLearningDeep2018a},
	abstractnote = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the ﬁeld of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE—a fast, scalable, and effective model, whose single-thread version is 10–400× faster than efﬁcient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE ﬁrst initializes network embeddings efﬁciently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and signiﬁcant efﬁciency superiority when compared to the aforementioned baselines. In addition, ProNE’s embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
@inproceedings{Chawla_Lazarevic_Hall_Bowyer_2003,
	title        = {SMOTEBoost: Improving prediction of the minority class in boosting},
	author       = {Chawla, Nitesh V. and Lazarevic, Aleksandar and Hall, Lawrence O. and Bowyer, Kevin W.},
	year         = 2003,
	booktitle    = {European Conference on Principles of Data Mining and Knowledge Discovery},
	publisher    = {Springer},
	pages        = {107–119},
	url          = {http://link.springer.com/chapter/10.1007/978-3-540-39804-2_12}
}
@inbook{Isaksson_Dunham_Hahsler_2012,
	title        = {SOStream: Self Organizing Density-Based Clustering over Data Stream},
	author       = {Isaksson, Charlie and Dunham, Margaret H. and Hahsler, Michael},
	year         = 2012,
	booktitle    = {Machine Learning and Data Mining in Pattern Recognition},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 7376,
	pages        = {264–278},
	isbn         = {978-3-642-31536-7},
	url          = {http://link.springer.com/10.1007/978-3-642-31537-4_21},
	place        = {Berlin, Heidelberg},
	editor       = {Perner, PetraEditor}
}
@inproceedings{Kang_Hauswald_Gao_Rovinski_Mudge_Mars_Tang_2017,
	title        = {Neurosurgeon: Collaborative intelligence between the cloud and mobile edge},
	author       = {Kang, Yiping and Hauswald, Johann and Gao, Cao and Rovinski, Austin and Mudge, Trevor and Mars, Jason and Tang, Lingjia},
	year         = 2017,
	booktitle    = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher    = {ACM},
	pages        = {615–629}
}
@article{King_Zeng_2001,
	title        = {Logistic regression in rare events data},
	author       = {King, Gary and Zeng, Langche},
	year         = 2001,
	journal      = {Political analysis},
	volume       = 9,
	number       = 2,
	pages        = {137–163}
}
@article{Kingma_Ba_2014,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik and Ba, Jimmy},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.6980},
	url          = {https://arxiv.org/abs/1412.6980}
}
@article{LeCun_Bengio_Hinton_2015,
	title        = {Deep learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	month        = {05},
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436–444},
	doi          = {10.1038/nature14539},
	issn         = {0028-0836},
	abstractnote = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}
@inproceedings{Maclaurin_Duvenaud_Adams_2015,
	title        = {Gradient-based Hyperparameter Optimization through Reversible Learning.},
	author       = {Maclaurin, Dougal and Duvenaud, David K. and Adams, Ryan P.},
	year         = 2015,
	booktitle    = {ICML},
	pages        = {2113–2122},
	url          = {http://www.jmlr.org/proceedings/papers/v37/maclaurin15.pdf}
}
@article{Snoek_Larochelle_Adams_2012,
	title        = {Practical Bayesian Optimization of Machine Learning Algorithms},
	author       = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	year         = 2012,
	month        = {06},
	journal      = {arXiv:1206.2944 [cs, stat]},
	url          = {http://arxiv.org/abs/1206.2944},
	note         = {arXiv: 1206.2944},
	abstractnote = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a “black art” that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.}
}
@article{Snoek_Rippel_Swersky_Kiros_Satish_Sundaram_Patwary_Prabhat_Adams_2015,
	title        = {Scalable Bayesian Optimization Using Deep Neural Networks},
	author       = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P.},
	year         = 2015,
	month        = {02},
	journal      = {arXiv:1502.05700 [stat]},
	url          = {http://arxiv.org/abs/1502.05700},
	note         = {arXiv: 1502.05700},
	abstractnote = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.}
}
@article{Boutaba_2018,
	title        = {A comprehensive survey on machine learning for networking: evolution, applications and research opportunities},
	author       = {Boutaba, Raouf and Salahuddin, Mohammad A. and Limam, Noura and Ayoubi, Sara and Shahriar, Nashid and Estrada-Solano, Felipe and Caicedo, Oscar M.},
	year         = 2018,
	month        = jun,
	journal      = {Journal of Internet Services and Applications},
	volume       = 9,
	number       = 1,
	pages        = 16,
	doi          = {10.1186/s13174-018-0087-2},
	issn         = {1869-0238},
	abstractnote = {Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.}
}
% @book{ml_telecom_med,
% 	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
% 	author       = {Computer Science and Telecommunications Board and Intelligence Community Studies Board and Division on Engineering and Physical Sciences and National Academies of Sciences, Engineering, and Medicine},
% 	year         = 2019,
% 	month        = dec,
% 	publisher    = {National Academies Press},
% 	doi          = {10.17226/25488},
% 	isbn         = {978-0-309-49450-2},
% 	url          = {https://www.nap.edu/catalog/25488},
% 	place        = {Washington, D.C.},
% 	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
% }
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker’s goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM ’18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network’s normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices’ context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks’ Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the ﬁeld of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE—a fast, scalable, and effective model, whose single-thread version is 10–400× faster than efﬁcient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE ﬁrst initializes network embeddings efﬁciently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and signiﬁcant efﬁciency superiority when compared to the aforementioned baselines. In addition, ProNE’s embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
@article{journa_1,
	volume       = 2,
	number       = 2,
	pages        = 6,
	abstractnote = {An intrusion detection system is software that monitors a single or a network of computers for malicious activities that are aimed at stealing or censoring information or corrupting network protocols. Most technique used in today’s intrusion detection system are not able to deal with the dynamic and complex nature of cyber-attacks on computer networks. Even though efficient adaptive methods like various techniques of machine learning can result in higher detection rates, lower false alarm rates and reasonable computation and communication cost. With the use of data mining can result in frequent pattern mining, classification, clustering and mini data stream. This survey paper describes a focused literature survey of machine learning and data mining methods for cyber analytics in support of intrusion detection. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in machine learning and data mining approaches, some well-known cyber data sets used in machine learning and data mining are described for cyber security is presented, and some recommendations on when to use a given method are provided.}
}
@article{Denker,
	title        = {Large Automatic Learning, Rule Extraction, and Generalization},
	author       = {Denker, John},
	pages        = 46
}
@article{Zhang_Patras_Haddadi_2019,
	title        = {Deep Learning in Mobile and Wireless Networking: A Survey},
	author       = {Zhang, Chaoyun and Patras, Paul and Haddadi, Hamed},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1803.04311 [cs]},
	url          = {http://arxiv.org/abs/1803.04311},
	note         = {arXiv: 1803.04311},
	abstractnote = {The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile trafﬁc volumes, real-time extraction of ﬁne-grained analytics, and agile management of network resources, so as to maximize user experience. Fulﬁlling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space.}
}
@inproceedings{Mohamed_Salleh_Omar_2012,
	title        = {A comparative study of Reduced Error Pruning method in decision tree algorithms},
	author       = {Mohamed, W. Nor Haizan W. and Salleh, Mohd Najib Mohd and Omar, Abdul Halim},
	year         = 2012,
	month        = nov,
	booktitle    = {2012 IEEE International Conference on Control System, Computing and Engineering},
	pages        = {392–397},
	doi          = {10.1109/ICCSCE.2012.6487177},
	issn         = {null},
	abstractnote = {Decision tree is one of the most popular and efficient technique in data mining. This technique has been established and well-explored by many researchers. However, some decision tree algorithms may produce a large structure of tree size and it is difficult to understand. Furthermore, misclassification of data often occurs in learning process. Therefore, a decision tree algorithm that can produce a simple tree structure with high accuracy in term of classification rate is a need to work with huge volume of data. Pruning methods have been introduced to reduce the complexity of tree structure without decrease the accuracy of classification. One of pruning methods is the Reduced Error Pruning (REP). To better understand pruning methods, an experiment was conducted using Weka application to compare the performance in term of complexity of tree structure and accuracy of classification for J 48, REPTree, PART, JRip, and Ridor algorithms using seven standard datasets from UCI machine learning repository. In data modeling, J48 and REPTree generate tree structure as an output while PART, Ridor and JRip generate rules. In additional J48, REPTree and PART using REP method for pruning while Ridor and JRip using improvement of REP method, namely IREP and RIPPER methods. The experiment result shown performance of J48 and REPTree are competitive in producing better result. Between J48 and REPTree, average differences performance of accuracy of classification is 7.1006\% and 6.285\% for complexity of tree structure. For classification rules algorithms, Ridor is the best algorithms compare to PART and JRip due to highest percentage of accuracy of classification in five dataset from seven datasets. An algorithm that produces high accuracy with simple tree structure or simple rules can be awarded as the best algorithm in decision tree.}
}
@book{Chang_2019,
	title        = {Implications of Artificial Intelligence for Cybersecurity: Proceedings of a Workshop},
	year         = 2019,
	month        = dec,
	publisher    = {National Academies Press},
	doi          = {10.17226/25488},
	isbn         = {978-0-309-49450-2},
	url          = {https://www.nap.edu/catalog/25488},
	editor       = {Johnson, Anne and Grumbling, EmilyEditors}
}
@inbook{Noel_2018,
	title        = {Text Mining for Modeling Cyberattacks},
	author       = {Noel, Steven},
	year         = 2018,
	month        = jan,
	booktitle    = {Handbook of Statistics},
	doi          = {10.1016/bs.host.2018.06.001},
	abstractnote = {This chapter examines how natural language processing can be applied for building rich models for cybersecurity analytics. For this, it applies text mining to the natural-language content of Common Attack Pattern Enumeration and Classification (CAPECTM), a standardized corpus of cyberattack patterns. We adopt a vector-space model in which CAPEC attack patterns are treated as documents with term vectors. This provides a space in which to define distance measures, such as for retrieving attack patterns through term queries or finding clusters of related attack patterns. Analysis of clustering patterns, i.e., cluster hierarchies (clusters within clusters) is aided through tree visualization techniques. These analytic and visual techniques provide a range of capabilities for leveraging the content and relationships in CAPEC, e.g., for building more complex security models such as network attack graphs.}
}
@article{Bacciu_Errica_Micheli_Podda_2019,
	title        = {A Gentle Introduction to Deep Learning for Graphs},
	author       = {Bacciu, Davide and Errica, Federico and Micheli, Alessio and Podda, Marco},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1912.12693 [cs, stat]},
	url          = {http://arxiv.org/abs/1912.12693},
	note         = {arXiv: 1912.12693},
	abstractnote = {The adaptive processing of graph data is a long-standing research topic which has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is designed as a tutorial introduction to the field of deep learning for graphs. It favours a consistent and progressive introduction of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view to the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. It introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. The methodological exposition is complemented by a discussion of interesting research challenges and applications in the field.}
}
@article{Bruna_Zaremba_Szlam_LeCun_2014,
	title        = {Spectral Networks and Locally Connected Networks on Graphs},
	author       = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	year         = 2014,
	month        = may,
	journal      = {arXiv:1312.6203 [cs]},
	url          = {http://arxiv.org/abs/1312.6203},
	note         = {arXiv: 1312.6203},
	abstractnote = {Convolutional Neural Networks are extremely efﬁcient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals deﬁned on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efﬁcient deep architectures.}
}
@article{Chen,
	title        = {Directed Graph Embedding},
	author       = {Chen, Mo},
	pages        = 6,
	abstractnote = {In this paper, we propose the Directed Graph Embedding (DGE) method that embeds vertices on a directed graph into a vector space by considering the link structure of graphs. The basic idea is to preserve the locality property of vertices on a directed graph in the embedded space. We use the transition probability together with the stationary distribution of Markov random walks to measure such locality property. It turns out that by exploring the directed links of the graph using random walks, we can get an optimal embedding on the vector space that preserves the local affinity which is inherent in the directed graph. Experiments on both synthetic data and real-world Web page data are considered. The application of our method to Web page classification problems gets a significant improvement comparing with state-of-art methods.}
}
@article{Cui_Wang_Pei_Zhu_2019,
	title        = {A Survey on Network Embedding},
	author       = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year         = 2019,
	month        = may,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 31,
	number       = 5,
	pages        = {833–852},
	doi          = {10.1109/TKDE.2018.2849727},
	issn         = {1041-4347, 1558-2191, 2326-3865}
}
@article{Dai_Li_Tian_Huang_Wang_Zhu_Song_2018,
	title        = {Adversarial Attack on Graph Structured Data},
	author       = {Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.02371 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.02371},
	note         = {arXiv: 1806.02371},
	abstractnote = {Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We ﬁrst propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classiﬁer. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction conﬁdence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classiﬁcation tasks. We also show such attacks can be used to diagnose the learned classiﬁers.}
}
@inproceedings{Dua_Du_2011,
	title        = {Data Mining and Machine Learning in Cybersecurity},
	author       = {Dua, Sumeet and Du, Xian},
	year         = 2011,
	doi          = {10.1201/b10867},
	abstractnote = {With the rapid advancement of information discovery techniques, machine learning and data mining continue to play a significant role in cybersecurity. Although several conferences, workshops, and journals focus on the fragmented research topics in this area, there has been no single interdisciplinary resource on past and current works and possible paths for future research in this area. This book fills this need. From basic concepts in machine learning and data mining to advanced problems in the machine learning domain, Data Mining and Machine Learning in Cybersecurity provides a unified reference for specific machine learning solutions to cybersecurity problems. It supplies a foundation in cybersecurity fundamentals and surveys contemporary challengesdetailing cutting-edge machine learning and data mining techniques. It also: Unveils cutting-edge techniques for detectingnew attacks Contains in-depth discussions of machine learning solutions to detection problems Categorizes methods for detecting, scanning, and profiling intrusions and anomalies Surveys contemporary cybersecurity problems and unveils state-of-the-art machine learning and data mining solutions Details privacy-preserving data mining methods This interdisciplinary resource includes technique review tables that allow for speedy access to common cybersecurity problems and associated data mining methods. Numerous illustrative figures help readers visualize the workflow of complex techniques and more than forty case studies provide a clear understanding of the design and application of data mining and machine learning techniques in cybersecurity.}
}
@article{Hahsler_Chelluboina,
	title        = {Visualizing Association Rules: Introduction to the R-extension Package arulesViz},
	author       = {Hahsler, Michael and Chelluboina, Sudheer},
	pages        = 24,
	abstractnote = {Association rule mining is a popular data mining method available in R as the extension package arules. However, mining association rules often results in a very large number of found rules, leaving the analyst with the task to go through all the rules and discover interesting ones. Sifting manually through large sets of rules is time consuming and strenuous. Visualization has a long history of making large data sets better accessible using techniques like selecting and zooming. In this paper we present the R-extension package arulesViz which implements several known and novel visualization techniques to explore association rules. With examples we show how these visualization techniques can be used to analyze a data set.}
}
@article{Hoskins_Musco_Musco_Tsourakakis_2018,
	title        = {Learning Networks from Random Walk-Based Node Similarities},
	author       = {Hoskins, Jeremy G. and Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	year         = 2018,
	month        = jan,
	journal      = {arXiv:1801.07386 [cs]},
	url          = {http://arxiv.org/abs/1801.07386},
	note         = {arXiv: 1801.07386},
	abstractnote = {Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker’s goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. For the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. We obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at https://github.com/cnmusco/graph-similarity-learning.}
}
@article{Ivanov_Sviridov_Burnaev_2019,
	title        = {Understanding Isomorphism Bias in Graph Data Sets},
	author       = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.12091 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.12091},
	note         = {arXiv: 1910.12091},
	abstractnote = {In recent years there has been a rapid increase in classification methods on graph structured data. Both in graph kernels and graph neural networks, one of the implicit assumptions of successful state-of-the-art models was that incorporating graph isomorphism features into the architecture leads to better empirical performance. However, as we discover in this work, commonly used data sets for graph classification have repeating instances which cause the problem of isomorphism bias, i.e. artificially increasing the accuracy of the models by memorizing target information from the training set. This prevents fair competition of the algorithms and raises a question of the validity of the obtained results. We analyze 54 data sets, previously extensively used for graph-related tasks, on the existence of isomorphism bias, give a set of recommendations to machine learning practitioners to properly set up their models, and open source new data sets for the future experiments.}
}
@article{Li_Tarlow_Brockschmidt_Zemel_2017,
	title        = {Gated Graph Sequence Neural Networks},
	author       = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
	year         = 2017,
	month        = sep,
	journal      = {arXiv:1511.05493 [cs, stat]},
	url          = {http://arxiv.org/abs/1511.05493},
	note         = {arXiv: 1511.05493},
	abstractnote = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a ﬂexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program veriﬁcation, in which subgraphs need to be described as abstract data structures.}
}
@article{Oroojlooyjadid_Nazari_Snyder_Takáč_2019,
	title        = {A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning algorithm to Solve Inventory Optimization Problems},
	author       = {Oroojlooyjadid, Afshin and Nazari, MohammadReza and Snyder, Lawrence and Takáč, Martin},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1708.05924 [cs]},
	url          = {http://arxiv.org/abs/1708.05924},
	note         = {arXiv: 1708.05924},
	abstractnote = {The beer game is a widely used in-class game that is played in supply chain management classes to demonstrate the bullwhip effect. The game is a decentralized, multi-agent, cooperative problem that can be modeled as a serial supply chain network in which agents cooperatively attempt to minimize the total cost of the network even though each agent can only observe its own local information. Each agent chooses order quantities to replenish its stock. Under some conditions, a base-stock replenishment policy is known to be optimal. However, in a decentralized supply chain in which some agents (stages) may act irrationally (as they do in the beer game), there is no known optimal policy for an agent wishing to act optimally. We propose a machine learning algorithm, based on deep Q-networks, to optimize the replenishment decisions at a given stage. When playing alongside agents who follow a base-stock policy, our algorithm obtains near-optimal order quantities. It performs much better than a base-stock policy when the other agents use a more realistic model of human ordering behavior. Unlike most other algorithms in the literature, our algorithm does not have any limits on the beer game parameter values. Like any deep learning algorithm, training the algorithm can be computationally intensive, but this can be performed ahead of time; the algorithm executes in real time when the game is played. Moreover, we propose a transfer learning approach so that the training performed for one agent and one set of cost coefficients can be adapted quickly for other agents and costs. Our algorithm can be extended to other decentralized multi-agent cooperative games with partially observed information, which is a common type of situation in real-world supply chain problems.}
}
@article{Qiu_Dong_Ma_Li_Wang_Tang_2018,
	title        = {Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec},
	author       = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	year         = 2018,
	journal      = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM ’18},
	pages        = {459–467},
	doi          = {10.1145/3159652.3159706},
	note         = {arXiv: 1710.02971},
	abstractnote = {Since the invention of word2vec [28, 29], the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk [31] empirically produces a low-rank transformation of a network’s normalized Laplacian matrix; (2) LINE [37], in theory, is a special case of DeepWalk when the size of vertices’ context is set to one; (3) As an extension of LINE, PTE [36] can be viewed as the joint factorization of multiple networks’ Laplacians; (4) node2vec [16] is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method1 as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.}
}
@article{Qu_Bengio_Tang,
	title        = {GMNN: Graph Markov Neural Networks},
	author       = {Qu, Meng and Bengio, Yoshua and Tang, Jian},
	pages        = 10,
	abstractnote = {This paper studies semi-supervised object classiﬁcation in relational data, which is a fundamental problem in relational data modeling. The problem has been extensively studied in the literature of both statistical relational learning (e.g. relational Markov networks) and graph neural networks (e.g. graph convolutional networks). Statistical relational learning methods can effectively model the dependency of object labels through conditional random ﬁelds for collective classiﬁcation, whereas graph neural networks learn effective object representations for classiﬁcation through end-to-end training. In this paper, we propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds. A GMNN models the joint distribution of object labels with a conditional random ﬁeld, which can be effectively trained with the variational EM algorithm. In the E-step, one graph neural network learns effective object representations for approximating the posterior distributions of object labels. In the M-step, another graph neural network is used to model the local label dependency. Experiments on object classiﬁcation, link classiﬁcation, and unsupervised node representation learning show that GMNN achieves state-of-the-art results.}
}
@inproceedings{Tang_Mhamdi_McLernon_Zaidi_Ghogho_2016,
	title        = {Deep learning approach for Network Intrusion Detection in Software Defined Networking},
	author       = {Tang, Tuan A and Mhamdi, Lotfi and McLernon, Des and Zaidi, Syed Ali Raza and Ghogho, Mounir},
	year         = 2016,
	month        = oct,
	booktitle    = {2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)},
	publisher    = {IEEE},
	pages        = {258–263},
	doi          = {10.1109/WINCOM.2016.7777224},
	isbn         = {978-1-5090-3837-4},
	url          = {http://ieeexplore.ieee.org/document/7777224/},
	place        = {Fez, Morocco},
	abstractnote = {Software Deﬁned Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for ﬂow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSLKDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the fortyone features of NSL-KDD Dataset. Through experiments, we conﬁrm that the deep learning approach shows strong potential to be used for ﬂow-based anomaly detection in SDN environments.}
}
@inproceedings{Zhang_Dong_Wang_Tang_Ding_2019,
	title        = {ProNE: Fast and Scalable Network Representation Learning},
	author       = {Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {4278–4284},
	doi          = {10.24963/ijcai.2019/594},
	isbn         = {978-0-9992411-4-1},
	url          = {https://www.ijcai.org/proceedings/2019/594},
	place        = {Macao, China},
	abstractnote = {Recent advances in network embedding have revolutionized the ﬁeld of graph and network mining. However, (pre-)training embeddings for very large-scale networks is computationally challenging for most existing methods. In this work, we present ProNE—a fast, scalable, and effective model, whose single-thread version is 10–400× faster than efﬁcient network embedding benchmarks with 20 threads, including LINE, DeepWalk, node2vec, GraRep, and HOPE. As a concrete example, the single-thread ProNE requires only 29 hours to embed a network of hundreds of millions of nodes while it takes LINE weeks and DeepWalk months by using 20 threads. To achieve this, ProNE ﬁrst initializes network embeddings efﬁciently by formulating the task as sparse matrix factorization. The second step of ProNE is to enhance the embeddings by propagating them in the spectrally modulated space. Extensive experiments on networks of various scales and types demonstrate that ProNE achieves both effectiveness and signiﬁcant efﬁciency superiority when compared to the aforementioned baselines. In addition, ProNE’s embedding enhancement step can be also generalized for improving other models at speed, e.g., offering >10\% relative gains for the used baselines.}
}
_Takáč_2019