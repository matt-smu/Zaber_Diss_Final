% This section responds to the question "What have you found?" Hence, only representative results from your research should be presented. The results should be essential for discussion.

% However, remember that most journals offer the possibility of adding Supporting Materials, so use them freely for data of secondary importance. In this way, do not attempt to "hide" data in the hope of saving it for a later paper. You may lose evidence to reinforce your conclusion. If data are too abundant, you can use those supplementary materials.

% Use sub-headings to keep results of the same type together, which is easier to review and read. Number these sub-sections for the convenience of internal cross-referencing, but always taking into account the publisher's Guide for Authors.

% For the data, decide on a logical order that tells a clear story and makes it and easy to understand. Generally, this will be in the same order as presented in the methods section.

% An important issue is that you must not include references in this section; you are presenting your results, so you cannot refer to others here. If you refer to others, is because you are discussing your results, and this must be included in the Discussion section.


In this section we describe our proof of concept implementation of the pipeline shown in Figure \ref{fig:automation:metric_pipeline}. The entire workflow can be thought of in terms of the well-known \textit{extract, transform, load} (ETL) process, which opens up a variety of design, implementation, and deployment options. Our goal in this section therefore is to describe contributions specific to security metrics analysis, where adherence to the literature is prioritized above computational optimization and efficiency. 

% and demonstrate how it can be used to address some current issues in security measurement research. We provide an example environment for metric development and evaluation. We create a library of select security metrics from the literature and build up reusable processing components for end-to-end automation of the pipeline. We then demonstrate the utility of the framework with two motivating examples. In the first case we develop a simple validation methodology for security metrics. Then we describe a distributed stream processing architecture for deploying security metrics in production, and discuss practical considerations for scaling, securing, and managing dependencies in the metric pipeline.